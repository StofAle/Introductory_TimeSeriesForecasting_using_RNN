{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "#### In this notebook, the trial runs from the preceding notebook ('01_So_What.ipynb') are systematically extended to try to find an optimal configuration for the two models, fine tuning the number of units in the network and the number of epochs used in the training schema. \n",
    "\n",
    "#### The best performing model configuration will be used in the notebook '03_Blue_in_Green.ipynb' to analyze the impact of adding noise to the clean dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [1. Load modules](#Part1_link)\n",
    "* [2. Setup data](#Part2_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.1  Generate data, separate testing and validation set and standardize testing data](#Part2.1_link)\n",
    "* [3. Setup models and evaluate for various hyper-parameter choices](#Part3_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.1 Compile and fit LSTM and RNN model](#Part3.1_link)\n",
    "* [4. Visualize and save results](#Part4_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part1_link'></a>\n",
    "# 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import Kind_of_Blue  # own class with a collection of methods used in this analysis\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2_link'></a>\n",
    "# 2. Setup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.1_link'></a>\n",
    "### 2.1 Generate data, separate testing and validation set and standardize testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps are repeated from the analysis in the preceding notebook, '01_So_What.ipynb', and are executed in the following step at once for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations in time series: 1820\n",
      "train split ratio =  0.7\n",
      "loaded data set length: 1820\n",
      "mean: 0.0, std: 1.0\n",
      "training set shape: x:(909, 365, 1), y:(909, 7, 1)\n",
      "validation set shape: x:(174, 365, 1), y:(174, 7, 1)\n",
      "number of training samples: 909\n"
     ]
    }
   ],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=5*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 10  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "print('number of observations in time series: {}'.format(len(observations)))\n",
    "\n",
    "# initialize dataframe to store time series\n",
    "df = pd.DataFrame(data=observations, columns=['observations'])\n",
    "df.index = idx\n",
    "\n",
    "# initialize object\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# load dataframe into object\n",
    "mdq._selected_features = ['observations']\n",
    "mdq.df = df\n",
    "\n",
    "# train-validation split ratio as class attribute set to 70%\n",
    "print('train split ratio = ', mdq.TRAIN_SPLIT_RATIO)\n",
    "\n",
    "# initialize dataset from dataframe \n",
    "mdq.initialize_dataset()\n",
    "print('loaded data set length: {}'.format(len(mdq._dataset)))\n",
    "\n",
    "# standardize data\n",
    "mdq.standardize_data()\n",
    "\n",
    "# check that mean equals zero and the standard deviation is one\n",
    "print('mean: {}, std: {}'.format(round(np.mean(mdq._dataset), 2), round(np.std(mdq._dataset), 2)))\n",
    "\n",
    "# set number of time points for 1/ future forecasting points and 2/ the past, historical time points\n",
    "future_target_size = int(365/52)\n",
    "past_history_size = int(1*365)\n",
    "\n",
    "# generate train and validation data\n",
    "mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size)\n",
    "\n",
    "print('number of training samples: {}'.format(mdq._num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3_link'></a>\n",
    "# 3. Setup models and evaluate for various hyper-parameter choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models are trained and evaluated under various choices for the number of units and number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.1_link'></a>\n",
    "### 3.1 Compile and fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generator for configurations to be iterated over\n",
    "\n",
    "def config_generator():\n",
    "    \n",
    "    unit_choices = [64, 128, 256]  # number of units in each neural network layer\n",
    "    layer_choices = [2]  # total number of layers\n",
    "    epoch_choices = [10, 30, 50]  # number of epochs the model is trained on\n",
    "    \n",
    "    for units in unit_choices:\n",
    "        for num_layers in layer_choices:\n",
    "            for epochs in epoch_choices:\n",
    "                yield units, num_layers, epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 62s 478ms/step - loss: 0.1651 - mse: 0.1651 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 54s 420ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 69s 535ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 62s 484ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 62s 478ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 59s 458ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 60s 465ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 8.0246e-04 - val_mse: 8.0246e-04\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 59s 459ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 8.8133e-04 - val_mse: 8.8133e-04\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 61s 476ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 8.4428e-04 - val_mse: 8.4428e-04\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 72s 561ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 7.8294e-04 - val_mse: 7.8294e-04\n",
      "currently running RNN model\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 15s 117ms/step - loss: 0.1566 - mse: 0.1566 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 13s 102ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 13s 99ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 13s 100ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 15s 115ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 9.4879e-04 - val_mse: 9.4879e-04\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 13s 98ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 14s 110ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 15s 117ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 5.5447e-04 - val_mse: 5.5447e-04\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 15s 117ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 4.1929e-04 - val_mse: 4.1929e-04\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 13s 103ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 64s 499ms/step - loss: 0.1571 - mse: 0.1571 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 53s 412ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 58s 448ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 68s 529ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 53s 409ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 9.8571e-04 - val_mse: 9.8571e-04\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 53s 408ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 4.0955e-04 - val_mse: 4.0955e-04\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 53s 410ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 53s 410ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 53s 413ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 59s 457ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 9.5763e-04 - val_mse: 9.5763e-04\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 60s 461ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 53s 413ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 53s 412ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 3.1981e-04 - val_mse: 3.1981e-04\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 55s 423ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 56s 435ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 54s 418ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 55s 423ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 61s 473ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 57s 438ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 9.8769e-04 - val_mse: 9.8769e-04\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 65s 502ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 70s 539ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 69s 536ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 9.6383e-04 - val_mse: 9.6383e-04\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 47s 365ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 2.8557e-04 - val_mse: 2.8557e-04\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 40s 312ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 5.6254e-04 - val_mse: 5.6254e-04\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 41s 319ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 41s 319ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 41s 318ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 7.5425e-04 - val_mse: 7.5425e-04\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 56s 431ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 53s 414ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 7.5499e-04 - val_mse: 7.5499e-04\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 59s 459ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "currently running RNN model\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 13s 102ms/step - loss: 0.1399 - mse: 0.1399 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 13s 99ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 12s 94ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 14s 105ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 12s 94ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 16s 121ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 14s 111ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 14s 107ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0014 - val_mse: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "129/129 [==============================] - 14s 107ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 7.9036e-04 - val_mse: 7.9036e-04\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 15s 119ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 9.3797e-04 - val_mse: 9.3797e-04\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 13s 104ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 5.0932e-04 - val_mse: 5.0932e-04\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 13s 99ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 4.6047e-04 - val_mse: 4.6047e-04\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 12s 89ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 10s 78ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 11s 82ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 4.6928e-04 - val_mse: 4.6928e-04\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 10s 80ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 13s 100ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 8.2017e-04 - val_mse: 8.2017e-04\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 11s 83ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 10s 81ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 11s 83ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 10s 80ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 11s 85ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 14s 109ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 16s 127ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 11s 89ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 9.7616e-04 - val_mse: 9.7616e-04\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 11s 83ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 3.9101e-04 - val_mse: 3.9101e-04\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 11s 87ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 3.4929e-04 - val_mse: 3.4929e-04\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 11s 84ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 6.5986e-04 - val_mse: 6.5986e-04\n",
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 62s 478ms/step - loss: 0.1834 - mse: 0.1834 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 56s 437ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 55s 425ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 52s 401ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 54s 417ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 73s 562ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 9.9652e-04 - val_mse: 9.9652e-04\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 60s 468ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 6.6874e-04 - val_mse: 6.6874e-04\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 56s 431ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 54s 418ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 9.0869e-04 - val_mse: 9.0869e-04\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 52s 405ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 59s 455ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 5.2045e-04 - val_mse: 5.2045e-04\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 66s 511ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 7.4323e-04 - val_mse: 7.4323e-04\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 58s 448ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 82s 636ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 84s 654ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 84s 650ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 61s 472ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 7.6826e-04 - val_mse: 7.6826e-04\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 60s 467ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 59s 454ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 7.3796e-04 - val_mse: 7.3796e-04\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 60s 465ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 7.9760e-04 - val_mse: 7.9760e-04\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 59s 457ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 6.4129e-04 - val_mse: 6.4129e-04\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 76s 586ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 73s 568ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 8.6231e-04 - val_mse: 8.6231e-04\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 87s 675ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 85s 658ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 8.3773e-04 - val_mse: 8.3773e-04\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 68s 528ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 56s 435ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 4.8405e-04 - val_mse: 4.8405e-04\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 56s 437ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 7.7518e-04 - val_mse: 7.7518e-04\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 62s 483ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 3.7011e-04 - val_mse: 3.7011e-04\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 59s 454ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 55s 424ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 58s 448ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 9.1968e-04 - val_mse: 9.1968e-04\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 70s 544ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 71s 554ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 68s 525ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 6.9114e-04 - val_mse: 6.9114e-04\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 60s 461ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 64s 497ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 8.2617e-04 - val_mse: 8.2617e-04\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 76s 593ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 5.5147e-04 - val_mse: 5.5147e-04\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 79s 616ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 82s 632ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 4.8417e-04 - val_mse: 4.8417e-04\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 85s 662ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 3.7036e-04 - val_mse: 3.7036e-04\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 91s 707ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 92s 711ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 5.3918e-04 - val_mse: 5.3918e-04\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 89s 692ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 85s 658ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 72s 562ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 71s 550ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 5.7658e-04 - val_mse: 5.7658e-04\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 76s 586ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 6.1677e-04 - val_mse: 6.1677e-04\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 87s 676ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 84s 649ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 4.4160e-04 - val_mse: 4.4160e-04\n",
      "currently running RNN model\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.1165 - mse: 0.1165 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 12s 97ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 4.8549e-04 - val_mse: 4.8549e-04\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 13s 100ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 11s 89ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 2.8909e-04 - val_mse: 2.8909e-04\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 11s 89ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 5.2517e-04 - val_mse: 5.2517e-04\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 12s 89ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 9.5457e-04 - val_mse: 9.5457e-04\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 11s 88ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 3.8849e-04 - val_mse: 3.8849e-04\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 4.9313e-04 - val_mse: 4.9313e-04\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 6.8624e-04 - val_mse: 6.8624e-04\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 8.6218e-04 - val_mse: 8.6218e-04\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 5.9682e-04 - val_mse: 5.9682e-04\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.2158 - mse: 0.2158 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 12s 93ms/step - loss: 0.0491 - mse: 0.0491 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 12s 95ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 12s 93ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 12s 93ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 12s 94ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 12s 93ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 12s 94ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 13s 99ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 14s 105ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 14s 106ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 13s 103ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 13s 105ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 13s 104ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 14s 109ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 12s 96ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 13s 98ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 12s 95ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 12s 96ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 12s 89ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 109s 843ms/step - loss: 0.1433 - mse: 0.1433 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 112s 866ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 109s 847ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 121s 935ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 130s 1s/step - loss: 0.0110 - mse: 0.0110 - val_loss: 7.1723e-04 - val_mse: 7.1723e-04\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 139s 1s/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 125s 967ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 90s 701ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 5.3374e-04 - val_mse: 5.3374e-04\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 96s 746ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 83s 646ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "currently running RNN model\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 12s 95ms/step - loss: 0.0768 - mse: 0.0768 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 11s 83ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 10s 79ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 6.1405e-04 - val_mse: 6.1405e-04\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 10s 80ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 11s 85ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 7.9200e-04 - val_mse: 7.9200e-04\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 10s 77ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 10s 78ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 4.6323e-04 - val_mse: 4.6323e-04\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 11s 82ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 8.7716e-04 - val_mse: 8.7716e-04\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 11s 87ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 88s 679ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 82s 633ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 78s 607ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 83s 646ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 8.7636e-04 - val_mse: 8.7636e-04\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 92s 711ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 9.5816e-04 - val_mse: 9.5816e-04\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 85s 657ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 8.6065e-04 - val_mse: 8.6065e-04\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 79s 613ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 77s 601ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 2.7935e-04 - val_mse: 2.7935e-04\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 73s 567ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 77s 598ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 82s 637ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 92s 712ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 3.6504e-04 - val_mse: 3.6504e-04\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 80s 619ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 77s 598ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 2.7581e-04 - val_mse: 2.7581e-04\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 74s 575ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 7.8996e-04 - val_mse: 7.8996e-04\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 76s 593ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 76s 588ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 6.7149e-04 - val_mse: 6.7149e-04\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 73s 566ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 6.5034e-04 - val_mse: 6.5034e-04\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 75s 581ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 2.4078e-04 - val_mse: 2.4078e-04\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 93s 722ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 4.6084e-04 - val_mse: 4.6084e-04\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 69s 531ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 75s 578ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 8.1288e-04 - val_mse: 8.1288e-04\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 82s 635ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 5.6720e-04 - val_mse: 5.6720e-04\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 79s 611ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 5.5234e-04 - val_mse: 5.5234e-04\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 81s 630ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 76s 589ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 9.1380e-04 - val_mse: 9.1380e-04\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 81s 627ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 2.8292e-04 - val_mse: 2.8292e-04\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 86s 665ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 73s 567ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 75s 584ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 8.0282e-04 - val_mse: 8.0282e-04\n",
      "currently running RNN model\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 11s 84ms/step - loss: 0.0720 - mse: 0.0720 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 10s 79ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 10s 81ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 10s 80ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 5.5519e-04 - val_mse: 5.5519e-04\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 10s 76ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 9.6758e-04 - val_mse: 9.6758e-04\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 10s 74ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 9.1656e-04 - val_mse: 9.1656e-04\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 10s 75ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 10s 79ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 10s 79ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 10s 78ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 10s 78ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 10s 78ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 10s 76ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 10s 74ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 10s 74ms/step - loss: 0.6804 - mse: 0.6804 - val_loss: 0.1242 - val_mse: 0.1242\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 10s 79ms/step - loss: 0.4525 - mse: 0.4525 - val_loss: 0.0680 - val_mse: 0.0680\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 11s 84ms/step - loss: 0.0794 - mse: 0.0794 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 10s 81ms/step - loss: 0.0585 - mse: 0.0585 - val_loss: 0.0370 - val_mse: 0.0370\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 11s 88ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 11s 81ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 10s 81ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 11s 83ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0258 - val_mse: 0.0258\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 11s 87ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 14s 107ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 14s 111ms/step - loss: 0.0391 - mse: 0.0391 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 10s 79ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 10s 80ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 11s 82ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 91s 707ms/step - loss: 0.1027 - mse: 0.1027 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 76s 591ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 79s 612ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 81s 627ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 84s 654ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 79s 609ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 8.7619e-04 - val_mse: 8.7619e-04\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 78s 608ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 88s 681ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 96s 742ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 78s 601ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 9.9009e-04 - val_mse: 9.9009e-04\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 70s 541ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 70s 540ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 5.8915e-04 - val_mse: 5.8915e-04\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 74s 573ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 70s 539ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 71s 550ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 6.9771e-04 - val_mse: 6.9771e-04\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 85s 659ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 2.0743e-04 - val_mse: 2.0743e-04\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 72s 555ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 72s 557ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 76s 591ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 8.3938e-04 - val_mse: 8.3938e-04\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 73s 567ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 8.1984e-04 - val_mse: 8.1984e-04\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 73s 565ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 4.4339e-04 - val_mse: 4.4339e-04\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 74s 573ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 75s 585ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 136s 1s/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 113s 874ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 100s 777ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 103s 802ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 9.3970e-04 - val_mse: 9.3970e-04\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 108s 840ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 7.6414e-04 - val_mse: 7.6414e-04\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 103s 795ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 7.1512e-04 - val_mse: 7.1512e-04\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 108s 839ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 6.6708e-04 - val_mse: 6.6708e-04\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 110s 850ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 110s 849ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 7.3808e-04 - val_mse: 7.3808e-04\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 101s 784ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 105s 812ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 6.9469e-04 - val_mse: 6.9469e-04\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 137s 1s/step - loss: 0.0068 - mse: 0.0068 - val_loss: 8.5808e-04 - val_mse: 8.5808e-04\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 129s 1s/step - loss: 0.0067 - mse: 0.0067 - val_loss: 3.1607e-04 - val_mse: 3.1607e-04\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 119s 924ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 4.6821e-04 - val_mse: 4.6821e-04\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 98s 762ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 95s 736ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 8.1612e-04 - val_mse: 8.1612e-04\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 117s 910ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 2.9025e-04 - val_mse: 2.9025e-04\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 115s 895ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 3.2900e-04 - val_mse: 3.2900e-04\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 117s 911ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 89s 686ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 3.8877e-04 - val_mse: 3.8877e-04\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 88s 682ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 5.4560e-04 - val_mse: 5.4560e-04\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 84s 651ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 2.5613e-04 - val_mse: 2.5613e-04\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 139s 1s/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 110s 856ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 4.0968e-04 - val_mse: 4.0968e-04\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 102s 790ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 5.6635e-04 - val_mse: 5.6635e-04\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 103s 795ms/step - loss: 0.0066 - mse: 0.0066 - val_loss: 3.9750e-04 - val_mse: 3.9750e-04\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 113s 878ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 7.5998e-04 - val_mse: 7.5998e-04\n",
      "currently running RNN model\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 13s 99ms/step - loss: 0.0864 - mse: 0.0864 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 13s 98ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 13s 100ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.1225 - val_mse: 0.1225\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 12s 94ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0131 - val_mse: 0.0131\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 15s 116ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 16s 124ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 15s 119ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 16s 126ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0095 - val_mse: 0.0095\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 12s 97ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 12s 96ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 8.1667e-04 - val_mse: 8.1667e-04\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 12s 94ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 4.5305e-04 - val_mse: 4.5305e-04\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 14s 105ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 15s 116ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 7.4140e-04 - val_mse: 7.4140e-04\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 14s 112ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 13s 104ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 15s 120ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 14s 111ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 15s 116ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 6.9747e-04 - val_mse: 6.9747e-04\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 13s 103ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 14s 111ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 13s 102ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 15s 117ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 8.2813e-04 - val_mse: 8.2813e-04\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 13s 99ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 17s 132ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 15s 114ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 4.8187e-04 - val_mse: 4.8187e-04\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 13s 97ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 4.1126e-04 - val_mse: 4.1126e-04\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 13s 98ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 13s 98ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 14s 112ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 9.9111e-04 - val_mse: 9.9111e-04\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 13s 100ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 8.3438e-04 - val_mse: 8.3438e-04\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 10s 81ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 10s 78ms/step - loss: 0.0917 - mse: 0.0917 - val_loss: 0.0366 - val_mse: 0.0366\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 11s 84ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 11s 85ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 11s 84ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 11s 88ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 11s 87ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 11s 87ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 9.1815e-04 - val_mse: 9.1815e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "129/129 [==============================] - 11s 87ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 8.1973e-04 - val_mse: 8.1973e-04\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 11s 83ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 11s 84ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 12s 93ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 4.2268e-04 - val_mse: 4.2268e-04\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 11s 86ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 11s 86ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 8.7276e-04 - val_mse: 8.7276e-04\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 11s 85ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 11s 85ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 11s 84ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 230s 2s/step - loss: 0.1098 - mse: 0.1098 - val_loss: 4.3919e-04 - val_mse: 4.3919e-04\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 215s 2s/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 218s 2s/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 198s 2s/step - loss: 0.0084 - mse: 0.0084 - val_loss: 6.1443e-04 - val_mse: 6.1443e-04\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 193s 1s/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 208s 2s/step - loss: 0.0067 - mse: 0.0067 - val_loss: 7.6777e-04 - val_mse: 7.6777e-04\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 251s 2s/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 256s 2s/step - loss: 0.0058 - mse: 0.0058 - val_loss: 9.3540e-04 - val_mse: 9.3540e-04\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 240s 2s/step - loss: 0.0063 - mse: 0.0063 - val_loss: 3.2941e-04 - val_mse: 3.2941e-04\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 237s 2s/step - loss: 0.0046 - mse: 0.0046 - val_loss: 4.2876e-04 - val_mse: 4.2876e-04\n",
      "currently running RNN model\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 29s 221ms/step - loss: 0.3168 - mse: 0.3168 - val_loss: 0.0869 - val_mse: 0.0869\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 28s 221ms/step - loss: 0.0724 - mse: 0.0724 - val_loss: 0.0397 - val_mse: 0.0397\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 29s 222ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 29s 225ms/step - loss: 0.0538 - mse: 0.0538 - val_loss: 0.0325 - val_mse: 0.0325\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 29s 221ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 33s 259ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 34s 267ms/step - loss: 0.2778 - mse: 0.2778 - val_loss: 19.5582 - val_mse: 19.5582\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 34s 262ms/step - loss: 1.4595 - mse: 1.4595 - val_loss: 0.2020 - val_mse: 0.2020\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 29s 222ms/step - loss: 0.2320 - mse: 0.2320 - val_loss: 0.1849 - val_mse: 0.1849\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 29s 223ms/step - loss: 0.2257 - mse: 0.2257 - val_loss: 0.1843 - val_mse: 0.1843\n",
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 238s 2s/step - loss: 0.0714 - mse: 0.0714 - val_loss: 7.1875e-04 - val_mse: 7.1875e-04\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 261s 2s/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 262s 2s/step - loss: 0.0087 - mse: 0.0087 - val_loss: 7.7694e-04 - val_mse: 7.7694e-04\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 300s 2s/step - loss: 0.0077 - mse: 0.0077 - val_loss: 6.1663e-04 - val_mse: 6.1663e-04\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 311s 2s/step - loss: 0.0065 - mse: 0.0065 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 311s 2s/step - loss: 0.0061 - mse: 0.0061 - val_loss: 4.6634e-04 - val_mse: 4.6634e-04\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 321s 2s/step - loss: 0.0056 - mse: 0.0056 - val_loss: 2.3938e-04 - val_mse: 2.3938e-04\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 340s 3s/step - loss: 0.0057 - mse: 0.0057 - val_loss: 2.6687e-04 - val_mse: 2.6687e-04\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 404s 3s/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 420s 3s/step - loss: 0.0049 - mse: 0.0049 - val_loss: 4.6176e-04 - val_mse: 4.6176e-04\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 408s 3s/step - loss: 0.0049 - mse: 0.0049 - val_loss: 3.7483e-04 - val_mse: 3.7483e-04\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 406s 3s/step - loss: 0.0049 - mse: 0.0049 - val_loss: 7.2770e-04 - val_mse: 7.2770e-04\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 473s 4s/step - loss: 0.0044 - mse: 0.0044 - val_loss: 5.9936e-04 - val_mse: 5.9936e-04\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 379s 3s/step - loss: 0.0044 - mse: 0.0044 - val_loss: 1.7849e-04 - val_mse: 1.7849e-04\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 339s 3s/step - loss: 0.0044 - mse: 0.0044 - val_loss: 7.0529e-04 - val_mse: 7.0529e-04\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 356s 3s/step - loss: 0.0043 - mse: 0.0043 - val_loss: 6.3698e-04 - val_mse: 6.3698e-04\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 406s 3s/step - loss: 0.0044 - mse: 0.0044 - val_loss: 6.5299e-04 - val_mse: 6.5299e-04\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 306s 2s/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 298s 2s/step - loss: 0.0040 - mse: 0.0040 - val_loss: 7.8790e-04 - val_mse: 7.8790e-04\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 282s 2s/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 289s 2s/step - loss: 0.0040 - mse: 0.0040 - val_loss: 5.1562e-04 - val_mse: 5.1562e-04\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 344s 3s/step - loss: 0.0038 - mse: 0.0038 - val_loss: 3.4426e-04 - val_mse: 3.4426e-04\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 358s 3s/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 374s 3s/step - loss: 0.0038 - mse: 0.0038 - val_loss: 9.4960e-04 - val_mse: 9.4960e-04\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 358s 3s/step - loss: 0.0038 - mse: 0.0038 - val_loss: 6.0139e-04 - val_mse: 6.0139e-04\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 357s 3s/step - loss: 0.0040 - mse: 0.0040 - val_loss: 9.6699e-04 - val_mse: 9.6699e-04\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 345s 3s/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 363s 3s/step - loss: 0.0037 - mse: 0.0037 - val_loss: 5.0797e-04 - val_mse: 5.0797e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "129/129 [==============================] - 347s 3s/step - loss: 0.0035 - mse: 0.0035 - val_loss: 1.7349e-04 - val_mse: 1.7349e-04\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 364s 3s/step - loss: 0.0036 - mse: 0.0036 - val_loss: 1.8785e-04 - val_mse: 1.8785e-04\n",
      "currently running RNN model\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 45s 348ms/step - loss: 0.3107 - mse: 0.3107 - val_loss: 0.0955 - val_mse: 0.0955\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 45s 349ms/step - loss: 0.0733 - mse: 0.0733 - val_loss: 0.0706 - val_mse: 0.0706\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 45s 348ms/step - loss: 0.1439 - mse: 0.1439 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 43s 333ms/step - loss: 0.1390 - mse: 0.1390 - val_loss: 0.0354 - val_mse: 0.0354\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 46s 356ms/step - loss: 0.0429 - mse: 0.0429 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 49s 379ms/step - loss: 0.0422 - mse: 0.0422 - val_loss: 0.0199 - val_mse: 0.0199\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 51s 392ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 49s 376ms/step - loss: 0.0374 - mse: 0.0374 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 50s 384ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 45s 351ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 46s 356ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 43s 336ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 46s 355ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 46s 358ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 45s 349ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 43s 331ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0083 - val_mse: 0.0083\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 46s 353ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 47s 361ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 48s 373ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 48s 374ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 50s 384ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 49s 379ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 45s 349ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 43s 336ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 45s 348ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 45s 350ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 46s 360ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 51s 395ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 58s 453ms/step - loss: 0.0063 - mse: 0.0063 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 51s 397ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 369s 3s/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 364s 3s/step - loss: 0.0114 - mse: 0.0114 - val_loss: 7.0414e-04 - val_mse: 7.0414e-04\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 361s 3s/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 374s 3s/step - loss: 0.0082 - mse: 0.0082 - val_loss: 3.2507e-04 - val_mse: 3.2507e-04\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 364s 3s/step - loss: 0.0069 - mse: 0.0069 - val_loss: 2.5641e-04 - val_mse: 2.5641e-04\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 369s 3s/step - loss: 0.0067 - mse: 0.0067 - val_loss: 1.9950e-04 - val_mse: 1.9950e-04\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 369s 3s/step - loss: 0.0066 - mse: 0.0066 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 366s 3s/step - loss: 0.0056 - mse: 0.0056 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 374s 3s/step - loss: 0.0054 - mse: 0.0054 - val_loss: 2.6865e-04 - val_mse: 2.6865e-04\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 395s 3s/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 376s 3s/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 379s 3s/step - loss: 0.0046 - mse: 0.0046 - val_loss: 5.0836e-04 - val_mse: 5.0836e-04\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 365s 3s/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 371s 3s/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 374s 3s/step - loss: 0.0046 - mse: 0.0046 - val_loss: 3.5693e-04 - val_mse: 3.5693e-04\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 368s 3s/step - loss: 0.0042 - mse: 0.0042 - val_loss: 9.6143e-04 - val_mse: 9.6143e-04\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 379s 3s/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 369s 3s/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 371s 3s/step - loss: 0.0060 - mse: 0.0060 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 393s 3s/step - loss: 0.0045 - mse: 0.0045 - val_loss: 3.6838e-04 - val_mse: 3.6838e-04\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 388s 3s/step - loss: 0.0043 - mse: 0.0043 - val_loss: 5.1320e-04 - val_mse: 5.1320e-04\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 371s 3s/step - loss: 0.0038 - mse: 0.0038 - val_loss: 3.4188e-04 - val_mse: 3.4188e-04\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 367s 3s/step - loss: 0.0039 - mse: 0.0039 - val_loss: 6.5137e-05 - val_mse: 6.5137e-05\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 358s 3s/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 372s 3s/step - loss: 0.0040 - mse: 0.0040 - val_loss: 9.1644e-04 - val_mse: 9.1644e-04\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 362s 3s/step - loss: 0.0039 - mse: 0.0039 - val_loss: 3.7974e-04 - val_mse: 3.7974e-04\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 364s 3s/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 369s 3s/step - loss: 0.0043 - mse: 0.0043 - val_loss: 7.7533e-04 - val_mse: 7.7533e-04\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 350s 3s/step - loss: 0.0036 - mse: 0.0036 - val_loss: 2.0577e-04 - val_mse: 2.0577e-04\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 373s 3s/step - loss: 0.0038 - mse: 0.0038 - val_loss: 3.3302e-04 - val_mse: 3.3302e-04\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 403s 3s/step - loss: 0.0039 - mse: 0.0039 - val_loss: 3.9585e-04 - val_mse: 3.9585e-04\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 358s 3s/step - loss: 0.0040 - mse: 0.0040 - val_loss: 8.8640e-04 - val_mse: 8.8640e-04\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 368s 3s/step - loss: 0.0035 - mse: 0.0035 - val_loss: 4.3229e-04 - val_mse: 4.3229e-04\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 354s 3s/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 360s 3s/step - loss: 0.0036 - mse: 0.0036 - val_loss: 2.0481e-04 - val_mse: 2.0481e-04\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 359s 3s/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 353s 3s/step - loss: 0.0036 - mse: 0.0036 - val_loss: 4.9029e-04 - val_mse: 4.9029e-04\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 369s 3s/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 357s 3s/step - loss: 0.0036 - mse: 0.0036 - val_loss: 4.3742e-04 - val_mse: 4.3742e-04\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 367s 3s/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 408s 3s/step - loss: 0.0034 - mse: 0.0034 - val_loss: 2.3709e-04 - val_mse: 2.3709e-04\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 356s 3s/step - loss: 0.0032 - mse: 0.0032 - val_loss: 4.8625e-04 - val_mse: 4.8625e-04\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 368s 3s/step - loss: 0.0035 - mse: 0.0035 - val_loss: 3.0952e-04 - val_mse: 3.0952e-04\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 361s 3s/step - loss: 0.0032 - mse: 0.0032 - val_loss: 3.6445e-04 - val_mse: 3.6445e-04\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 358s 3s/step - loss: 0.0038 - mse: 0.0038 - val_loss: 5.5498e-04 - val_mse: 5.5498e-04\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 371s 3s/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 352s 3s/step - loss: 0.0036 - mse: 0.0036 - val_loss: 1.7374e-04 - val_mse: 1.7374e-04\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 291s 2s/step - loss: 0.0035 - mse: 0.0035 - val_loss: 2.8922e-04 - val_mse: 2.8922e-04\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 284s 2s/step - loss: 0.0034 - mse: 0.0034 - val_loss: 6.6187e-04 - val_mse: 6.6187e-04\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 294s 2s/step - loss: 0.0034 - mse: 0.0034 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "currently running RNN model\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 33s 258ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 33s 256ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 33s 258ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 4.6655e-04 - val_mse: 4.6655e-04\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 33s 256ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 5.4874e-04 - val_mse: 5.4874e-04\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 33s 254ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 8.6948e-04 - val_mse: 8.6948e-04\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 33s 255ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 34s 262ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 6.6168e-04 - val_mse: 6.6168e-04\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 33s 256ms/step - loss: 0.0064 - mse: 0.0064 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 37s 284ms/step - loss: 0.0056 - mse: 0.0056 - val_loss: 6.3259e-04 - val_mse: 6.3259e-04\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 38s 297ms/step - loss: 0.5649 - mse: 0.5649 - val_loss: 2.0380 - val_mse: 2.0380\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 38s 293ms/step - loss: 1.7063 - mse: 1.7063 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 37s 285ms/step - loss: 0.0720 - mse: 0.0720 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 33s 259ms/step - loss: 0.0583 - mse: 0.0583 - val_loss: 0.0370 - val_mse: 0.0370\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 33s 254ms/step - loss: 0.0544 - mse: 0.0544 - val_loss: 0.0391 - val_mse: 0.0391\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 34s 262ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 42s 328ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0356 - val_mse: 0.0356\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 43s 331ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0372 - val_mse: 0.0372\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 34s 264ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0396 - val_mse: 0.0396\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 33s 257ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0390 - val_mse: 0.0390\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 33s 257ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0402 - val_mse: 0.0402\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 33s 257ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 33s 256ms/step - loss: 0.0505 - mse: 0.0505 - val_loss: 0.0436 - val_mse: 0.0436\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 33s 256ms/step - loss: 0.0523 - mse: 0.0523 - val_loss: 0.0445 - val_mse: 0.0445\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 33s 260ms/step - loss: 0.4370 - mse: 0.4370 - val_loss: 0.0597 - val_mse: 0.0597\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 33s 253ms/step - loss: 0.0817 - mse: 0.0817 - val_loss: 0.0623 - val_mse: 0.0623\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 36s 280ms/step - loss: 0.0760 - mse: 0.0760 - val_loss: 0.0578 - val_mse: 0.0578\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 39s 299ms/step - loss: 0.0736 - mse: 0.0736 - val_loss: 0.0581 - val_mse: 0.0581\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 38s 296ms/step - loss: 0.0728 - mse: 0.0728 - val_loss: 0.0560 - val_mse: 0.0560\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 35s 270ms/step - loss: 0.0719 - mse: 0.0719 - val_loss: 0.0613 - val_mse: 0.0613\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 33s 255ms/step - loss: 0.0731 - mse: 0.0731 - val_loss: 0.0587 - val_mse: 0.0587\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 33s 254ms/step - loss: 0.0710 - mse: 0.0710 - val_loss: 0.0610 - val_mse: 0.0610\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 33s 255ms/step - loss: 0.0714 - mse: 0.0714 - val_loss: 0.0589 - val_mse: 0.0589\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 33s 258ms/step - loss: 0.0728 - mse: 0.0728 - val_loss: 0.0593 - val_mse: 0.0593\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 33s 255ms/step - loss: 0.0709 - mse: 0.0709 - val_loss: 0.0578 - val_mse: 0.0578\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 33s 255ms/step - loss: 0.0717 - mse: 0.0717 - val_loss: 0.0587 - val_mse: 0.0587\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 33s 257ms/step - loss: 0.0720 - mse: 0.0720 - val_loss: 0.0642 - val_mse: 0.0642\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 33s 258ms/step - loss: 0.0729 - mse: 0.0729 - val_loss: 0.0654 - val_mse: 0.0654\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 33s 258ms/step - loss: 0.0715 - mse: 0.0715 - val_loss: 0.0638 - val_mse: 0.0638\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 33s 257ms/step - loss: 0.0716 - mse: 0.0716 - val_loss: 0.0579 - val_mse: 0.0579\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 33s 255ms/step - loss: 0.0706 - mse: 0.0706 - val_loss: 0.0568 - val_mse: 0.0568\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 33s 254ms/step - loss: 0.0701 - mse: 0.0701 - val_loss: 0.0557 - val_mse: 0.0557\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 34s 265ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 0.0519 - val_mse: 0.0519\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 33s 255ms/step - loss: 0.0678 - mse: 0.0678 - val_loss: 0.0625 - val_mse: 0.0625\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 39s 301ms/step - loss: 0.0658 - mse: 0.0658 - val_loss: 0.0498 - val_mse: 0.0498\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 38s 297ms/step - loss: 0.0612 - mse: 0.0612 - val_loss: 0.0478 - val_mse: 0.0478\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 38s 297ms/step - loss: 0.0612 - mse: 0.0612 - val_loss: 0.0555 - val_mse: 0.0555\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 33s 255ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0425 - val_mse: 0.0425\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 33s 255ms/step - loss: 0.0581 - mse: 0.0581 - val_loss: 0.0439 - val_mse: 0.0439\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 33s 254ms/step - loss: 0.0562 - mse: 0.0562 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 33s 258ms/step - loss: 0.0595 - mse: 0.0595 - val_loss: 0.0440 - val_mse: 0.0440\n"
     ]
    }
   ],
   "source": [
    "# iterations over the model parameter configurations are done for both LSTM as well as RNN model\n",
    "model_types = ['LSTM', 'RNN']\n",
    "\n",
    "# set number of steps per epoch\n",
    "num_samples = mdq._num_samples\n",
    "steps_per_epoch = int(num_samples/future_target_size)\n",
    "validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "# initialize results dictionary\n",
    "res = {'model_type': [], 'epochs': [], 'num_layers': [], 'units': [], 'val_mse': []\n",
    "       , 'mse': [], 'total_training_time': []}\n",
    "\n",
    "for units, num_layers, epochs in config_generator():\n",
    "    for model_type in model_types:\n",
    "\n",
    "        print('currently running {} model'.format(model_type))\n",
    "\n",
    "        # compile model\n",
    "        mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "        # fit model\n",
    "        mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "                      ,validation_steps=validation_steps, model_type=model_type)\n",
    "        \n",
    "        # get errors\n",
    "        history = mdq._histories[model_type]\n",
    "        val_mse = history.history['val_mse'][-1]\n",
    "        mse = history.history['mse'][-1]\n",
    "        \n",
    "        # get total training time\n",
    "        total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "        \n",
    "        # append results to results dictionary\n",
    "        res['model_type'].append(model_type)\n",
    "        res['epochs'].append(epochs)\n",
    "        res['num_layers'].append(num_layers)\n",
    "        res['units'].append(units)\n",
    "        res['val_mse'].append(val_mse)\n",
    "        res['mse'].append(mse)\n",
    "        res['total_training_time'].append(total_training_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part4_link'></a>\n",
    "# 4. Visualize and save results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are stored locally in a .csv file and the model performance as a function of number of units and epochs plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform dictionary to dataframe\n",
    "df_res = pd.DataFrame(res)\n",
    "\n",
    "# store dataframe as csv locally\n",
    "df_res.to_csv('../data/02_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize results; use bubble plots to indicate magnitude of mean-square error for specific configuration comparing\n",
    "# RNN to LSTM results\n",
    "\n",
    "x_label = 'epochs'\n",
    "y_label = 'units'\n",
    "z_label = 'mse'\n",
    "\n",
    "for model_type in model_types:\n",
    "    condition_1 = (df_res['model_type']== model_type)\n",
    "    \n",
    "    x = df_res[condition_1][x_label].values\n",
    "    y = df_res[condition_1][y_label].values\n",
    "    \n",
    "    z = df_res[condition_1][z_label].values\n",
    "    plt.scatter(x, y, s=z*10000, alpha=0.6, c=\"red\", linewidth=0.0)\n",
    "        \n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title('mean-square training error: {} model'.format(model_type))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
