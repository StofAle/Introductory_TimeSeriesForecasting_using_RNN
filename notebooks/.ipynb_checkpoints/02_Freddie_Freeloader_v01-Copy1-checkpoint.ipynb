{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "#### In this notebook, the trial runs from the preceding notebook ('01_So_What.ipynb') are systematically extended to try to find an optimal configuration for the two models. The model parameters to be fine tuned are: number of epochs, number of layers and the number of units.\n",
    "\n",
    "#### The best performing model configuration will be used in the notebook '03_Blue_in_Green.ipynb' to analyze the impact of adding noise to the clean dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [1. Load modules](#Part1_link)\n",
    "* [2. Setup data](#Part2_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.1  Generate data, separate testing and validation set and standardize testing data](#Part2.1_link)\n",
    "* [3. Setup models and evaluate for various hyper-parameter choices](#Part3_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.1 Compile and fit LSTM and RNN model](#Part3.1_link)\n",
    "* [4. Visualize results](#Part4_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part1_link'></a>\n",
    "# 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import Kind_of_Blue  # own class with a collection of methods used in this analysis\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2_link'></a>\n",
    "# 2. Setup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.1_link'></a>\n",
    "### 2.1 Generate data, separate testing and validation set and standardize testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps are repeated from the previous notebook, '01_So_What.ipynb', and are grouped into one single step here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations in time series: 1820\n",
      "train split ratio =  0.7\n",
      "loaded data set length: 1820\n",
      "mean: 0.0, std: 1.0\n",
      "training set shape: x:(909, 365, 1), y:(909, 7, 1)\n",
      "validation set shape: x:(174, 365, 1), y:(174, 7, 1)\n",
      "number of training samples: 909\n"
     ]
    }
   ],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=5*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 10  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "print('number of observations in time series: {}'.format(len(observations)))\n",
    "\n",
    "# initialize dataframe to store time series\n",
    "df = pd.DataFrame(data=observations, columns=['observations'])\n",
    "df.index = idx\n",
    "\n",
    "# initialize object\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# load dataframe into object\n",
    "mdq._selected_features = ['observations']\n",
    "mdq.df = df\n",
    "\n",
    "# train-validation split ratio as class attribute set to 70%\n",
    "print('train split ratio = ', mdq.TRAIN_SPLIT_RATIO)\n",
    "\n",
    "# initialize dataset from dataframe \n",
    "mdq.initialize_dataset()\n",
    "print('loaded data set length: {}'.format(len(mdq._dataset)))\n",
    "\n",
    "# standardize data\n",
    "mdq.standardize_data()\n",
    "\n",
    "# check that mean equals zero and the standard deviation is one\n",
    "print('mean: {}, std: {}'.format(round(np.mean(mdq._dataset), 2), round(np.std(mdq._dataset), 2)))\n",
    "\n",
    "# set number of time points for 1/ future forecasting points and 2/ the past, historical time points\n",
    "future_target_size = int(365/52)\n",
    "past_history_size = int(1*365)\n",
    "\n",
    "# set batch size\n",
    "batch_size = 32\n",
    "\n",
    "# generate train and validation data\n",
    "mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size\n",
    "                                , batch_size=batch_size)\n",
    "\n",
    "print('number of training samples: {}'.format(mdq._num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3_link'></a>\n",
    "# 3. Setup models and evaluate for various hyper-parameter choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.1_link'></a>\n",
    "### 3.1 Compile and fit LSTM and RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator for configurations to be iterated over\n",
    "\n",
    "def config_generator():\n",
    "    \n",
    "    unit_choices = [500, 700, 1500]  # number of units in each neural network layer\n",
    "    layer_choices = [2]  # total number of layers\n",
    "    epoch_choices = [30, 100]  # number of epochs the model is trained on\n",
    "    \n",
    "    for units in unit_choices:\n",
    "        for num_layers in layer_choices:\n",
    "            for epochs in epoch_choices:\n",
    "                yield units, num_layers, epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently running RNN model with units, num_layers, epochs as 500, 2, 30\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 132s 1s/step - loss: 0.6267 - mse: 0.6267 - val_loss: 0.2603 - val_mse: 0.2603\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 136s 1s/step - loss: 0.1896 - mse: 0.1896 - val_loss: 0.0609 - val_mse: 0.0609\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 140s 1s/step - loss: 0.0734 - mse: 0.0734 - val_loss: 0.0903 - val_mse: 0.0903\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 133s 1s/step - loss: 0.0751 - mse: 0.0751 - val_loss: 0.0408 - val_mse: 0.0408\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 113s 876ms/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0898 - val_mse: 0.0898\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 115s 894ms/step - loss: 0.0634 - mse: 0.0634 - val_loss: 0.0586 - val_mse: 0.0586\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 118s 913ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0756 - val_mse: 0.0756\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 124s 962ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0369 - val_mse: 0.0369\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 115s 894ms/step - loss: 0.0574 - mse: 0.0574 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 144s 1s/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 186s 1s/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0294 - val_mse: 0.0294\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 144s 1s/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0256 - val_mse: 0.0256\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 146s 1s/step - loss: 0.0456 - mse: 0.0456 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 147s 1s/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 153s 1s/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 154s 1s/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.0886 - val_mse: 0.0886\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 165s 1s/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0546 - val_mse: 0.0546\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 159s 1s/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0519 - val_mse: 0.0519\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 161s 1s/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 167s 1s/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0098 - val_mse: 0.0098\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 161s 1s/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 158s 1s/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 162s 1s/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 166s 1s/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 159s 1s/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 161s 1s/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 166s 1s/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 164s 1s/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 158s 1s/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0143 - val_mse: 0.0143\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 157s 1s/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0811 - val_mse: 0.0811\n",
      "currently running RNN model with units, num_layers, epochs as 500, 2, 100\n",
      "Epoch 1/100\n",
      "129/129 [==============================] - 167s 1s/step - loss: 1.7026 - mse: 1.7026 - val_loss: 0.3173 - val_mse: 0.3173\n",
      "Epoch 2/100\n",
      "129/129 [==============================] - 160s 1s/step - loss: 0.5453 - mse: 0.5453 - val_loss: 0.0678 - val_mse: 0.0678\n",
      "Epoch 3/100\n",
      "129/129 [==============================] - 157s 1s/step - loss: 0.0961 - mse: 0.0961 - val_loss: 0.0655 - val_mse: 0.0655\n",
      "Epoch 4/100\n",
      "129/129 [==============================] - 176s 1s/step - loss: 0.0910 - mse: 0.0910 - val_loss: 0.0672 - val_mse: 0.0672\n",
      "Epoch 5/100\n",
      "129/129 [==============================] - 216s 2s/step - loss: 0.0874 - mse: 0.0874 - val_loss: 0.0689 - val_mse: 0.0689\n",
      "Epoch 6/100\n",
      "129/129 [==============================] - 160s 1s/step - loss: 0.0819 - mse: 0.0819 - val_loss: 0.0645 - val_mse: 0.0645\n",
      "Epoch 7/100\n",
      "129/129 [==============================] - 160s 1s/step - loss: 0.0834 - mse: 0.0834 - val_loss: 0.0638 - val_mse: 0.0638\n",
      "Epoch 8/100\n",
      "129/129 [==============================] - 165s 1s/step - loss: 0.0837 - mse: 0.0837 - val_loss: 0.0669 - val_mse: 0.0669\n",
      "Epoch 9/100\n",
      "129/129 [==============================] - 160s 1s/step - loss: 0.0810 - mse: 0.0810 - val_loss: 0.0678 - val_mse: 0.0678\n",
      "Epoch 10/100\n",
      "129/129 [==============================] - 157s 1s/step - loss: 0.0849 - mse: 0.0849 - val_loss: 0.0666 - val_mse: 0.0666\n",
      "Epoch 11/100\n",
      "129/129 [==============================] - 161s 1s/step - loss: 0.0821 - mse: 0.0821 - val_loss: 0.0710 - val_mse: 0.0710\n",
      "Epoch 12/100\n",
      "129/129 [==============================] - 165s 1s/step - loss: 0.0825 - mse: 0.0825 - val_loss: 0.0690 - val_mse: 0.0690\n",
      "Epoch 13/100\n",
      "129/129 [==============================] - 158s 1s/step - loss: 0.0844 - mse: 0.0844 - val_loss: 0.0711 - val_mse: 0.0711\n",
      "Epoch 14/100\n",
      "129/129 [==============================] - 155s 1s/step - loss: 0.0802 - mse: 0.0802 - val_loss: 0.0648 - val_mse: 0.0648\n",
      "Epoch 15/100\n",
      "129/129 [==============================] - 162s 1s/step - loss: 0.0815 - mse: 0.0815 - val_loss: 0.0659 - val_mse: 0.0659\n",
      "Epoch 16/100\n",
      "129/129 [==============================] - 163s 1s/step - loss: 0.0730 - mse: 0.0730 - val_loss: 0.0540 - val_mse: 0.0540\n",
      "Epoch 17/100\n",
      "129/129 [==============================] - 158s 1s/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.0485 - val_mse: 0.0485\n",
      "Epoch 18/100\n",
      "129/129 [==============================] - 154s 1s/step - loss: 0.0591 - mse: 0.0591 - val_loss: 0.0456 - val_mse: 0.0456\n",
      "Epoch 19/100\n",
      "129/129 [==============================] - 164s 1s/step - loss: 0.0611 - mse: 0.0611 - val_loss: 0.0477 - val_mse: 0.0477\n",
      "Epoch 20/100\n",
      "129/129 [==============================] - 158s 1s/step - loss: 0.0586 - mse: 0.0586 - val_loss: 0.0453 - val_mse: 0.0453\n",
      "Epoch 21/100\n",
      "129/129 [==============================] - 155s 1s/step - loss: 0.0551 - mse: 0.0551 - val_loss: 0.0509 - val_mse: 0.0509\n",
      "Epoch 22/100\n",
      "129/129 [==============================] - 158s 1s/step - loss: 0.0584 - mse: 0.0584 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 23/100\n",
      "129/129 [==============================] - 162s 1s/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0687 - val_mse: 0.0687\n",
      "Epoch 24/100\n",
      "129/129 [==============================] - 158s 1s/step - loss: 0.0571 - mse: 0.0571 - val_loss: 0.0567 - val_mse: 0.0567\n",
      "Epoch 25/100\n",
      "129/129 [==============================] - 157s 1s/step - loss: 0.0586 - mse: 0.0586 - val_loss: 0.0441 - val_mse: 0.0441\n",
      "Epoch 26/100\n",
      "129/129 [==============================] - 161s 1s/step - loss: 0.0588 - mse: 0.0588 - val_loss: 0.0470 - val_mse: 0.0470\n",
      "Epoch 27/100\n",
      "129/129 [==============================] - 162s 1s/step - loss: 0.0581 - mse: 0.0581 - val_loss: 0.0472 - val_mse: 0.0472\n",
      "Epoch 28/100\n",
      "129/129 [==============================] - 166s 1s/step - loss: 0.0593 - mse: 0.0593 - val_loss: 0.0507 - val_mse: 0.0507\n",
      "Epoch 29/100\n",
      "129/129 [==============================] - 167s 1s/step - loss: 0.0645 - mse: 0.0645 - val_loss: 0.0526 - val_mse: 0.0526\n",
      "Epoch 30/100\n",
      "129/129 [==============================] - 120s 930ms/step - loss: 0.0622 - mse: 0.0622 - val_loss: 0.0622 - val_mse: 0.0622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "129/129 [==============================] - 114s 885ms/step - loss: 0.0627 - mse: 0.0627 - val_loss: 0.0666 - val_mse: 0.0666\n",
      "Epoch 32/100\n",
      "129/129 [==============================] - 112s 869ms/step - loss: 0.0608 - mse: 0.0608 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 33/100\n",
      "129/129 [==============================] - 112s 869ms/step - loss: 0.0532 - mse: 0.0532 - val_loss: 0.0347 - val_mse: 0.0347\n",
      "Epoch 34/100\n",
      "129/129 [==============================] - 113s 876ms/step - loss: 0.0509 - mse: 0.0509 - val_loss: 0.0515 - val_mse: 0.0515\n",
      "Epoch 35/100\n",
      "129/129 [==============================] - 117s 910ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.0826 - val_mse: 0.0826\n",
      "Epoch 36/100\n",
      "129/129 [==============================] - 116s 896ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0335 - val_mse: 0.0335\n",
      "Epoch 37/100\n",
      "129/129 [==============================] - 112s 869ms/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.0336 - val_mse: 0.0336\n",
      "Epoch 38/100\n",
      "129/129 [==============================] - 112s 867ms/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0268 - val_mse: 0.0268\n",
      "Epoch 39/100\n",
      "129/129 [==============================] - 113s 875ms/step - loss: 0.0453 - mse: 0.0453 - val_loss: 0.0383 - val_mse: 0.0383\n",
      "Epoch 40/100\n",
      "129/129 [==============================] - 116s 898ms/step - loss: 0.0484 - mse: 0.0484 - val_loss: 0.0317 - val_mse: 0.0317\n",
      "Epoch 41/100\n",
      "129/129 [==============================] - 117s 911ms/step - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 42/100\n",
      "129/129 [==============================] - 117s 904ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 43/100\n",
      "129/129 [==============================] - 112s 866ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0539 - val_mse: 0.0539\n",
      "Epoch 44/100\n",
      "129/129 [==============================] - 112s 865ms/step - loss: 3.8204 - mse: 3.8204 - val_loss: 1.4174 - val_mse: 1.4174\n",
      "Epoch 45/100\n",
      "129/129 [==============================] - 113s 873ms/step - loss: 1.0320 - mse: 1.0320 - val_loss: 0.9515 - val_mse: 0.9515\n",
      "Epoch 46/100\n",
      "129/129 [==============================] - 117s 910ms/step - loss: 0.4945 - mse: 0.4945 - val_loss: 0.1074 - val_mse: 0.1074\n",
      "Epoch 47/100\n",
      "129/129 [==============================] - 110s 851ms/step - loss: 0.1419 - mse: 0.1419 - val_loss: 0.2048 - val_mse: 0.2048\n",
      "Epoch 48/100\n",
      "129/129 [==============================] - 111s 859ms/step - loss: 0.1087 - mse: 0.1087 - val_loss: 0.0640 - val_mse: 0.0640\n",
      "Epoch 49/100\n",
      "129/129 [==============================] - 109s 848ms/step - loss: 0.0968 - mse: 0.0968 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 50/100\n",
      "129/129 [==============================] - 109s 845ms/step - loss: 0.0837 - mse: 0.0837 - val_loss: 0.0664 - val_mse: 0.0664\n",
      "Epoch 51/100\n",
      "129/129 [==============================] - 116s 899ms/step - loss: 0.0788 - mse: 0.0788 - val_loss: 0.0418 - val_mse: 0.0418\n",
      "Epoch 52/100\n",
      "129/129 [==============================] - 110s 851ms/step - loss: 0.0749 - mse: 0.0749 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 53/100\n",
      "129/129 [==============================] - 110s 850ms/step - loss: 0.0702 - mse: 0.0702 - val_loss: 0.0432 - val_mse: 0.0432\n",
      "Epoch 54/100\n",
      "129/129 [==============================] - 108s 840ms/step - loss: 0.0672 - mse: 0.0672 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 55/100\n",
      "129/129 [==============================] - 109s 843ms/step - loss: 0.0641 - mse: 0.0641 - val_loss: 0.0353 - val_mse: 0.0353\n",
      "Epoch 56/100\n",
      "129/129 [==============================] - 111s 862ms/step - loss: 0.0634 - mse: 0.0634 - val_loss: 0.0376 - val_mse: 0.0376\n",
      "Epoch 57/100\n",
      "129/129 [==============================] - 113s 877ms/step - loss: 0.0637 - mse: 0.0637 - val_loss: 0.0462 - val_mse: 0.0462\n",
      "Epoch 58/100\n",
      "129/129 [==============================] - 109s 844ms/step - loss: 0.0583 - mse: 0.0583 - val_loss: 0.0586 - val_mse: 0.0586\n",
      "Epoch 59/100\n",
      "129/129 [==============================] - 109s 848ms/step - loss: 0.0602 - mse: 0.0602 - val_loss: 0.0603 - val_mse: 0.0603\n",
      "Epoch 60/100\n",
      "129/129 [==============================] - 109s 846ms/step - loss: 0.0625 - mse: 0.0625 - val_loss: 0.0460 - val_mse: 0.0460\n",
      "Epoch 61/100\n",
      "129/129 [==============================] - 109s 846ms/step - loss: 0.0608 - mse: 0.0608 - val_loss: 0.0611 - val_mse: 0.0611\n",
      "Epoch 62/100\n",
      "129/129 [==============================] - 147s 1s/step - loss: 0.0604 - mse: 0.0604 - val_loss: 0.0488 - val_mse: 0.0488\n",
      "Epoch 63/100\n",
      "129/129 [==============================] - 116s 896ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 64/100\n",
      "129/129 [==============================] - 112s 871ms/step - loss: 0.0555 - mse: 0.0555 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 65/100\n",
      "129/129 [==============================] - 108s 837ms/step - loss: 0.0559 - mse: 0.0559 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 66/100\n",
      "129/129 [==============================] - 109s 846ms/step - loss: 0.0582 - mse: 0.0582 - val_loss: 0.0292 - val_mse: 0.0292\n",
      "Epoch 67/100\n",
      "129/129 [==============================] - 115s 895ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 0.0450 - val_mse: 0.0450\n",
      "Epoch 68/100\n",
      "129/129 [==============================] - 109s 845ms/step - loss: 0.0550 - mse: 0.0550 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 69/100\n",
      "129/129 [==============================] - 108s 836ms/step - loss: 0.0555 - mse: 0.0555 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 70/100\n",
      "129/129 [==============================] - 108s 835ms/step - loss: 0.0550 - mse: 0.0550 - val_loss: 0.0308 - val_mse: 0.0308\n",
      "Epoch 71/100\n",
      "129/129 [==============================] - 99s 764ms/step - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0307 - val_mse: 0.0307\n",
      "Epoch 72/100\n",
      "129/129 [==============================] - 68s 529ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 73/100\n",
      "129/129 [==============================] - 74s 577ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0300 - val_mse: 0.0300\n",
      "Epoch 74/100\n",
      "129/129 [==============================] - 70s 541ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0344 - val_mse: 0.0344\n",
      "Epoch 75/100\n",
      "129/129 [==============================] - 66s 509ms/step - loss: 0.0487 - mse: 0.0487 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 76/100\n",
      "129/129 [==============================] - 69s 538ms/step - loss: 0.0519 - mse: 0.0519 - val_loss: 0.0328 - val_mse: 0.0328\n",
      "Epoch 77/100\n",
      "129/129 [==============================] - 68s 525ms/step - loss: 0.0478 - mse: 0.0478 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 78/100\n",
      "129/129 [==============================] - 69s 534ms/step - loss: 0.0514 - mse: 0.0514 - val_loss: 0.0362 - val_mse: 0.0362\n",
      "Epoch 79/100\n",
      "129/129 [==============================] - 65s 505ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0345 - val_mse: 0.0345\n",
      "Epoch 80/100\n",
      "129/129 [==============================] - 69s 532ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0736 - val_mse: 0.0736\n",
      "Epoch 81/100\n",
      "129/129 [==============================] - 75s 583ms/step - loss: 0.0436 - mse: 0.0436 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 82/100\n",
      "129/129 [==============================] - 69s 533ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0270 - val_mse: 0.0270\n",
      "Epoch 83/100\n",
      "129/129 [==============================] - 66s 509ms/step - loss: 0.0524 - mse: 0.0524 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 84/100\n",
      "129/129 [==============================] - 68s 525ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 85/100\n",
      "129/129 [==============================] - 67s 516ms/step - loss: 0.0447 - mse: 0.0447 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 86/100\n",
      "129/129 [==============================] - 67s 522ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 87/100\n",
      "129/129 [==============================] - 68s 523ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 88/100\n",
      "129/129 [==============================] - 67s 517ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 89/100\n",
      "129/129 [==============================] - 68s 529ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 75s 584ms/step - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 91/100\n",
      "129/129 [==============================] - 66s 510ms/step - loss: 0.0439 - mse: 0.0439 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 92/100\n",
      "129/129 [==============================] - 67s 517ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 93/100\n",
      "129/129 [==============================] - 68s 526ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0363 - val_mse: 0.0363\n",
      "Epoch 94/100\n",
      "129/129 [==============================] - 67s 516ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 95/100\n",
      "129/129 [==============================] - 66s 513ms/step - loss: 0.0377 - mse: 0.0377 - val_loss: 0.0285 - val_mse: 0.0285\n",
      "Epoch 96/100\n",
      "129/129 [==============================] - 66s 509ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 97/100\n",
      "129/129 [==============================] - 66s 510ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 98/100\n",
      "129/129 [==============================] - 70s 542ms/step - loss: 0.0345 - mse: 0.0345 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 99/100\n",
      "129/129 [==============================] - 74s 576ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 100/100\n",
      "129/129 [==============================] - 68s 528ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "currently running RNN model with units, num_layers, epochs as 700, 2, 30\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 113s 875ms/step - loss: 0.4238 - mse: 0.4238 - val_loss: 0.1424 - val_mse: 0.1424\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 111s 858ms/step - loss: 0.1444 - mse: 0.1444 - val_loss: 0.0760 - val_mse: 0.0760\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 112s 867ms/step - loss: 0.0999 - mse: 0.0999 - val_loss: 0.0765 - val_mse: 0.0765\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 113s 879ms/step - loss: 0.0727 - mse: 0.0727 - val_loss: 0.0566 - val_mse: 0.0566\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 117s 907ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.1252 - val_mse: 0.1252\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 119s 926ms/step - loss: 0.0554 - mse: 0.0554 - val_loss: 0.1014 - val_mse: 0.1014\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 113s 880ms/step - loss: 0.0767 - mse: 0.0767 - val_loss: 0.0431 - val_mse: 0.0431\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 107s 829ms/step - loss: 0.0499 - mse: 0.0499 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 116s 900ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 123s 952ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 111s 864ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 115s 890ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 107s 830ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 114s 883ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0084 - val_mse: 0.0084\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 119s 926ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 112s 866ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 114s 883ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 114s 882ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 113s 875ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0126 - val_mse: 0.0126\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 123s 952ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0180 - val_mse: 0.0180\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 114s 880ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 112s 865ms/step - loss: 0.0693 - mse: 0.0693 - val_loss: 0.0343 - val_mse: 0.0343\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 112s 871ms/step - loss: 0.0316 - mse: 0.0316 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 114s 885ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 109s 846ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 119s 925ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0135 - val_mse: 0.0135\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 115s 889ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 109s 847ms/step - loss: 0.0497 - mse: 0.0497 - val_loss: 0.0264 - val_mse: 0.0264\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 110s 855ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 111s 863ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "currently running RNN model with units, num_layers, epochs as 700, 2, 100\n",
      "Epoch 1/100\n",
      "129/129 [==============================] - 117s 910ms/step - loss: 1.2646 - mse: 1.2646 - val_loss: 0.1862 - val_mse: 0.1862\n",
      "Epoch 2/100\n",
      "129/129 [==============================] - 111s 861ms/step - loss: 0.2037 - mse: 0.2037 - val_loss: 0.1627 - val_mse: 0.1627\n",
      "Epoch 3/100\n",
      "129/129 [==============================] - 110s 854ms/step - loss: 0.1780 - mse: 0.1780 - val_loss: 0.1854 - val_mse: 0.1854\n",
      "Epoch 4/100\n",
      "129/129 [==============================] - 108s 835ms/step - loss: 0.1890 - mse: 0.1890 - val_loss: 0.1592 - val_mse: 0.1592\n",
      "Epoch 5/100\n",
      "129/129 [==============================] - 111s 864ms/step - loss: 0.1916 - mse: 0.1916 - val_loss: 0.1694 - val_mse: 0.1694\n",
      "Epoch 6/100\n",
      "129/129 [==============================] - 118s 912ms/step - loss: 0.2013 - mse: 0.2013 - val_loss: 0.1765 - val_mse: 0.1765\n",
      "Epoch 7/100\n",
      "129/129 [==============================] - 111s 861ms/step - loss: 0.1948 - mse: 0.1948 - val_loss: 0.1716 - val_mse: 0.1716\n",
      "Epoch 8/100\n",
      "129/129 [==============================] - 123s 952ms/step - loss: 0.1806 - mse: 0.1806 - val_loss: 0.1418 - val_mse: 0.1418\n",
      "Epoch 9/100\n",
      "129/129 [==============================] - 110s 851ms/step - loss: 0.1759 - mse: 0.1759 - val_loss: 0.1459 - val_mse: 0.1459\n",
      "Epoch 10/100\n",
      "129/129 [==============================] - 113s 877ms/step - loss: 0.1695 - mse: 0.1695 - val_loss: 0.1320 - val_mse: 0.1320\n",
      "Epoch 11/100\n",
      "129/129 [==============================] - 116s 899ms/step - loss: 0.1494 - mse: 0.1494 - val_loss: 0.1465 - val_mse: 0.1465\n",
      "Epoch 12/100\n",
      "129/129 [==============================] - 113s 873ms/step - loss: 0.1445 - mse: 0.1445 - val_loss: 0.1143 - val_mse: 0.1143\n",
      "Epoch 13/100\n",
      "129/129 [==============================] - 114s 887ms/step - loss: 0.1118 - mse: 0.1118 - val_loss: 0.0858 - val_mse: 0.0858\n",
      "Epoch 14/100\n",
      "129/129 [==============================] - 113s 876ms/step - loss: 0.0804 - mse: 0.0804 - val_loss: 0.0551 - val_mse: 0.0551\n",
      "Epoch 15/100\n",
      "129/129 [==============================] - 112s 868ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.0571 - val_mse: 0.0571\n",
      "Epoch 16/100\n",
      "129/129 [==============================] - 115s 888ms/step - loss: 0.0716 - mse: 0.0716 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 17/100\n",
      "129/129 [==============================] - 119s 926ms/step - loss: 0.0652 - mse: 0.0652 - val_loss: 0.0554 - val_mse: 0.0554\n",
      "Epoch 18/100\n",
      "129/129 [==============================] - 115s 893ms/step - loss: 0.0688 - mse: 0.0688 - val_loss: 0.0547 - val_mse: 0.0547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "129/129 [==============================] - 110s 852ms/step - loss: 0.0658 - mse: 0.0658 - val_loss: 0.0361 - val_mse: 0.0361\n",
      "Epoch 20/100\n",
      "129/129 [==============================] - 112s 868ms/step - loss: 0.0573 - mse: 0.0573 - val_loss: 0.0605 - val_mse: 0.0605\n",
      "Epoch 21/100\n",
      "129/129 [==============================] - 110s 852ms/step - loss: 0.0581 - mse: 0.0581 - val_loss: 0.0392 - val_mse: 0.0392\n",
      "Epoch 22/100\n",
      "129/129 [==============================] - 118s 917ms/step - loss: 0.0612 - mse: 0.0612 - val_loss: 0.0359 - val_mse: 0.0359\n",
      "Epoch 23/100\n",
      "129/129 [==============================] - 111s 857ms/step - loss: 0.0518 - mse: 0.0518 - val_loss: 0.0601 - val_mse: 0.0601\n",
      "Epoch 24/100\n",
      "129/129 [==============================] - 112s 870ms/step - loss: 0.0619 - mse: 0.0619 - val_loss: 0.0421 - val_mse: 0.0421\n",
      "Epoch 25/100\n",
      "129/129 [==============================] - 111s 861ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0389 - val_mse: 0.0389\n",
      "Epoch 26/100\n",
      "129/129 [==============================] - 111s 863ms/step - loss: 0.0513 - mse: 0.0513 - val_loss: 0.0457 - val_mse: 0.0457\n",
      "Epoch 27/100\n",
      "129/129 [==============================] - 122s 945ms/step - loss: 0.0662 - mse: 0.0662 - val_loss: 0.0598 - val_mse: 0.0598\n",
      "Epoch 28/100\n",
      "129/129 [==============================] - 112s 868ms/step - loss: 0.0504 - mse: 0.0504 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 29/100\n",
      "129/129 [==============================] - 110s 853ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0280 - val_mse: 0.0280\n",
      "Epoch 30/100\n",
      "129/129 [==============================] - 110s 849ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0427 - val_mse: 0.0427\n",
      "Epoch 31/100\n",
      "129/129 [==============================] - 109s 844ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0302 - val_mse: 0.0302\n",
      "Epoch 32/100\n",
      "129/129 [==============================] - 115s 893ms/step - loss: 0.0432 - mse: 0.0432 - val_loss: 0.0221 - val_mse: 0.0221\n",
      "Epoch 33/100\n",
      "129/129 [==============================] - 115s 892ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 34/100\n",
      "129/129 [==============================] - 112s 872ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 35/100\n",
      "129/129 [==============================] - 110s 853ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 36/100\n",
      "129/129 [==============================] - 113s 876ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 37/100\n",
      "129/129 [==============================] - 115s 892ms/step - loss: 0.0247 - mse: 0.0247 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 38/100\n",
      "129/129 [==============================] - 121s 942ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 39/100\n",
      "129/129 [==============================] - 113s 875ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 40/100\n",
      "129/129 [==============================] - 124s 962ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 41/100\n",
      "129/129 [==============================] - 112s 872ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 42/100\n",
      "129/129 [==============================] - 114s 880ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 43/100\n",
      "129/129 [==============================] - 123s 952ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 44/100\n",
      "129/129 [==============================] - 114s 881ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 45/100\n",
      "129/129 [==============================] - 112s 865ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 46/100\n",
      "129/129 [==============================] - 112s 869ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 47/100\n",
      "129/129 [==============================] - 117s 904ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 48/100\n",
      "129/129 [==============================] - 122s 946ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 49/100\n",
      "129/129 [==============================] - 115s 893ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0103 - val_mse: 0.0103\n",
      "Epoch 50/100\n",
      "129/129 [==============================] - 112s 871ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 51/100\n",
      "129/129 [==============================] - 110s 854ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 52/100\n",
      "129/129 [==============================] - 113s 874ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 53/100\n",
      "129/129 [==============================] - 118s 911ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 54/100\n",
      "129/129 [==============================] - 111s 857ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 55/100\n",
      "129/129 [==============================] - 113s 877ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 56/100\n",
      "129/129 [==============================] - 114s 883ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 57/100\n",
      "129/129 [==============================] - 110s 850ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 58/100\n",
      "129/129 [==============================] - 119s 920ms/step - loss: 0.0429 - mse: 0.0429 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 59/100\n",
      "129/129 [==============================] - 116s 899ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0668 - val_mse: 0.0668\n",
      "Epoch 60/100\n",
      "129/129 [==============================] - 112s 865ms/step - loss: 0.0344 - mse: 0.0344 - val_loss: 0.0150 - val_mse: 0.0150\n",
      "Epoch 61/100\n",
      "129/129 [==============================] - 113s 873ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 62/100\n",
      "129/129 [==============================] - 112s 869ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 63/100\n",
      "129/129 [==============================] - 112s 868ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 64/100\n",
      "129/129 [==============================] - 121s 940ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 65/100\n",
      "129/129 [==============================] - 112s 866ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 66/100\n",
      "129/129 [==============================] - 111s 864ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 67/100\n",
      "129/129 [==============================] - 113s 879ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 68/100\n",
      "129/129 [==============================] - 114s 884ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 69/100\n",
      "129/129 [==============================] - 119s 922ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 70/100\n",
      "129/129 [==============================] - 113s 876ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 71/100\n",
      "129/129 [==============================] - 115s 893ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 72/100\n",
      "129/129 [==============================] - 122s 943ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 73/100\n",
      "129/129 [==============================] - 114s 884ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0097 - val_mse: 0.0097\n",
      "Epoch 74/100\n",
      "129/129 [==============================] - 118s 913ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 75/100\n",
      "129/129 [==============================] - 110s 851ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 76/100\n",
      "129/129 [==============================] - 113s 877ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 77/100\n",
      "129/129 [==============================] - 114s 886ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 113s 874ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0075 - val_mse: 0.0075\n",
      "Epoch 79/100\n",
      "129/129 [==============================] - 121s 940ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 7.4079e-04 - val_mse: 7.4079e-04\n",
      "Epoch 80/100\n",
      "129/129 [==============================] - 114s 882ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 81/100\n",
      "129/129 [==============================] - 114s 880ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 82/100\n",
      "129/129 [==============================] - 111s 862ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 83/100\n",
      "129/129 [==============================] - 110s 854ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0073 - val_mse: 0.0073\n",
      "Epoch 84/100\n",
      "129/129 [==============================] - 112s 866ms/step - loss: 0.8455 - mse: 0.8455 - val_loss: 5.6963 - val_mse: 5.6963\n",
      "Epoch 85/100\n",
      "129/129 [==============================] - 120s 927ms/step - loss: 0.4692 - mse: 0.4692 - val_loss: 0.1654 - val_mse: 0.1654\n",
      "Epoch 86/100\n",
      "129/129 [==============================] - 109s 845ms/step - loss: 0.1442 - mse: 0.1442 - val_loss: 0.0707 - val_mse: 0.0707\n",
      "Epoch 87/100\n",
      "129/129 [==============================] - 108s 840ms/step - loss: 0.0661 - mse: 0.0661 - val_loss: 0.0653 - val_mse: 0.0653\n",
      "Epoch 88/100\n",
      "129/129 [==============================] - 109s 842ms/step - loss: 0.0455 - mse: 0.0455 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 89/100\n",
      "129/129 [==============================] - 109s 843ms/step - loss: 0.0480 - mse: 0.0480 - val_loss: 0.0413 - val_mse: 0.0413\n",
      "Epoch 90/100\n",
      "129/129 [==============================] - 117s 908ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.0381 - val_mse: 0.0381\n",
      "Epoch 91/100\n",
      "129/129 [==============================] - 112s 872ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.0306 - val_mse: 0.0306\n",
      "Epoch 92/100\n",
      "129/129 [==============================] - 110s 855ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0265 - val_mse: 0.0265\n",
      "Epoch 93/100\n",
      "129/129 [==============================] - 112s 864ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0331 - val_mse: 0.0331\n",
      "Epoch 94/100\n",
      "129/129 [==============================] - 110s 856ms/step - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 95/100\n",
      "129/129 [==============================] - 117s 910ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0382 - val_mse: 0.0382\n",
      "Epoch 96/100\n",
      "129/129 [==============================] - 108s 835ms/step - loss: 0.0448 - mse: 0.0448 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 97/100\n",
      "129/129 [==============================] - 110s 849ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0326 - val_mse: 0.0326\n",
      "Epoch 98/100\n",
      "129/129 [==============================] - 112s 865ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0438 - val_mse: 0.0438\n",
      "Epoch 99/100\n",
      "129/129 [==============================] - 110s 856ms/step - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0358 - val_mse: 0.0358\n",
      "Epoch 100/100\n",
      "129/129 [==============================] - 108s 837ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0419 - val_mse: 0.0419\n",
      "currently running RNN model with units, num_layers, epochs as 1500, 2, 30\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 462s 4s/step - loss: 4.1198 - mse: 4.1198 - val_loss: 0.1447 - val_mse: 0.1447\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 452s 4s/step - loss: 0.1768 - mse: 0.1768 - val_loss: 0.0813 - val_mse: 0.0813\n",
      "Epoch 3/30\n",
      " 25/129 [====>.........................] - ETA: 4:19 - loss: 0.1170 - mse: 0.1170"
     ]
    }
   ],
   "source": [
    "# iterations over the model parameter configurations are done for both LSTM as well as RNN model\n",
    "# model_types = ['LSTM', 'RNN']\n",
    "model_types = ['RNN']\n",
    "\n",
    "# set number of steps per epoch\n",
    "num_samples = mdq._num_samples\n",
    "steps_per_epoch = int(num_samples/future_target_size)\n",
    "validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "# initialize results dictionary\n",
    "res = {'model_type': [], 'epochs': [], 'num_layers': [], 'units': [], 'val_mse': []\n",
    "       , 'mse': [], 'total_training_time': []}\n",
    "\n",
    "for units, num_layers, epochs in config_generator():\n",
    "    for model_type in model_types:\n",
    "\n",
    "        print('currently running {} model with units, num_layers, epochs as {}, {}, {}'.format(model_type\n",
    "                                                                                       , units\n",
    "                                                                                       , num_layers\n",
    "                                                                                       , epochs))\n",
    "\n",
    "        # compile model\n",
    "        mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "        # fit model\n",
    "        mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "                      ,validation_steps=validation_steps, model_type=model_type)\n",
    "        \n",
    "        # get errors\n",
    "        history = mdq._histories[model_type]\n",
    "        val_mse = history.history['val_mse'][-1]\n",
    "        mse = history.history['mse'][-1]\n",
    "        \n",
    "        # get total training time\n",
    "        total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "        \n",
    "        # append results to results dictionary\n",
    "        res['model_type'].append(model_type)\n",
    "        res['epochs'].append(epochs)\n",
    "        res['num_layers'].append(num_layers)\n",
    "        res['units'].append(units)\n",
    "        res['val_mse'].append(val_mse)\n",
    "        res['mse'].append(mse)\n",
    "        res['total_training_time'].append(total_training_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part4_link'></a>\n",
    "# 4. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary to dataframe\n",
    "df_res = pd.DataFrame(res)\n",
    "\n",
    "# store dataframe as csv locally\n",
    "# df_res.to_csv('../data/02_results_run4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results; use bubble plots to indicate magnitude of mean-square error for specific configuration comparing\n",
    "# RNN to LSTM results\n",
    "\n",
    "x_label = 'epochs'\n",
    "y_label = 'units'\n",
    "z_label = 'mse'\n",
    "# condition_label = 'num_layers'\n",
    "# condition_vals = list(set(df_res[condition_label]))\n",
    "\n",
    "# condition_LSTM = (df_res['model_type']=='LSTM')\n",
    "# condition_RNN = (df_res['model_type']=='RNN')\n",
    "\n",
    "for model_type in ['LSTM', 'RNN']:\n",
    "    condition_1 = (df_res['model_type']== model_type)\n",
    "    \n",
    "    x = df_res[condition_1][x_label].values\n",
    "    y = df_res[condition_1][y_label].values\n",
    "    \n",
    "    z = df_res[condition_1][z_label].values\n",
    "    plt.scatter(x, y, s=z*10000, alpha=0.6, c=\"red\", linewidth=0.0)\n",
    "        \n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title('mean-square training error: {} model'.format(model_type))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[df_res['model_type']=='RNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
