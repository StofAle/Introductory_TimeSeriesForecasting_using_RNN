{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "#### In this notebook, the optimal network configurations obtained from the runs in the preceding notebook ('02_Freddie_Freeloader.ipynb') are applied to the clean data set with added random noise. The noise is added in two different ways: \n",
    "#### 1) 'Add distortion': The noise is fed as separate input to the model while the target variable remains the clean time series\n",
    "#### 2) 'Distort signal': The noise is added ontop of the clean time series data, which is taken as the target variable.\n",
    "#### In both scenarios, the model performance is measures as a function of the magnitude of the level of noise.\n",
    "\n",
    "#### The best performing model configuration will be used in the notebook '03_Blue_in_Green.ipynb' to analyze the impact of adding noise to the clean dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [1. Load modules](#Part1_link)\n",
    "* [2. Distortion next to clean time series](#Part2_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.1 Evaluate model performance under varying noise levels](#Part2.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.2 Visualize and save results](#Part2.2_link)\n",
    "* [3. Distorted time series](#Part3_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.1 Evaluate model performance under varying noise levels](#Part3.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.2 Visualize and save results](#Part3.2_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part1_link'></a>\n",
    "# 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import Kind_of_Blue  # own class with a collection of methods used in this analysis\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2_link'></a>\n",
    "# 2. Distortion next to clean time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run RNN and LSTM model with noise as separate feature. Evaluate model performance for a range of variances of the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=5*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 10  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "\n",
    "# initialize object\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# set target feature \n",
    "mdq._selected_features = ['observations']\n",
    "\n",
    "# set number of time points for 1/ future forecasting points and 2/ the past, historical time points\n",
    "future_target_size = int(365/52)\n",
    "past_history_size = int(1*365)\n",
    "\n",
    "# specify model configuration: this is chosen basen on the results from the previous notebook 02_Freddie_Freeloader.ipynb\n",
    "units = 128  # number of units in each neural network layer\n",
    "num_layers = 2  # total number of layers\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.1_link'></a>\n",
    "### 2.1 Evaluate model performance under varying noise levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps are repeated from the previous notebook, '02_Freddie_Freeloader.ipynb', and are grouped into one single step here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: x:(909, 365, 1), y:(909, 7, 1)\n",
      "validation set shape: x:(174, 365, 1), y:(174, 7, 1)\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 9s 68ms/step - loss: 0.1085 - mse: 0.1085 - val_loss: 0.2357 - val_mse: 0.2357\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 9s 68ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 9s 66ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 8s 65ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 8s 65ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 9s 66ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 9s 67ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 8s 66ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 8s 65ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 8s 65ms/step - loss: 0.0708 - mse: 0.0708 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "training set shape: x:(909, 365, 1), y:(909, 7, 1)\n",
      "validation set shape: x:(174, 365, 1), y:(174, 7, 1)\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 9s 67ms/step - loss: 0.1085 - mse: 0.1085 - val_loss: 0.2357 - val_mse: 0.2357\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 9s 66ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 9s 66ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 9s 73ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 9s 68ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 9s 68ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 7/10\n",
      "122/129 [===========================>..] - ETA: 0s - loss: 0.0191 - mse: 0.0191"
     ]
    }
   ],
   "source": [
    "# add random noise with zero mean and varying standard deviation as a separate feature to the input data \n",
    "standard_deviations = [0.1, 1.0, 10.0]\n",
    "\n",
    "# initialize results dictionary\n",
    "res_2 = {'model_type': [], 'std': [], 'val_mse': []\n",
    "       , 'mse': [], 'total_training_time': []}\n",
    "\n",
    "# model type \n",
    "model_types = ['RNN', 'LSTM']\n",
    "\n",
    "for model_type in model_types:\n",
    "    \n",
    "    for std in standard_deviations:\n",
    "        \n",
    "        # generate Gaussian noise\n",
    "        mean = 0.0\n",
    "        noise = [np.random.normal(loc=mean, scale=std, size=None) for x in range(len(idx))]\n",
    "\n",
    "        # initialize dataframe to store time series\n",
    "        df = pd.DataFrame(data={'observations': observations, 'noise': noise})\n",
    "        df.index = idx\n",
    "\n",
    "        # plot clean data and added noise\n",
    "        df.plot(alpha=0.5)\n",
    "        # save figure\n",
    "        fig_name = model_type + '_std_' + str(std) + '.jpg'\n",
    "        plt.savefig('../images/03_' + fig_name, dpi=500)\n",
    "\n",
    "        # load dataframe into object\n",
    "        mdq.df = df\n",
    "\n",
    "        # initialize dataset from dataframe \n",
    "        mdq.initialize_dataset()\n",
    "\n",
    "        # standardize data\n",
    "        mdq.standardize_data()\n",
    "\n",
    "        # generate train and validation data\n",
    "        mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size)\n",
    "\n",
    "        # set number of steps per epoch\n",
    "        num_samples = mdq._num_samples\n",
    "        steps_per_epoch = int(num_samples/future_target_size)\n",
    "        validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "        # compile model\n",
    "        mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "        # fit model\n",
    "        mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "                      ,validation_steps=validation_steps, model_type=model_type)\n",
    "\n",
    "        # get errors\n",
    "        history = mdq._histories[model_type]\n",
    "        val_mse = history.history['val_mse'][-1]\n",
    "        mse = history.history['mse'][-1]\n",
    "\n",
    "        # get total training time\n",
    "        total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "\n",
    "        # append results to results dictionary\n",
    "        res_2['model_type'].append(model_type)\n",
    "        res_2['std'].append(std)\n",
    "        res_2['val_mse'].append(val_mse)\n",
    "        res_2['mse'].append(mse)\n",
    "        res_2['total_training_time'].append(total_training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.2_link'></a>\n",
    "### 2.2 Visualize and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary to dataframe\n",
    "df_res_22 = pd.DataFrame(res_2)\n",
    "\n",
    "# store dataframe as csv locally\n",
    "df_res_22.to_csv('../data/03_results_addedNoise.csv')\n",
    "\n",
    "# read in stored data\n",
    "# df_res_22 = pd.read_csv('../data/03_results_addedNoise.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results; use bubble plots to indicate magnitude of mean-square error for specific configuration comparing\n",
    "# RNN to LSTM results\n",
    "\n",
    "df_res = df_res_22\n",
    "\n",
    "x_label = 'std'\n",
    "y_label = 'total_training_time'\n",
    "z_label = 'mse'\n",
    "\n",
    "for model_type in model_types:\n",
    "    condition_1 = (df_res['model_type']== model_type)\n",
    "    \n",
    "    x = df_res[condition_1][x_label].values\n",
    "    y = df_res[condition_1][y_label].values\n",
    "    \n",
    "    z = df_res[condition_1][z_label].values\n",
    "    plt.scatter(x, y, s=z*10000, alpha=0.6, c=\"red\", linewidth=0.0)\n",
    "        \n",
    "    plt.xlabel('standard deviation of the random noise')\n",
    "    plt.ylabel('total training time')\n",
    "    plt.title('mean-square training error: {} model'.format(model_type))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3_link'></a>\n",
    "# 3. Distorted time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run RNN and LSTM model with noise added ontop of the clean data. Evaluate model performance for a range of variances of the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=5*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 10  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "\n",
    "# initialize object\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# set target feature \n",
    "mdq._selected_features = ['observations']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.1_link'></a>\n",
    "### 3.1 Evaluate model performance under varying noise levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add random noise with zero mean and varying standard deviation as a separate feature to the input data \n",
    "# standard_deviations = [0.1, 1.0, 10.0]\n",
    "\n",
    "# initialize results dictionary\n",
    "res_3 = {'model_type': [], 'std': [], 'val_mse': []\n",
    "       , 'mse': [], 'total_training_time': []}\n",
    "\n",
    "# model type \n",
    "model_types = ['RNN', 'LSTM']\n",
    "\n",
    "for model_type in model_types:\n",
    "    \n",
    "    for std in standard_deviations:\n",
    "      \n",
    "        # generate noisy observations by adding Gaussian noise to clean observations\n",
    "        mean = 0.0\n",
    "        noise = [np.random.normal(loc=mean, scale=std, size=None) for x in range(len(idx))]        \n",
    "        noisy_observations = [noise[i]+observations[i] for i in range(len(noise))]\n",
    "        \n",
    "        # initialize dataframe to store time series\n",
    "        df = pd.DataFrame(data={'observations': noisy_observations})\n",
    "        df.index = idx\n",
    "\n",
    "        # plot clean data and added noise\n",
    "        df.plot(alpha=0.5)\n",
    "        # save figure\n",
    "        fig_name = model_type + '_std_' + str(std) + '.jpg'\n",
    "        plt.savefig('../images/03_' + fig_name, dpi=500)\n",
    "\n",
    "        # load dataframe into object\n",
    "        mdq.df = df\n",
    "\n",
    "        # initialize dataset from dataframe \n",
    "        mdq.initialize_dataset()\n",
    "\n",
    "        # standardize data\n",
    "        mdq.standardize_data()\n",
    "\n",
    "        # generate train and validation data\n",
    "        mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size)\n",
    "\n",
    "        # set number of steps per epoch\n",
    "        num_samples = mdq._num_samples\n",
    "        steps_per_epoch = int(num_samples/future_target_size)\n",
    "        validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "        # compile model\n",
    "        mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "        # fit model\n",
    "        mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "                      ,validation_steps=validation_steps, model_type=model_type)\n",
    "\n",
    "        # get errors\n",
    "        history = mdq._histories[model_type]\n",
    "        val_mse = history.history['val_mse'][-1]\n",
    "        mse = history.history['mse'][-1]\n",
    "\n",
    "        # get total training time\n",
    "        total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "\n",
    "        # append results to results dictionary\n",
    "        res_3['model_type'].append(model_type)\n",
    "        res_3['std'].append(std)\n",
    "        res_3['val_mse'].append(val_mse)\n",
    "        res_3['mse'].append(mse)\n",
    "        res_3['total_training_time'].append(total_training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.2_link'></a>\n",
    "### 3.2 Visualize and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary to dataframe\n",
    "df_res_32 = pd.DataFrame(res_3)\n",
    "\n",
    "# store dataframe as csv locally\n",
    "df_res_32.to_csv('../data/03_results_distored.csv')\n",
    "\n",
    "# read in locally stored data\n",
    "# df_res_32 = pd.read_csv('../data/03_results_distored.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results; use bubble plots to indicate magnitude of mean-square error for specific configuration comparing\n",
    "# RNN to LSTM results\n",
    "\n",
    "df_res = df_res_32\n",
    "\n",
    "x_label = 'std'\n",
    "y_label = 'total_training_time'\n",
    "z_label = 'mse'\n",
    "\n",
    "for model_type in model_types:\n",
    "    condition_1 = (df_res['model_type']== model_type)\n",
    "    \n",
    "    x = df_res[condition_1][x_label].values\n",
    "    y = df_res[condition_1][y_label].values\n",
    "    \n",
    "    z = df_res[condition_1][z_label].values\n",
    "    plt.scatter(x, y, s=z*10000, alpha=0.6, c=\"red\", linewidth=0.0)\n",
    "        \n",
    "    plt.xlabel('standard deviation of the random noise')\n",
    "    plt.ylabel('total training time')\n",
    "    plt.title('mean-square training error: {} model'.format(model_type))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
