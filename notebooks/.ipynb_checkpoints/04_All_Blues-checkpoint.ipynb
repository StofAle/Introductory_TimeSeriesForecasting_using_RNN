{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "#### In this notebook, the optimal network configurations obtained from the runs in the preceding notebook ('03_Blue_in_Green.ipynb') is applied to different lenth of the (historical) training data set. The behavior of the learning curves with the length of the historical information taken into account to generate forecasts is investigated and an optimal length is inferred.\n",
    "\n",
    "#### The experiements are run on the clean as well as distored datasets which were analyzed in the preceeding notebooks.\n",
    "\n",
    "#### The inferred optimal range of historical information given the 7-day forecasting horizon is used as a guideline in the subsequent application, presented in the notebook '05_Flamenco_Sketches.ipynb'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [1. Load modules](#Part1_link)\n",
    "* [2. Clean time series](#Part2_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.1 Evaluate model performance under varying amounts of historical information](#Part2.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.2 Visualize and save results](#Part2.2_link)\n",
    "* [3. Distorted time series](#Part3_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.1 Evaluate model performance under varying amounts of historical information](#Part3.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.2 Visualize and save results](#Part3.2_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part1_link'></a>\n",
    "# 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import Kind_of_Blue  # own class with a collection of methods used in this analysis\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2_link'></a>\n",
    "# 2. Clean time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model performance for a range of historical training data lengths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=5*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 10  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "\n",
    "# initialize object\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# set target feature \n",
    "mdq._selected_features = ['observations']\n",
    "\n",
    "# initialize dataframe to store time series\n",
    "df = pd.DataFrame(data={'observations': observations})\n",
    "df.index = idx\n",
    "\n",
    "# load dataframe into object\n",
    "mdq.df = df\n",
    "\n",
    "# initialize dataset from dataframe \n",
    "mdq.initialize_dataset()\n",
    "\n",
    "# standardize data\n",
    "mdq.standardize_data()\n",
    "\n",
    "# set number of time points for 1/ future forecasting points and 2/ the past, historical time points\n",
    "future_target_size = int(365/52)\n",
    "\n",
    "# specify model configuration: this is chosen basen on the results from the previous notebook 02_Freddie_Freeloader.ipynb\n",
    "units = 128  # number of units in each neural network layer\n",
    "num_layers = 2  # total number of layers\n",
    "epochs = 50\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.1_link'></a>\n",
    "### 2.1 Evaluate model performance under varying amounts of historical information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps are repeated from the previous notebook, '02_Freddie_Freeloader.ipynb', and are grouped into one single step here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: x:(1267, 7, 1), y:(1267, 7, 1)\n",
      "validation set shape: x:(532, 7, 1), y:(532, 7, 1)\n",
      "Epoch 1/50\n",
      "181/181 [==============================] - 1s 4ms/step - loss: 0.0625 - mse: 0.0625 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - 1s 4ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 10/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 11/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 8.0070e-04 - val_mse: 8.0070e-04\n",
      "Epoch 12/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 9.8071e-04 - val_mse: 9.8071e-04\n",
      "Epoch 13/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0080 - val_mse: 0.0080\n",
      "Epoch 14/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 15/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 16/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 17/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 18/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 9.8518e-04 - val_mse: 9.8518e-04\n",
      "Epoch 19/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 20/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 21/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 4.6974e-04 - val_mse: 4.6974e-04\n",
      "Epoch 22/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 4.9279e-04 - val_mse: 4.9279e-04\n",
      "Epoch 23/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 24/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 25/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 26/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 27/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 6.8936e-04 - val_mse: 6.8936e-04\n",
      "Epoch 28/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 29/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 7.3715e-04 - val_mse: 7.3715e-04\n",
      "Epoch 30/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 4.8013e-04 - val_mse: 4.8013e-04\n",
      "Epoch 31/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 32/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 33/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 34/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 35/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 36/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 37/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 38/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 39/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 4.8804e-04 - val_mse: 4.8804e-04\n",
      "Epoch 40/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 41/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 42/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 43/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 8.0698e-04 - val_mse: 8.0698e-04\n",
      "Epoch 44/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 6.6254e-04 - val_mse: 6.6254e-04\n",
      "Epoch 45/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 46/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 47/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 48/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 7.5536e-04 - val_mse: 7.5536e-04\n",
      "Epoch 49/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 50/50\n",
      "181/181 [==============================] - 0s 3ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 7.2281e-04 - val_mse: 7.2281e-04\n",
      "training set shape: x:(1204, 70, 1), y:(1204, 7, 1)\n",
      "validation set shape: x:(469, 70, 1), y:(469, 7, 1)\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 3s 16ms/step - loss: 0.0568 - mse: 0.0568 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 9.8489e-04 - val_mse: 9.8489e-04\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 6.4051e-04 - val_mse: 6.4051e-04\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 3s 15ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 5.4967e-04 - val_mse: 5.4967e-04\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 2s 13ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 3s 15ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 9.8064e-04 - val_mse: 9.8064e-04\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 7.6277e-04 - val_mse: 7.6277e-04\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 2s 13ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.2274 - mse: 0.2274 - val_loss: 0.1934 - val_mse: 0.1934\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 33/50\n",
      "172/172 [==============================] - 3s 15ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 34/50\n",
      "172/172 [==============================] - 3s 16ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 35/50\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 36/50\n",
      "172/172 [==============================] - 3s 15ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 9.6391e-04 - val_mse: 9.6391e-04\n",
      "Epoch 37/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 38/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 39/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 40/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0096 - val_mse: 0.0096\n",
      "Epoch 41/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 42/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.0348 - val_mse: 0.0348\n",
      "Epoch 43/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 44/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 45/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 46/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 47/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 48/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 49/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 50/50\n",
      "172/172 [==============================] - 2s 14ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "training set shape: x:(1134, 140, 1), y:(1134, 7, 1)\n",
      "validation set shape: x:(399, 140, 1), y:(399, 7, 1)\n",
      "Epoch 1/50\n",
      "162/162 [==============================] - 4s 28ms/step - loss: 0.0645 - mse: 0.0645 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 2/50\n",
      "162/162 [==============================] - 5s 29ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 5s 29ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 9.0513e-04 - val_mse: 9.0513e-04\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 5s 29ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 10/50\n",
      "162/162 [==============================] - 5s 28ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 11s 68ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 10s 64ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 9.8180e-04 - val_mse: 9.8180e-04\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.6035 - mse: 0.6035 - val_loss: 0.0567 - val_mse: 0.0567\n",
      "Epoch 18/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0159 - val_mse: 0.0159\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 25/50\n",
      "162/162 [==============================] - 5s 28ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 5s 28ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 28/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 29/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 30/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0069 - val_mse: 0.0069\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 33/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 5s 29ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0311 - val_mse: 0.0311\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 5s 30ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 5s 28ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 5s 28ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0211 - val_mse: 0.0211\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0066 - val_mse: 0.0066\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.0090 - val_mse: 0.0090\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0200 - val_mse: 0.0200\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.0138 - val_mse: 0.0138\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "training set shape: x:(910, 364, 1), y:(910, 7, 1)\n",
      "validation set shape: x:(175, 364, 1), y:(175, 7, 1)\n",
      "Epoch 1/50\n",
      "130/130 [==============================] - 10s 75ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 9s 72ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 9s 68ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 9s 66ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 9s 71ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 9s 69ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 9s 68ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 9s 69ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 3.7214e-04 - val_mse: 3.7214e-04\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 9s 66ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 8.7179e-04 - val_mse: 8.7179e-04\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 9s 66ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 12/50\n",
      "130/130 [==============================] - 10s 74ms/step - loss: 1.1652 - mse: 1.1652 - val_loss: 0.9073 - val_mse: 0.9073\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 9s 69ms/step - loss: 0.9819 - mse: 0.9819 - val_loss: 0.2503 - val_mse: 0.2503\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 9s 69ms/step - loss: 0.2531 - mse: 0.2531 - val_loss: 0.1987 - val_mse: 0.1987\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 8s 65ms/step - loss: 0.1688 - mse: 0.1688 - val_loss: 0.1003 - val_mse: 0.1003\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 10s 79ms/step - loss: 0.0961 - mse: 0.0961 - val_loss: 0.0534 - val_mse: 0.0534\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 9s 67ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.0436 - val_mse: 0.0436\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 9s 68ms/step - loss: 0.0677 - mse: 0.0677 - val_loss: 0.0450 - val_mse: 0.0450\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 9s 69ms/step - loss: 0.0569 - mse: 0.0569 - val_loss: 0.0491 - val_mse: 0.0491\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 9s 67ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0411 - val_mse: 0.0411\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 9s 67ms/step - loss: 0.0500 - mse: 0.0500 - val_loss: 0.0298 - val_mse: 0.0298\n",
      "Epoch 22/50\n",
      "130/130 [==============================] - 9s 68ms/step - loss: 0.0459 - mse: 0.0459 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 23/50\n",
      "130/130 [==============================] - 11s 82ms/step - loss: 0.0476 - mse: 0.0476 - val_loss: 0.0301 - val_mse: 0.0301\n",
      "Epoch 24/50\n",
      "130/130 [==============================] - 11s 86ms/step - loss: 0.0446 - mse: 0.0446 - val_loss: 0.0288 - val_mse: 0.0288\n",
      "Epoch 25/50\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 26/50\n",
      "130/130 [==============================] - 9s 70ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0367 - val_mse: 0.0367\n",
      "Epoch 27/50\n",
      "130/130 [==============================] - 10s 79ms/step - loss: 0.0431 - mse: 0.0431 - val_loss: 0.0460 - val_mse: 0.0460\n",
      "Epoch 28/50\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.0583 - mse: 0.0583 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 29/50\n",
      "130/130 [==============================] - 10s 78ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 9s 69ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.0182 - val_mse: 0.0182\n",
      "Epoch 31/50\n",
      "130/130 [==============================] - 9s 69ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 32/50\n",
      "130/130 [==============================] - 10s 74ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.0186 - val_mse: 0.0186\n",
      "Epoch 33/50\n",
      "130/130 [==============================] - 9s 71ms/step - loss: 0.0276 - mse: 0.0276 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 34/50\n",
      "130/130 [==============================] - 9s 68ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 35/50\n",
      "130/130 [==============================] - 9s 72ms/step - loss: 0.0394 - mse: 0.0394 - val_loss: 0.0279 - val_mse: 0.0279\n",
      "Epoch 36/50\n",
      "130/130 [==============================] - 9s 70ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 37/50\n",
      "130/130 [==============================] - 9s 68ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 38/50\n",
      "130/130 [==============================] - 9s 71ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 39/50\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 40/50\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 41/50\n",
      "130/130 [==============================] - 9s 73ms/step - loss: 0.0274 - mse: 0.0274 - val_loss: 0.0092 - val_mse: 0.0092\n",
      "Epoch 42/50\n",
      "130/130 [==============================] - 9s 69ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 43/50\n",
      "130/130 [==============================] - 8s 65ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 44/50\n",
      "130/130 [==============================] - 9s 72ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 45/50\n",
      "130/130 [==============================] - 9s 67ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0163 - val_mse: 0.0163\n",
      "Epoch 46/50\n",
      "130/130 [==============================] - 10s 76ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.0089 - val_mse: 0.0089\n",
      "Epoch 47/50\n",
      "130/130 [==============================] - 9s 72ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 48/50\n",
      "130/130 [==============================] - 13s 97ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 49/50\n",
      "130/130 [==============================] - 11s 82ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 50/50\n",
      "130/130 [==============================] - 12s 93ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "training set shape: x:(1267, 7, 1), y:(1267, 7, 1)\n",
      "validation set shape: x:(532, 7, 1), y:(532, 7, 1)\n",
      "Epoch 1/50\n",
      "181/181 [==============================] - 2s 12ms/step - loss: 0.1497 - mse: 0.1497 - val_loss: 0.0649 - val_mse: 0.0649\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - 2s 10ms/step - loss: 0.0666 - mse: 0.0666 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 3/50\n",
      "181/181 [==============================] - 2s 10ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 4/50\n",
      "181/181 [==============================] - 2s 11ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 5/50\n",
      "181/181 [==============================] - 3s 17ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 6/50\n",
      "181/181 [==============================] - 3s 16ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 7/50\n",
      "181/181 [==============================] - 3s 15ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 8/50\n",
      "181/181 [==============================] - 2s 12ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 9/50\n",
      "181/181 [==============================] - 2s 12ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 10/50\n",
      "181/181 [==============================] - 2s 11ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 11/50\n",
      "181/181 [==============================] - 2s 11ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 12/50\n",
      "181/181 [==============================] - 2s 10ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 13/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 14/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 15/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 16/50\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 5.7121e-04 - val_mse: 5.7121e-04\n",
      "Epoch 17/50\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 18/50\n",
      "181/181 [==============================] - 2s 8ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 19/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 20/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 21/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 22/50\n",
      "181/181 [==============================] - 2s 10ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 5.5148e-04 - val_mse: 5.5148e-04\n",
      "Epoch 23/50\n",
      "181/181 [==============================] - 2s 11ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 24/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 25/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 26/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 27/50\n",
      "181/181 [==============================] - 2s 8ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 5.6420e-04 - val_mse: 5.6420e-04\n",
      "Epoch 28/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 7.8257e-04 - val_mse: 7.8257e-04\n",
      "Epoch 29/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 8.6540e-04 - val_mse: 8.6540e-04\n",
      "Epoch 30/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 31/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 32/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 33/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 34/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 35/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 36/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0071 - mse: 0.0071 - val_loss: 7.5831e-04 - val_mse: 7.5831e-04\n",
      "Epoch 37/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 38/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 39/50\n",
      "181/181 [==============================] - 2s 9ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 7.3207e-04 - val_mse: 7.3207e-04\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 1s 8ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 41/50\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 42/50\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 43/50\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 0.0070 - mse: 0.0070 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 44/50\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 0.0065 - mse: 0.0065 - val_loss: 7.4343e-04 - val_mse: 7.4343e-04\n",
      "Epoch 45/50\n",
      "181/181 [==============================] - 2s 8ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 3.8796e-04 - val_mse: 3.8796e-04\n",
      "Epoch 46/50\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 47/50\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 48/50\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 9.3947e-04 - val_mse: 9.3947e-04\n",
      "Epoch 49/50\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 50/50\n",
      "181/181 [==============================] - 1s 8ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 3.7508e-04 - val_mse: 3.7508e-04\n",
      "training set shape: x:(1204, 70, 1), y:(1204, 7, 1)\n",
      "validation set shape: x:(469, 70, 1), y:(469, 7, 1)\n",
      "Epoch 1/50\n",
      "172/172 [==============================] - 11s 64ms/step - loss: 0.0928 - mse: 0.0928 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 2/50\n",
      "172/172 [==============================] - 11s 64ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 3/50\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 4/50\n",
      "172/172 [==============================] - 12s 67ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 5/50\n",
      "172/172 [==============================] - 11s 63ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 6/50\n",
      "172/172 [==============================] - 11s 64ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 7.4696e-04 - val_mse: 7.4696e-04\n",
      "Epoch 7/50\n",
      "172/172 [==============================] - 12s 69ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 8/50\n",
      "172/172 [==============================] - 13s 75ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 9/50\n",
      "172/172 [==============================] - 13s 73ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 10/50\n",
      "172/172 [==============================] - 13s 73ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 11/50\n",
      "172/172 [==============================] - 11s 64ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 12/50\n",
      "172/172 [==============================] - 12s 68ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 13/50\n",
      "172/172 [==============================] - 11s 64ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 14/50\n",
      "172/172 [==============================] - 11s 66ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 15/50\n",
      "172/172 [==============================] - 11s 66ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 16/50\n",
      "172/172 [==============================] - 11s 64ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 17/50\n",
      "172/172 [==============================] - 11s 64ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 18/50\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 8.7970e-04 - val_mse: 8.7970e-04\n",
      "Epoch 19/50\n",
      "172/172 [==============================] - 11s 66ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 20/50\n",
      "172/172 [==============================] - 10s 61ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 21/50\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 7.3081e-04 - val_mse: 7.3081e-04\n",
      "Epoch 22/50\n",
      "172/172 [==============================] - 9s 55ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 7.5430e-04 - val_mse: 7.5430e-04\n",
      "Epoch 23/50\n",
      "172/172 [==============================] - 10s 57ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0070 - val_mse: 0.0070\n",
      "Epoch 24/50\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 25/50\n",
      "172/172 [==============================] - 10s 60ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 8.5418e-04 - val_mse: 8.5418e-04\n",
      "Epoch 26/50\n",
      "172/172 [==============================] - 10s 58ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 27/50\n",
      "172/172 [==============================] - 10s 58ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 7.7659e-04 - val_mse: 7.7659e-04\n",
      "Epoch 28/50\n",
      "172/172 [==============================] - 11s 65ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 29/50\n",
      "172/172 [==============================] - 11s 64ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 8.2953e-04 - val_mse: 8.2953e-04\n",
      "Epoch 30/50\n",
      "172/172 [==============================] - 11s 63ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 7.9488e-04 - val_mse: 7.9488e-04\n",
      "Epoch 31/50\n",
      "172/172 [==============================] - 10s 59ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 32/50\n",
      "172/172 [==============================] - 10s 58ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0065 - val_mse: 0.0065\n",
      "Epoch 33/50\n",
      "172/172 [==============================] - 10s 57ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 34/50\n",
      "172/172 [==============================] - 11s 63ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 35/50\n",
      "172/172 [==============================] - 10s 60ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 36/50\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 7.8057e-04 - val_mse: 7.8057e-04\n",
      "Epoch 37/50\n",
      "172/172 [==============================] - 11s 63ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 7.6122e-04 - val_mse: 7.6122e-04\n",
      "Epoch 38/50\n",
      "172/172 [==============================] - 10s 61ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 39/50\n",
      "172/172 [==============================] - 11s 64ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 40/50\n",
      "172/172 [==============================] - 10s 60ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 41/50\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 42/50\n",
      "172/172 [==============================] - 10s 57ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 43/50\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 44/50\n",
      "172/172 [==============================] - 10s 56ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 7.4986e-04 - val_mse: 7.4986e-04\n",
      "Epoch 45/50\n",
      "172/172 [==============================] - 11s 63ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 7.6724e-04 - val_mse: 7.6724e-04\n",
      "Epoch 46/50\n",
      "172/172 [==============================] - 11s 62ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 6.9725e-04 - val_mse: 6.9725e-04\n",
      "Epoch 47/50\n",
      "172/172 [==============================] - 10s 56ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 48/50\n",
      "172/172 [==============================] - 11s 61ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 11s 67ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 7.7683e-04 - val_mse: 7.7683e-04\n",
      "Epoch 50/50\n",
      "172/172 [==============================] - 11s 64ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "training set shape: x:(1134, 140, 1), y:(1134, 7, 1)\n",
      "validation set shape: x:(399, 140, 1), y:(399, 7, 1)\n",
      "Epoch 1/50\n",
      "162/162 [==============================] - 20s 122ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 2/50\n",
      "162/162 [==============================] - 20s 126ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 3/50\n",
      "162/162 [==============================] - 19s 116ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 4/50\n",
      "162/162 [==============================] - 18s 112ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 5/50\n",
      "162/162 [==============================] - 19s 115ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 6/50\n",
      "162/162 [==============================] - 19s 118ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 7/50\n",
      "162/162 [==============================] - 22s 133ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 8/50\n",
      "162/162 [==============================] - 23s 142ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 9/50\n",
      "162/162 [==============================] - 22s 138ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 10/50\n",
      "162/162 [==============================] - 19s 117ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 11/50\n",
      "162/162 [==============================] - 18s 111ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 12/50\n",
      "162/162 [==============================] - 18s 113ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 13/50\n",
      "162/162 [==============================] - 19s 117ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 14/50\n",
      "162/162 [==============================] - 19s 120ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 15/50\n",
      "162/162 [==============================] - 19s 116ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 16/50\n",
      "162/162 [==============================] - 21s 129ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 17/50\n",
      "162/162 [==============================] - 22s 139ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 18/50\n",
      "162/162 [==============================] - 23s 143ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 19/50\n",
      "162/162 [==============================] - 18s 111ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 20/50\n",
      "162/162 [==============================] - 18s 110ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 21/50\n",
      "162/162 [==============================] - 17s 106ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 22/50\n",
      "162/162 [==============================] - 17s 104ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 23/50\n",
      "162/162 [==============================] - 18s 111ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 24/50\n",
      "162/162 [==============================] - 22s 137ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 25/50\n",
      "162/162 [==============================] - 20s 121ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 26/50\n",
      "162/162 [==============================] - 21s 128ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 27/50\n",
      "162/162 [==============================] - 21s 132ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 28/50\n",
      "162/162 [==============================] - 20s 122ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 29/50\n",
      "162/162 [==============================] - 20s 125ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 30/50\n",
      "162/162 [==============================] - 21s 129ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 31/50\n",
      "162/162 [==============================] - 25s 153ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 32/50\n",
      "162/162 [==============================] - 27s 168ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 33/50\n",
      "162/162 [==============================] - 18s 112ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 34/50\n",
      "162/162 [==============================] - 24s 146ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 35/50\n",
      "162/162 [==============================] - 20s 126ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 36/50\n",
      "162/162 [==============================] - 20s 125ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 37/50\n",
      "162/162 [==============================] - 25s 155ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 38/50\n",
      "162/162 [==============================] - 24s 151ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 39/50\n",
      "162/162 [==============================] - 21s 132ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 40/50\n",
      "162/162 [==============================] - 22s 138ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 41/50\n",
      "162/162 [==============================] - 23s 142ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 42/50\n",
      "162/162 [==============================] - 21s 127ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 43/50\n",
      "162/162 [==============================] - 19s 116ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 44/50\n",
      "162/162 [==============================] - 22s 136ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 45/50\n",
      "162/162 [==============================] - 21s 128ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 46/50\n",
      "162/162 [==============================] - 19s 120ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 47/50\n",
      "162/162 [==============================] - 26s 159ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 48/50\n",
      "162/162 [==============================] - 19s 117ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 49/50\n",
      "162/162 [==============================] - 22s 136ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 50/50\n",
      "162/162 [==============================] - 21s 129ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "training set shape: x:(910, 364, 1), y:(910, 7, 1)\n",
      "validation set shape: x:(175, 364, 1), y:(175, 7, 1)\n",
      "Epoch 1/50\n",
      "130/130 [==============================] - 42s 320ms/step - loss: 0.1714 - mse: 0.1714 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 2/50\n",
      "130/130 [==============================] - 42s 326ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 3/50\n",
      "130/130 [==============================] - 38s 296ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0061 - val_mse: 0.0061\n",
      "Epoch 4/50\n",
      "130/130 [==============================] - 38s 289ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 5/50\n",
      "130/130 [==============================] - 38s 290ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 6/50\n",
      "130/130 [==============================] - 38s 291ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 7/50\n",
      "130/130 [==============================] - 38s 289ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 8/50\n",
      "130/130 [==============================] - 43s 334ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 9/50\n",
      "130/130 [==============================] - 38s 293ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 10/50\n",
      "130/130 [==============================] - 38s 290ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 11/50\n",
      "130/130 [==============================] - 38s 289ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 37s 282ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 13/50\n",
      "130/130 [==============================] - 37s 283ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 14/50\n",
      "130/130 [==============================] - 37s 283ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 15/50\n",
      "130/130 [==============================] - 37s 281ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 16/50\n",
      "130/130 [==============================] - 37s 284ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 17/50\n",
      "130/130 [==============================] - 37s 283ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 18/50\n",
      "130/130 [==============================] - 37s 281ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 19/50\n",
      "130/130 [==============================] - 37s 283ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 8.8282e-04 - val_mse: 8.8282e-04\n",
      "Epoch 20/50\n",
      "130/130 [==============================] - 37s 285ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 21/50\n",
      "130/130 [==============================] - 37s 285ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 9.1762e-04 - val_mse: 9.1762e-04\n",
      "Epoch 22/50\n",
      "130/130 [==============================] - 37s 287ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 23/50\n",
      "130/130 [==============================] - 37s 286ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 24/50\n",
      "130/130 [==============================] - 48s 372ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 25/50\n",
      "130/130 [==============================] - 38s 289ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 26/50\n",
      "130/130 [==============================] - 38s 289ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 6.6728e-04 - val_mse: 6.6728e-04\n",
      "Epoch 27/50\n",
      "130/130 [==============================] - 38s 289ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 4.9282e-04 - val_mse: 4.9282e-04\n",
      "Epoch 28/50\n",
      "130/130 [==============================] - 38s 294ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 29/50\n",
      "130/130 [==============================] - 38s 292ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 9.9864e-04 - val_mse: 9.9864e-04\n",
      "Epoch 30/50\n",
      "130/130 [==============================] - 38s 296ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 6.4959e-04 - val_mse: 6.4959e-04\n",
      "Epoch 31/50\n",
      "130/130 [==============================] - 39s 296ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 32/50\n",
      "130/130 [==============================] - 39s 298ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 6.4443e-04 - val_mse: 6.4443e-04\n",
      "Epoch 33/50\n",
      "130/130 [==============================] - 39s 298ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 34/50\n",
      "130/130 [==============================] - 48s 371ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 35/50\n",
      "130/130 [==============================] - 52s 398ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 36/50\n",
      "130/130 [==============================] - 58s 449ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 37/50\n",
      "130/130 [==============================] - 53s 410ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 38/50\n",
      "130/130 [==============================] - 64s 490ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 39/50\n",
      "130/130 [==============================] - 53s 405ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 40/50\n",
      "130/130 [==============================] - 54s 413ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 5.6733e-04 - val_mse: 5.6733e-04\n",
      "Epoch 41/50\n",
      "130/130 [==============================] - 54s 412ms/step - loss: 0.0077 - mse: 0.0077 - val_loss: 8.7049e-04 - val_mse: 8.7049e-04\n",
      "Epoch 42/50\n",
      "130/130 [==============================] - 54s 418ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0076 - val_mse: 0.0076\n",
      "Epoch 43/50\n",
      "130/130 [==============================] - 55s 420ms/step - loss: 0.0078 - mse: 0.0078 - val_loss: 6.9927e-04 - val_mse: 6.9927e-04\n",
      "Epoch 44/50\n",
      "130/130 [==============================] - 54s 417ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 45/50\n",
      "130/130 [==============================] - 50s 382ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 46/50\n",
      "130/130 [==============================] - 39s 297ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 47/50\n",
      "130/130 [==============================] - 38s 293ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 48/50\n",
      "130/130 [==============================] - 38s 294ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 49/50\n",
      "130/130 [==============================] - 39s 296ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 6.0996e-04 - val_mse: 6.0996e-04\n",
      "Epoch 50/50\n",
      "130/130 [==============================] - 88s 679ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 7.9065e-04 - val_mse: 7.9065e-04\n"
     ]
    }
   ],
   "source": [
    "# choose a few past history sizes\n",
    "past_history_sizes = [1 * future_target_size, 10 * future_target_size, 20 * future_target_size, 52 * future_target_size]\n",
    "\n",
    "# initialize results dictionary\n",
    "res_2 = {'model_type': [], 'past_history_size': [], 'val_mse': []\n",
    "       , 'mse': [], 'total_training_time': []}\n",
    "\n",
    "# model type \n",
    "model_types = ['RNN', 'LSTM']\n",
    "\n",
    "for model_type in model_types:\n",
    "    \n",
    "    for past_history_size in past_history_sizes:\n",
    "        \n",
    "        # generate train and validation data\n",
    "        mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size)\n",
    "\n",
    "        # set number of steps per epoch\n",
    "        num_samples = mdq._num_samples\n",
    "        steps_per_epoch = int(num_samples/future_target_size)\n",
    "        validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "        # compile model\n",
    "        mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "        # fit model\n",
    "        mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "                      ,validation_steps=validation_steps, model_type=model_type)\n",
    "\n",
    "        # get errors\n",
    "        history = mdq._histories[model_type]\n",
    "        val_mse = history.history['val_mse'][-1]\n",
    "        mse = history.history['mse'][-1]\n",
    "\n",
    "        # get total training time\n",
    "        total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "\n",
    "        # append results to results dictionary\n",
    "        res_2['model_type'].append(model_type)\n",
    "        res_2['past_history_size'].append(past_history_size)\n",
    "        res_2['val_mse'].append(val_mse)\n",
    "        res_2['mse'].append(mse)\n",
    "        res_2['total_training_time'].append(total_training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.2_link'></a>\n",
    "### 2.2 Visualize and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary to dataframe\n",
    "df_res_22 = pd.DataFrame(res_2)\n",
    "\n",
    "# store dataframe as csv locally\n",
    "df_res_22.to_csv('../data/04_results_cleanData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAE0CAYAAABTplZXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd1yV9f//8QdDQEs8pnAQBU1EBMGRhqMUxa0pqSmQlR8EJVMr98jdQMVRbhO1cGQ4yhlYiiDhHrlQMbcmKAoIDubvD36cr8dzWAoe8Lzut5u3m76v9/u6Xtd18Dy5tkFiYmI2QgghhJ4w1HUBQgghxMskwSeEEEKvSPAJIYTQKxJ8Qggh9IoEnxBCCL0iwSeEEEKvSPAJNQqFgm7duum6jBJz9erVV34dxaulW7duKBQKrl69+kLzGTx4cLHM51UgwSfEc9i3bx8KhYLBgwfrupRCUSgUuLi4FOs8c79In/5jZWVFkyZNGDFiBNeuXStw3I4dO7T2WblyJQqFgoCAALX2gIAA1dglS5ZoHfvXX3+Vqc9GvHwSfEKIF9K1a1fGjh3L2LFj+eijj4Cc4HJzc+PSpUv5jp0yZQrp6enPtdxZs2aRmJj4XGOFfpPgE0K8kG7dujF+/HjGjx/P7NmzOXjwIG3btuX+/fvMnj07z3F2dnZcvHiRFStWFHmZdnZ23L9/n1mzZr1I6UJPSfDpiRMnTuDn50f9+vWxtLTE3t6eLl26FPpLJysri+DgYDp16oStrS1KpZIWLVowd+5c0tLSNPpv376dgQMH8tZbb2FtbU316tVp3bo1ixcvJjMzU6N/7uGvffv2sWXLFtzd3alWrRq1atXCx8eHmzdvFml9Hzx4wIQJE3ByckKpVPL222+zYMECsrO1P6Hvv//+Y8aMGXTs2JG6detiYWFBvXr18PX1JSYmRq1vQEAA3bt3B+CXX35RO9S3du1aANLS0vjxxx/54IMPcHZ2xtLSkpo1a9KjRw/CwsK01vDPP//g6+uLi4sLSqWS2rVr07JlS0aOHElSUpJG/y1btuDh4UGtWrWwtLTkrbfeYurUqSQnJ6v65B6SBbh+/bparSV1KNDY2JhPPvkEgOPHj+fZb9SoUVSsWPG59tx8fX2pUaMGQUFBXL58+YXqffq8b3x8PEOGDMHe3h5ra2s6duzI33//DUBKSgoTJkxQfZ7NmjXj999/1zrPJ0+e8MMPP/DOO+9QrVo1atSoQfv27QkODs7zZ3DTpk24ublhZWVFnTp1GDRoEP/991++tZ84cYIBAwZQr149LCwscHBwYNCgQQXuaes7Y10XIEre6tWrGT58OAAdO3bEwcGB+/fvc/r0aX744Qd8fX3zHZ+RkcFHH31EaGgoderUoXfv3piamvL3338zffp0IiIi2LRpE8bG//fjNG3aNAwNDWnatCnW1tYkJSURERHBhAkTOHbsGEFBQVqXtWLFCv744w+6du3KO++8w5EjR/jtt984deoUf//9N6ampgWu75MnT/Dw8ODYsWM4OTnRp08fkpOTmTNnjupL7FnR0dH88MMPtGrVih49elChQgX+/fdftmzZwh9//EFoaCgNGjQA4N133+XatWv88ssvODs7q10ok3se7f79+4wbN45mzZrRtm1bqlatyu3bt9m5cyeenp58//33/O9//1ONO3nyJB07dsTAwIDOnTvz5ptvkpKSwrVr11i3bh1DhgyhUqVKqv4jR45kxYoVVK9enffeew+FQsGRI0f4/vvv2bVrF2FhYVSsWBFbW1vGjh3LzJkzMTc3Vwu7p8/5BQQEMHPmTLy9vfM8d/Y8nv6ZeJaFhQVffvklX3/9NbNnz+abb74p9HzNzMyYMmUKAwcOZMqUKQQHB79wrUlJSXTq1InKlSvTp08fbt26xZYtW+jduze7du3iyy+/5OHDh3Tt2pUHDx6wadMmfHx8qF69Om+//bZqPunp6fTu3ZuoqCjq1KnDgAEDSEtLY/v27Xz++edER0ezdOlStWUvWrSIr776CnNzczw9PVEoFOzZs4eOHTtibm6utd6QkBA+++wzTExM6NKlC9WrV+fSpUts2rSJ0NBQtm/frvqZFeok+F5x586dY/jw4ZiZmbF9+3YaNWqkNv3GjRsFzmPevHmEhoYycOBAZsyYgZGREZCzFzh8+HB+/vlngoKC+PTTT1VjQkJCePPNN9Xmk5WVxaeffkpISAj+/v5qXxa59uzZQ0REBPXq1VO1+fn5sXHjRnbs2EGvXr0KrHfhwoUcO3aMrl27smbNGgwNcw5sDB8+nDZt2mgd07p1ay5cuEDFihXV2k+cOEHXrl2ZNm0amzZtAqBVq1ZAzt6ei4sL48eP15ifQqHg1KlTVK9eXa09MTGRTp06MXXqVDw9PSlfvjwA69ev58mTJ6xevVq1N5nrwYMHmJiYqP7966+/smLFCt577z2WL1+umgdAYGAg3377LQEBAXz33XfUrFmT8ePHM3PmTCpVqqS11uKWmZnJmjVrAGjRokW+fYcMGcKqVav48ccf8fPzo1atWoVezgcffMDSpUvZunUr+/fvL3BZBTl9+jT+/v7MmDEDAwMDAObOncv06dN57733aNu2LUFBQZQrVw4Ad3d3Bg4cyPfff6/a0wdYsGABUVFRuLu7s379etVnN3HiRDp37sz69evp3Lkz77//PpCzxzlt2jTMzc2JjIxUbYMpU6YwYMAArXuVly5dYtiwYdSoUYOdO3dibW2tmrZv3z7ef/99hg4dSmRk5Attk1eVHOp8xa1YsYKMjAxGjhypEXoANWrUyHd8VlYWS5cuxcLCgoCAAFXoARgaGjJ9+nQMDAz49ddf1cY9G3q5/T/77DMgJ+C08ff3Vws9gP79+wNw7NixfGvNtXbtWgwMDFR7nblsbW3x9/fXOsbCwkIj9AAaNWpEq1atiIqKKtJFGKamphqhBzmB+NFHH5GYmKi2Prl1VqhQQWNMxYoV1fZ0Fy9ejJGREQsWLFALPYARI0ZQpUoVQkJCCl0rwKBBgzh06BBTpkwp0jiAHTt2EBAQQEBAAKNHj6Z58+bs3r0bR0dHRo8ene9YMzMzJk+eTFpaWpGXbWBgwLfffgvAV199lechxMJ67bXXmDx5sir0APr27QtAcnIy33zzjSr0AHr16kW5cuU4deqU2nxyQ//bb79V+4WlUqVKTJ48GYCff/5Z1b5hwwbS0tIYOHCgWvAbGhoydepUtf9zuVasWMGTJ0/47rvv1EIPcn4x69KlCydPntQ4TC9yyB7fK+7IkSNAziHO53Hx4kUSEhJ48803CQwM1NqnfPnyxMbGqrXdu3eP+fPns2vXLq5evUpqaqra9LzOXWgL59wAKcx5oAcPHnDp0iWsrKywt7fXmP7OO+/kOTYsLIyVK1dy4sQJEhISyMjIUJuekJCAlZVVgTXkiomJYf78+URHR3P79m2ePHmiNv3pbdC7d2+WLl1Kv3796NGjB61bt8bV1ZW6deuqjXn06BEnT56kcuXKGofLcpmYmPDff/9x79493njjjULVWqVKFapUqVLodXvazp072blzp1pbw4YN2b59u9ZfJp7Vp08fli5dypYtWzhw4ADNmzcv9LKbN29Ojx492Lp1Kxs3bqRPnz5Frj+XnZ0dr732mlpb7uetUCiwsbFRm2ZkZISFhQW3bt1SteX+/FlaWuLo6KixDDc3NyDnfG6u3L9r+9msVasW1atX17g15ODBg0DOIfqn55Xrzp07AFy4cEFrHfpOgu8Vl3tRhLa9j8K4d+8eAJcvX2bmzJmFGpOYmEjbtm25evUqTZo0wcvLi8qVK2NkZERSUhJLly7VCIFc2s5n5P7Gq+2imGflXthhYWGhdbqlpaXW9qVLlzJu3DgUCgVt27bFxsYGMzMzDAwM2LFjB6dPn86zZm0OHz5Mjx49yMjIwM3NjS5dulCxYkUMDQ05deoUO3fuVJtf48aNCQsLY/bs2Wzfvl21x2Zra8uXX37JgAEDgJxzh9nZ2dy7d6/AzyMlJaXQwfciFi1aRL9+/cjKyuLatWvMmTOH1atXM3DgQH755Re1PShtDAwM+Oabb+jatSsTJ07kzz//LNLyp02bRmhoKNOmTdM4TFwU2kI69xxlXgFuZGSk9gtS7s9fXj9nFSpUwNzcXO0CpML8zD4bfLn/LxcuXKh1TK5nf+EUOST4XnG5F0TcunVLdXVfUeQGUe65icJYvXo1V69eZezYsRrnlA4dOpTnnkpxyK039zfeZ8XHx2u0ZWRkEBAQgFKpJCIiQmOv7vDhw0WuY/bs2Tx69Iht27apzgnmmjt3rsYeEkCTJk345ZdfSEtL4+TJk+zZs4fly5czYsQIKlSogJeXl2r9nJyciI6OLnJdJcnQ0JBatWqxYMEC4uLiCA0NJSgoiIEDBxY4tmXLlnTv3p1t27apzqUW1ptvvsnAgQNZtGgRixcv1ukFHbmfj7afM4CHDx+SnJys9gvJ8/zM5o65fPkylStXfqGa9ZGc43vF5V5AsmvXrucaX7duXSpVqsTRo0e13ragTe6l1D169NCYltdVlcWlYsWK1K5dm7i4OC5evFio5SckJJCUlISrq6tG6KWkpGg9lFTQXuilS5eoXLmyRujlVcPTTExMaNq0KWPGjGHZsmVAzu0hAK+//jpOTk7ExsaSkJCQ73yeZmhoSFZWVqH7v6gZM2ZQrlw5AgIC1PZu8jNt2jTKlSvHtGnTePz4cZGWN3r0aCpXrsy8efPyDJCXIffnLz4+nnPnzmlMz73Y5OlD+g0bNgS0/1xcuXJF6608uf+vS9svP2WFBN8rztfXl3LlyjFnzhyNk/BAgffHGRsb8+mnn3Lnzh1GjRrFw4cPNfokJCRw8uRJ1b9tbW2BnKvLnvbPP/8wb96851mNIunXrx/Z2dlMnjxZ7cv+2rVrqiB5moWFBRUqVOD48eOkpKSo2tPT0xk3bpzWgMk9H5bXVbG2traqW0aeFhwczO7duzX6R0dHaz2HGRcXB+RcBJJryJAhpKen89lnn3H//n2NMQ8ePFCd23263rt37/Lo0SOt9SYkJHDhwgVu376tdXpR1a5dm48++oh79+6xYMGCQo/x8/Pj+vXrRb6pXaFQMGbMGB48eJDvTfMvw8cffwzkXMX59AVRycnJTJ8+HUB1nyPknOMsV64cy5cv58qVK6r2rKwspk2bpvWXq0GDBmFiYsLEiRO5cOGCxvTMzEyN/3/i/8ihzlecg4MDc+fO5csvv6Rt27Z06tQJBwcHkpKSOHPmDLdu3VILLW1Gjx7N2bNnCQ4OZteuXbRu3Zrq1atz9+5dLl++zIEDB/Dz81MdYvLy8mL+/PlMmDCBqKgo7Ozs+PfffwkLC6N79+5s3ry5RNd56NCh7Nixg507d9KqVSvat29PcnIyv/32Gy1atOCPP/5Q629oaIi/vz/z5s2jZcuWdO3alfT0dPbt28f9+/dp1aqVxpeIvb09NjY27N+/n4EDB2JnZ4eRkRFdunTB2dmZwYMHs3v3brp06cL777+Pubk5x48f58CBA3h4eLBlyxa1+S1cuJA9e/bw7rvvUqtWLSpWrMjFixcJCwujfPnyavff9evXj3/++Ycff/yRRo0a0a5dO2xtbUlKSuLatWtER0fTtm1b1q1bpxrTtm1bQkJC6N27Ny1btsTU1BRnZ2e6dOkCwI8//ljs9/GNHj2aX375hSVLluDv70/VqlULHDN27FjWr1/Pv//+W+Tl+fn5ERQU9Fxji9OQIUP466+/+Ouvv2jZsiWdOnUiPT2dbdu2cevWLby8vFS3MgDUrFmTKVOmMHHiRFq3bk3Pnj2pXLkyu3fvJjExkfr163PmzBm1Zdjb27N48WKGDBlCixYtaN++PXZ2dmRmZnLz5k0OHjzIkydP8nxeqr6T4NMDH3/8MU5OTixYsIDo6Gh27dpF5cqVsbe3Z8SIEQWONzY2Jjg4mE2bNrF27Vr+/PNP1YUTNjY2DB8+HC8vL1X/atWq8ccffzB16lQOHDjAnj17sLe3Z86cObi5uZV48JmamvL7778zY8YMfvvtN5YuXYqtrS0jR46ke/fuGsEHOZfDV6lShdWrV/PTTz9hbm5OmzZtmDhxosaDkiEnLNeuXcuUKVPYtWsXycnJZGdnY21tjbOzM+3bt2f9+vXMnj2b3377DUNDQ5o0acK2bdu4cuWKRvD5+flRuXJljh49yqFDh0hPT6datWp4eXkxdOhQjas7Z82aRceOHVmxYgVRUVHcv3+fSpUqYW1tja+vr8bVjTNmzMDQ0JDw8HAOHjxIZmYm3t7equArCdbW1gwYMIDFixcze/ZsZsyYUeAYhULB6NGjmTBhQpGXl3uYNPd5obpiYmLC5s2bWbJkCSEhIQQFBWFoaIijoyPjxo1T7RE+bejQoVhZWTF//nzWr1/P66+/Trt27Zg2bRp+fn5al5P7VKBFixYRERFBeHg4ZmZmWFlZ0b59ezw8PEp6Vcssg8TExBe7+UUIIYQoQ+QcnxBCCL0iwSeEEEKvSPAJIYTQKxJ8Qggh9IoEnxBCCL0iwSeEEEKvSPAJIYTQKxJ8z+HZV/CUJVK7bkjtuiG160Zpr12CTwghhF6R4BNCCKFXJPiEEELoFQk+IYQQekXeziCEeOVlZGSQmpqq6zKKxMzMjKSkJF2X8VxeRu3Gxsa89tprzze2mGsRQohSJSMjgwcPHqBQKDAwMNB1OYVmamqq9gLisuRl1J6amsqTJ08wNTUt8lg51CmEeKWlpqaWudATBatQoQKPHz9+rrESfEKIV56E3qvnRT5TCT4hhBB6RYJPCCGEXpHgE0KIV1y3bt0YPXp0kca4uLiwYMGCEqpIt+SqTiGEKIV69uyJs7MzgYGBLzyvNWvWYGxctK/78PBwKlSo8MLLLo0k+IQQooxKT0+nXLlyBfarXLlykeddtWrV5ympTJBDnUIIUcoMHjyY/fv3s3z5chQKBQqFgrVr16JQKNi1axfu7u5YWFiwe/duLl++jLe3N3Xr1sXa2prWrVsTGhqqNr9nD3W6uLgQGBjIl19+iY2NDU5OTsyfP19tzLOHOhUKBT/99BP9+/fH2tqahg0b8uuvv6qNOXLkCK1bt6ZmzZq0atWKXbt2oVAo2LdvXwlspecnwSeEEAXJzsbw7FmMd+3C8OxZyM4u0cXNmDGDpk2b0q9fP86fP8/58+epUaMGAFOnTmXixIkcPnyYpk2bkpKSQocOHfjtt9+IioqiR48efPzxx1y4cCHfZSxevBgnJyciIiL44osvmDx5MocOHcp3zKxZs+jatStRUVH06tWLoUOHcu3aNQBSUlLw9PSkbt26hIWFMX36dCZPnlw8G6SYSfAJIUR+srMxWbECkx9/xHjnTkx+/BGTFStKNPwqVapEuXLlqFChAkqlEqVSiaFhztf12LFjcXd3p1atWlStWhUXFxcGDBhA/fr1qV27NqNGjaJhw4Zs2bIl32W4u7szaNAgateujb+/P7Vr1yYiIiLfMZ6ennh6elK7dm2++uorjI2N2b9/PwAbNmwgMzOTBQsWUK9ePdq2bcvIkSOLZ4MUMznHJ4QQ+TCMicHw9Gn1ttOnMYyJIcvJ6aXX07hxY7V/p6amMnPmTMLCwrh9+zYZGRk8fvyY+vXr5zufZ6dbWVlx586dQo8xNjamSpUqqjEXLlzA0dGR8uXLq56o0rRp00Kv18skwSeEEPkwvHEjz3ZdBN+zD2aeNGkSf/31F19//TV2dnZUqFCBTz/9lLS0tHzn8+xFMQYGBmQXsBeb35js7Owy84QcOdQphBD5yPr/59YK215cTExMyMzMLLDfgQMH8PLywsPDA2dnZ6ytrbl8+XKJ1qaNg4MDZ8+e5dGjR6q2o0ePvvQ6CkOCTwgh8pHl6EiWs7N6m7MzWY6OJbpcGxsbjh49ytWrV0lISCArK0trPzs7O7Zv386JEyc4c+YMgwYN4smTJyVamzZ9+vTByMiIL774gvPnz7N3717mzp0LlL5npUrwCSFEfgwMSPP1JW3QIDK6diVt0CDSfH2hhL/MBw8ejImJCc2bN8fOzo4beRxy/fbbb7GwsKBr16706dOHt99+mxYtWpRobdq8/vrrrF+/npiYGDp06MCkSZMYO3YsQKl7vZJBYmJiyV6X+wqKjY3F3t5e12U8F6ldN6R23YiNjcXS0pJKlSrpupQie/z4cakLjMLKrX3Hjh189NFHXLx4kSpVqhT7cpKSkp7rs5WLW4QQQhSLdevWqW6zuHTpEuPHj6dz584lEnovQoJPCCFEsbhz5w4BAQHExcVhaWlJp06dmDp1qq7L0qDzc3xBQUE0aNAApVKJm5sb0dHR+faPiorCzc0NpVJJw4YNWblypdr05cuX07JlS2xsbLCxsaFDhw6EhYWV5CoIIYQAvvjiC06dOsW1a9c4ffo0c+bMoWLFirouS4NOg2/z5s2MGzeOkSNHEhkZiaurK3369OH69eta+1+5coW+ffvi6upKZGQkI0aMYMyYMWpPKLC2tmbatGlEREQQHh5O69at6devH6efuQFVCCGEftJp8C1atIgPP/yQ/v374+DgQGBgIEqlUmMvLteqVauwsrIiMDAQBwcH+vfvj7e3NwsXLlT16datGx06dKB27drUqVOHSZMm8frrr3P48OGXtVpCCCFKMZ0FX1paGidOnMDd3V2t3d3dnYMHD2odc+jQIY3+7dq14/jx46Snp2v0z8zMZNOmTaSmpuLq6lp8xQshhCizdHZxS0JCApmZmVhYWKi1W1hYEB8fr3VMfHw8bdq00eifkZFBQkICVlZWAJw5c4aOHTvy+PFjXnvtNdasWVPgc+tiY2OLVH9R+5cmUrtuSO26kZycjKmpqa7LeC65z7wsi15G7cnJyVrzoqDbb3R+Veezd/QX9Lw3bf2fbbe3t2ffvn0kJSWxdetWBg8ezPbt23HK57l6RblPqazf1yS1v3xSu27ExsZibm5eJu+HexXu4ytp5ubm2NjYFHmczoKvSpUqGBkZaaT13bt3NfYCc1laWmrtb2xszBtvvKFqMzExoXbt2kDOk8yPHTvG4sWL1c4FCiGE0E86O8dnYmJCo0aNCA8PV2sPDw+nWbNmWse4urqyd+9ejf6NGzfWeGr407Kysgp8UrkQQrxKnn3r+rP/1qZFixYEBAS88LJ79uxZ4LJ0SaeHOocMGYK/vz9NmjShWbNmrFy5ktu3b+Pj4wOAv78/AMuWLQPAx8eH5cuXM27cOHx8fDh48CDr1q0jKChINc+pU6fSsWNHqlevTkpKChs3biQqKoqQkJCXv4JCCFFKrFmzBmPj4v3KX7t2LWPGjOHmzZtq7StXruT1118v1mUVJ50GX69evbh37x6BgYHExcXh6OhISEgItra2ABoPZa1VqxYhISFMmDCBlStXYmVlxcyZM/Hw8FD1iYuLY9CgQcTHx2Nubk79+vXZuHEj7dq1e6nrJoQQpUnlypVf6rJK8/lJnT+5xc/Pj1OnThEfH09ERATvvPOOatqOHTvYsWOHWv93332XyMhI4uPjOXnyJAMGDFCbvmTJEk6fPk18fDwXL15ky5YtEnpCiDJl1apVODs7k5GRodbu5+eHt7c3ly9fxtvbm7p162JtbU3r1q0JDQ3Nd57PHuq8c+cO3t7eWFlZ4ezszOrVqzXGLFy4kJYtW2JtbY2joyPDhg0jMTERgH379jFkyBBSU1NRKBQoFArVYdJnD3UmJiby6aefUrNmTaysrPDw8CAmJkY1fe3atVSvXp2IiAhatGiBtbU17733HleuXCnytisMnQefEEKUdtnZcPasIbt2GXP2rCEFvKj8hfXs2ZPk5GS1axpSU1PZuXMnnp6epKSk0KFDB3777TeioqLo0aMHH3/8MRcuXCj0Mj777DMuX77M77//ztq1a1m/fj3Xrl1T62NoaEhAQAD79+9n+fLlHD16lDFjxgDQrFkzAgICqFChAufPn+f8+fMMGzZM67IGDx7M0aNHWbduHbt376Z8+fJ88MEHai+tffLkCXPnzmXhwoXs2rWLpKQkRowYUYStVng6v51BCCFKs+xsWLHChNOn/28/wdk5C1/ftBJ7JZ9CoaBdu3aEhITQvn17ALZv346xsTGdO3fGzMwMFxcXVf9Ro0YRGhrKli1bCnVRycWLF/nzzz8JDQ2lefPmQM7RskaNGqn1++yzz1R/r1mzJtOnT+fDDz9k6dKlmJiYYG5ujoGBAUqlMs9l/fvvv/zxxx/s2LFDdURv2bJluLi4sGHDBj755BMAMjIymD17turWmWHDhjFkyBCysrIwNCzefTQJPiGEyEdMjKFa6AGcPm1ITIwhTk7a34peHHr37s2XX37Jw4cPqVChAhs2bKBHjx6YmZmRmprKzJkzCQsL4/bt22RkZPD48eMCH9SR6/z58xgaGtKkSRNVm62tLdWqVVPrFxERwbx587hw4QLJyclkZmaSlpZGXFycRt+ClvX007MqVaqEk5MT586dU7WZmpqq3S9qZWVFeno6SUlJxX5+Ug51CiFEPm7c0P41mVd7cenQoQNGRkbs3LmTO3fusHfvXvr27QvApEmT+P3335kwYQI7duxg3759NGnSpNC3bWUX4ljttWvX8PT0pG7duvz000/s3btXdS90UW4Py29ZTz945NkrTnOnZWUV/y8XEnxCCJGPGjW0f/Hm1V5cTE1N8fDwYMOGDWzevBmlUsm7774LwIEDB/Dy8sLDwwNnZ2esra25fPlyoeft4OBAVlYWx44dU7Vdv36d//77T/Xv48ePk5aWRkBAAK6urtSpU0dtOuTcj52ZmZnvsurVq0dWVhaHDh1StSUnJ3P27FkcHBwKXXNxkuATQoh8ODpm4eysHnLOzlk4OpZs8AH07duX3bt3s2rVKj744APVuS47Ozu2b9/OiRMnOHPmDIMGDeLJkyeFnq+9vT3t27dn+PDhHDp0iJMnT/LZZ59Rvnx5VR87OzuysrJYvHgxV65cYePGjSxdulRtPra2tjx+/Jjw8HASEhJ4+PChxrLs7Ozo2rUrw4cPJzo6WlVvxYoV6dOnz3NumRcjwSeEEPkwMABf37cQwAUAACAASURBVDQGDUqja9cMBg1KK9ELW572zjvvUK1aNc6dO6c6zAnw7bffYmFhQdeuXenTpw9vv/02LVq0KNK8Fy9ejK2tLT169MDb25s+ffqo7qEGcHZ2ZsaMGSxevJjmzZsTHBzM119/rTaPZs2aMWDAAHx9fbGzs+OHH37Ic1lvvfUW3t7etGvXjkePHrFx40a1oH2ZDBITE0v4wtxXT1l/aK/U/vJJ7boRGxuLpaUllSpV0nUpRSYPqS5YUlLSc322sscnhBBCr0jwCSGE0CsSfEIIIfSKBJ8QQgi9IsEnhBBCr0jwCSFeeYV5UokoW17kM5XgE0K80l577TUSExMl/F4xDx8+fO5bJuQh1UKIV5qxsTEVK1YkOTlZ16UUSXJyMubm5rou47m8jNqNjY0xNTV9vrHFXIsQQpQ6xsbGZe4m9vj4eGxsbHRdxnMp7bXLoU4hhBB6RYJPCCGEXpHgE0IIoVck+IQQQugVCT4hhBB6RYJPCCGEXpHgE0IIoVck+IQQQugVCT4hhBB6RYJPCCGEXpHgE0IIoVck+IQQQugVCT4hhBB6RYJPCCGEXpHgE0IIoVck+IQQQugVCT4hhBB6RYJPCCGEXpHgE0IIoVck+IQQQugVCT4hhBB6RYJPCCGEXpHgE0IIoVck+IQQQugVY10XIIQQQo9lZ2MYE4PhjRtk1ahBlqMjGBiU6CIl+IQQQuhGdjYmK1ZgePq0qinL2Zk0X98SDT851CmEEEInDGNi1EIPwPD0aQxjYkp2uSU690IICgqiQYMGKJVK3NzciI6Ozrd/VFQUbm5uKJVKGjZsyMqVK9Wmz507l7Zt22JjY4OdnR2enp6cPXu2JFdBCCHEczC8caNI7cW23BKdewE2b97MuHHjGDlyJJGRkbi6utKnTx+uX7+utf+VK1fo27cvrq6uREZGMmLECMaMGcOWLVtUfaKiovD19SUsLIytW7dibGzM+++/z/3791/WagkhhCiErBo1itReXHQafIsWLeLDDz+kf//+ODg4EBgYiFKp1NiLy7Vq1SqsrKwIDAzEwcGB/v374+3tzcKFC1V9Nm/ezEcffYSTkxP169dn2bJl3L17lwMHDrys1RJCCFEIWY6OZDk7q7c5O+dc4FKCdHZxS1paGidOnGDYsGFq7e7u7hw8eFDrmEOHDuHu7q7W1q5dO3755RfS09MpV66cxpiUlBSysrJQKBTFV7wQQogXZ2BAmq+v/lzVmZCQQGZmJhYWFmrtFhYWxMfHax0THx9PmzZtNPpnZGSQkJCAlZWVxphx48bh4uKCq6trvvXExsYWqf6i9i9NpHbdkNp1Q2rXjSLVXq4cvPlmzt8vXnzhZdvb2+c7Xee3Mxg8k+zZ2dkabQX119YOMGHCBA4cOEBoaChGRkb51lHQhnpabGxskfqXJlK7bkjtuiG160Zpr11nwVelShWMjIw09u7u3r2rsReYy9LSUmt/Y2Nj3njjDbX28ePHs3nzZrZt20atWrWKtXYhhBBll84ubjExMaFRo0aEh4ertYeHh9OsWTOtY1xdXdm7d69G/8aNG6ud3xs7diwbN25k69at1K1bt9hrF0IIUXbp9KrOIUOGsG7dOoKDgzl//jxjx47l9u3b+Pj4AODv74+/v7+qv4+PD7du3WLcuHGcP3+e4OBg1q1bx9ChQ1V9Ro0axbp16wgKCkKhUBAXF0dcXBwpKSkvff2EEEKUPjo9x9erVy/u3btHYGAgcXFxODo6EhISgq2tLQA3nrmJsVatWoSEhDBhwgRWrlyJlZUVM2fOxMPDQ9UnKCgIQK0NcvYCx48fX8JrJIQQorTT+cUtfn5++Pn5aZ22Y8cOjbZ3332XyMjIPOeXmJhYbLUJIYR49ej8kWVCCCHEyyTBJ4QQQq9I8AkhhNArEnxCCCH0igSfEEIIvSLBJ4QQQq9I8AkhhNArEnxCCCH0igSfEEIIvSLBJ4QQQq889yPLDhw4QGRkJHfu3MHf3586deqQmprKuXPnsLe3x9zcvDjrFEIIIYpFkYMvLS2NAQMGsHPnTtVLY9977z3q1KmDkZERH3zwAUOGDGHUqFElUa8QQgjxQop8qDMgIICwsDACAwM5fPiw6g3oAGZmZrz//vv88ccfxVqkEEIIUVyKHHwbNmzgf//7H76+vhpvPQewt7fnypUrxVGbEEIIUeyKHHx37tzBxcUlz+mmpqakpqa+UFFCCCFESSly8CmVynz36I4ePUrNmjVfpCYhhBCixBQ5+Hr06MGqVau4ePGiqs3AwACAP/74gw0bNtCrV6/iq1AIIYQoRkUOvrFjx2JjY4Obmxt+fn4YGBgwd+5c2rdvT79+/WjUqBFffPFFSdQqhBBCvLAiB1/FihXZtWsXI0aM4M6dO5iZmXHgwAFSU1MZP34827Ztw8zMrCRqFUIIIV7Yc93AbmZmxsiRIxk5cmRx1yOEEEKUqGJ7ZNmhQ4fYtWuXXNEphBCiVCty8M2aNYuePXuqtXl6etK5c2c8PT1xdXXl2rVrxVagEEIIUZyKHHy///47Tk5Oqn/v3LmTXbt28cUXX7BixQrS0tKYNWtWsRYphBBCFJcin+O7ceMG9vb2qn9v27YNOzs7pkyZAkBsbCxr1qwpvgqFEEKIYvRc5/gyMzNVf4+IiKBdu3aqf1tbW3Pnzp0Xr0wIIYQoAUUOvjp16rBjxw4A/vrrL27fvk379u1V02/evIlCoSi+CoUQQohiVORDncOGDcPX15eaNWvy8OFD6tatS9u2bVXTIyIi8n2WpxBCCKFLRQ6+nj17UrlyZcLCwjA3N8fX1xdj45zZ3L9/nypVqtC3b99iL1SIUic7G8OYGAxv3CCrRg2yHB3h/z++TwhRej3XDext2rShTZs2Gu2VK1eWC1uEfsjOxmTFCgxPn1Y1ZTk7k+brK+EnRCn3XMG3c+dOVq9ezZUrV0hMTFR7GS3kPLQ6JiamWAoUojQyjIlRCz0Aw9OnMYyJIeup232EEKVPkYNv5syZzJw5k0qVKuHs7Ezt2rVLoi4hSjXDGzfybJfgE6J0K3LwLV++HDc3N9avX4+pqWlJ1CREqZdVo0aR2oUQpUeRb2dIT0+nR48eEnpCr2U5OpLl7Kze5uycc4GLEKJUK/Ien7u7O8ePH8fHx6ck6hGibDAwIM3XV67qFKIMKvIeX2BgIMePH2fGjBlcv35d48IWIfSGgQFZTk5kdOyYc15PQk+IMqHIe3xVq1ald+/eTJ8+Pc+HURsYGJCQkPDCxQkhhBDFrcjBN3XqVObPn0/NmjVp0qQJ5ubmJVGXEEIIUSKKHHzBwcF07dpVblQXQghRJhX5HF9WVpba2xiEEEKIsqTIwdelSxeioqJKohYhhBCixBU5+EaOHElsbCxffPEFR44c4fbt29y5c0fjjxBCCFEaFfkc39tvvw3AqVOnWL16dZ797t279/xVCSGEECWkyME3ZswYDOR+JSGEEGVUkYNv/PjxJVGHKEvkPXRCiDLsuV5LJPSYvIdOCFHGFfniluIWFBREgwYNUCqVuLm5ER0dnW//qKgo3NzcUCqVNGzYkJUrV6pN//vvv/Hy8sLR0RGFQsHatWtLsny9k9976IQQoizQafBt3ryZcePGMXLkSCIjI3F1daVPnz5cv35da/8rV67Qt29fXF1diYyMZMSIEYwZM4YtW7ao+qSmpuLk5MSMGTMoX778y1oVvZHfe+iEEKIs0GnwLVq0iA8//JD+/fvj4OBAYGAgSqVSYy8u16pVq7CysiIwMBAHBwf69++Pt7c3CxcuVPXp2LEjkydPxsPDA0NDne/QvnLkPXRCiLJOZ8mQlpbGiRMncHd3V2t3d3fn4MGDWsccOnRIo3+7du04fvw46enpJVar+D/yHjohRFmns4tbEhISyMzMxMLCQq3dwsKC+Ph4rWPi4+Np06aNRv+MjAwSEhKwsrJ67npiY2NLtH9p8sK1t26NWfXqmMbF8USp5LGdHVy8WDzFFUCvt7sOSe26IbU/H3t7+3yn6/yqzmfvCczOzs73PkFt/bW1F1VBG+ppsbGxRepfmhRb7XXrvvg8iki2u25I7bohtZccnR3qrFKlCkZGRhp7d3fv3tXYC8xlaWmptb+xsTFvvPFGidUqhBDi1aGz4DMxMaFRo0aEh4ertYeHh9OsWTOtY1xdXdm7d69G/8aNG1OuXLmSKlUIIcQrRKeHOocMGYK/vz9NmjShWbNmrFy5ktu3b+Pj4wOAv78/AMuWLQPAx8eH5cuXM27cOHx8fDh48CDr1q0jKChINc+UlBQuXboE5LxC6caNG5w8eZLKlStjY2PzktdQvMqysyEmxpAbNwypUSMLR8csuYdfiDJAp8HXq1cv7t27R2BgIHFxcTg6OhISEoKtrS0AN565N6xWrVqEhIQwYcIEVq5ciZWVFTNnzsTDw0PV5/jx43Tv3l3174CAAAICAvD29mbJkiUvZ8XEKy87G1asMOH06f87aOLsnIWvb5qEnxClnM4vbvHz88PPz0/rtB07dmi0vfvuu0RGRuY5v1atWpGYmFhs9RWaPL9Sr8TEGKqFHsDp04bExBji5JSlo6qEEIWh8+B7JcjzK/XOjRvaT4/fuCHBJ0RpJ482KQby/Er9U6OG9nDLq10IUXpI8BUDeX6l/nF0zMLZWT3knJ1zLnARQpRucqizGMjzK/WPgQH4+qbJVZ1ClEESfMUg9/mVz57jk+dXvtoMDMDJKUvO6QlRxkjwFQcDA9J8feWqTiGEKAMk+IqLgQFZTk5kOTnpuhIhhBD5kItbhBBC6BUJPiGEEHpFgk8IIYRekeATQgihVyT4hBBC6BW5qlMIIYTO6OL1XhJ8QgghdEJXr/eSQ51CCCF0Ir/Xe5UkCT4hhBA6kd/rvUqSBJ8QQgid0NXrvST4hBBC6ISuXu8lF7cIIYTQCV293kuCTwghhM7o4vVecqhTCCGEXpHgE0IIoVck+IQQQugVCT4hhBB6RS5uEUWmi2frCSFEcZHgE0Wiq2frCSFEcZFDnaJIdPVsPSGEKC7ybSWKRFfP1hNCiOIi31aiSHT1bD0hhCguEnyiSHT1bD0hhCgucnGLKBJdPVtPCCGKiwSfKDJdPFtPCCGKixzqFEIIoVck+IQQQugVCT4hhBB6RYJPCCGEXpHgE0IIoVck+IQQQugVCT4hhBB6RYJPCCGEXpHgE0IIoVfkyS3FRF7OKoQQZYMEXzGQl7MKIUTZIYc6i4G8nFUIIcoOnX8zBwUF0aBBA5RKJW5ubkRHR+fbPyoqCjc3N5RKJQ0bNmTlypUvPM8XJS9nFUKIskOn38ybN29m3LhxjBw5ksjISFxdXenTpw/Xr1/X2v/KlSv07dsXV1dXIiMjGTFiBGPGjGHLli3PPc/iIC9nFUKIskOnwbdo0SI+/PBD+vfvj4ODA4GBgSiVSq17cQCrVq3CysqKwMBAHBwc6N+/P97e3ixcuPC551kc5OWsQghRdujs4pa0tDROnDjBsGHD1Nrd3d05ePCg1jGHDh3C3d1dra1du3b88ssvpKenk52dXeR5Fgd5OasQQpQdOgu+hIQEMjMzsbCwUGu3sLAgPj5e65j4+HjatGmj0T8jI4OEhASys7OLPM9csbGxRapfW/9y5eDNN3P+fvFikWb3UhV1XUsTqV03pHbdkNqfj729fb7TdX47g8Ezu0XZ2dkabQX1z21/+u9FmScUvKGeFhsbW6T+pYnUrhtSu25I7bpR2mvXWfBVqVIFIyMjjT2xu3fvauyx5bK0tNTa39jYmDfeeIPs7Owiz1MIIYR+0dnFLSYmJjRq1Ijw8HC19vDwcJo1a6Z1jKurK3v37tXo37hxY8qVK/dc8xRCCKFfdHpV55AhQ1i3bh3BwcGcP3+esWPHcvv2bXx8fADw9/fH399f1d/Hx4dbt24xbtw4zp8/T3BwMOvWrWPo0KGFnqcQQgj9ptNzfL169eLevXsEBgYSFxeHo6MjISEh2NraAnDjxg21/rVq1SIkJIQJEyawcuVKrKysmDlzJh4eHoWepxBCCP2m84tb/Pz88PPz0zptx44dGm3vvvsukZGRzz1PIYQQ+k2eqSWEEEKvSPAJIYTQKxJ8Qggh9IoEnxBCCL0iwSeEEEKvSPAJIYTQKxJ8Qggh9IoEnxBCCL0iwSeEEEKvSPAJIYTQKxJ8Qggh9IoEnxBCCL0iwSeEEEKvSPAJIYTQKxJ8Qggh9IoEnxBCCL0iwSeEEEKvSPAJIYTQKxJ8Qggh9IoEnxBCCL0iwSeEEEKvSPAJIYTQKxJ8Qggh9IoEnxBCCL0iwSeEEEKvSPAJIYTQKxJ8Qggh9IoEnxBCCL1ikJiYmK3rIoQQQoiXRfb4hBBC6BUJPiGEEHpFgk8IIYRekeATQgihVyT4hBBC6BUJviIKCgqiQYMGKJVK3NzciI6O1nVJagICAlAoFGp/6tatq5qenZ1NQEAA9erVw8rKim7duhETE6OTWv/++2+8vLxwdHREoVCwdu1atemFqTUxMZFBgwZha2uLra0tgwYNIjExUee1Dx48WONzaN++vVqfJ0+eMHr0aGrXro21tTVeXl7cvHmzxGufO3cubdu2xcbGBjs7Ozw9PTl79qxan9K67QtTe2nd9suXL6dly5bY2NhgY2NDhw4dCAsLU00vrdu8MLWX1m2eFwm+Iti8eTPjxo1j5MiRREZG4urqSp8+fbh+/bquS1Njb2/P+fPnVX+eDucffviBRYsWMXPmTPbs2YOFhQU9e/bkwYMHL73O1NRUnJycmDFjBuXLl9eYXpha/fz8OHnyJBs2bGDjxo2cPHkSf39/ndcO0KZNG7XPYcOGDWrTx48fz7Zt21ixYgU7d+7kwYMHeHp6kpmZWaK1R0VF4evrS1hYGFu3bsXY2Jj333+f+/fvq/qU1m1fmNqhdG57a2trpk2bRkREBOHh4bRu3Zp+/fpx+vRpoPRu88LUDqVzm+dF7uMrgnbt2lG/fn3mz5+vanvrrbfw8PBgypQpOqzs/wQEBLB161b279+vMS07O5t69eoxcOBARo0aBcCjR4+wt7fn66+/xsfH52WXq1K9enVmzZpFv379Cl3r+fPnadasGaGhoTRv3hyA/fv306VLFw4fPoy9vb1Oaoec34Dv3bvHr7/+qnVMUlISderUYdGiRfTt2xeAGzdu4OLiwsaNG2nXrt1LqR0gJSUFW1tb1q5dS5cuXcrUtn+2dihb275WrVpMmTKF//3vf2Vmmz9bu4+PT5na5iB7fIWWlpbGiRMncHd3V2t3d3fn4MGDOqpKuytXruDo6EiDBg0YMGAAV65cAeDq1avExcWprUP58uVp2bJlqVuHwtR66NAhXn/9dZo1a6bq07x5c1577bVSsT779++nTp06NGnShM8//5w7d+6opp04cYL09HS19atRowYODg4vvfaUlBSysrJQKBRA2dr2z9aeq7Rv+8zMTDZt2kRqaiqurq5laps/W3uu0r7Nn2b80pdYRiUkJJCZmYmFhYVau4WFBfHx8TqqSlPTpk1ZvHgx9vb23L17l8DAQDp27MiBAweIi4sD0LoO//33ny7KzVNhao2Pj6dKlSoYGBiophsYGFC1alWdfybt27ene/fu1KxZk2vXrvHNN9/Qo0cP9u7di6mpKfHx8RgZGVGlShW1cbr4eRo3bhwuLi6qL7GytO2frR1K97Y/c+YMHTt25PHjx7z22musWbOG+vXrq778S/M2z6t2KN3bXBsJviJ6+ocOcg7JPdumSx06dFD7d9OmTWnUqBHr1q3j7bffBkr/OjytoFq11V0a1qd3796qv9evX59GjRrh4uJCWFgYPXr0yHPcy659woQJHDhwgNDQUIyMjNSmlfZtn1ftpXnb29vbs2/fPpKSkti6dSuDBw9m+/btqumleZvnVbuTk1Op3ubayKHOQqpSpQpGRkYav53cvXtX47e00uT111+nXr16XLp0CaVSCVAm1qEwtVpaWnL37l2ys//vNHV2djYJCQmlbn2qVauGtbU1ly5dAnJqz8zMJCEhQa3fy/wsxo8fz6ZNm9i6dSu1atVStZeFbZ9X7dqUpm1vYmJC7dq1ady4MVOmTMHFxYXFixeXiW2eV+3alKZtro0EXyGZmJjQqFEjwsPD1drDw8PVjrmXNo8fPyY2NhalUknNmjVRKpVq6/D48WP2799f6tahMLW6urqSkpLCoUOHVH0OHTpEampqqVufhIQE/vvvP9UXXKNGjShXrpza+t28eVN1AUNJGzt2LBs3bmTr1q1qt7tA6d/2+dWuTWnb9k/LysoiLS2t1G/z/GrXpjRvcwCjcePGTX3pSy2jKlasSEBAAFZWVpiZmREYGEh0dDQLFy6kUqVKui4PgIkTJ2JiYkJWVhYXL15k9OjRXLp0iXnz5qFQKMjMzGTevHnUqVOHzMxMvvrqK+Li4vj+++8xNTV9qbWmpKRw7tw54uLiWL16NU5OTpibm5OWlkalSpUKrLVq1aocOXKEjRs30qBBA27evMnw4cN56623SvwS7/xqNzIyYvr06bz++utkZGRw6tQphg0bRmZmJoGBgZiammJmZsbt27dZvnw5zs7OJCUlMXz4cMzNzZk2bRqGhiX3O+moUaNYv349P/30EzVq1CA1NZXU1FQg5xc8AwODUrvtC6o9JSWl1G77qVOnqv5v3rx5kyVLlhASEsLUqVOxs7Mrtdu8oNqVSmWp3eZ5kdsZiigoKIgffviBuLg4HB0d+e6773jnnXd0XZbKgAEDiI6OJiEhgapVq9K0aVO++uor6tWrB+QcGpkxYwY//fQTiYmJNGnShNmzZ+Pk5PTSa923bx/du3fXaPf29mbJkiWFqvX+/fuMHTuWP/74A4AuXbowa9Ysjav8Xmbtc+fOpV+/fpw8eZKkpCSUSiWtWrXiq6++okaNGqq+jx8/ZtKkSWzcuJHHjx/TunVr5syZo9anJOS1bcaOHcv48eOBwv2c6GLbF1T7o0ePSu22Hzx4MPv27SM+Ph5zc3Pq16/P559/rrqUv7Ru84JqL83bPC8SfEIIIfSKnOMTQgihVyT4hBBC6BUJPiGEEHpFgk8IIYRekeATQgihVyT4hBBC6BUJPlFmubi4qD0jMC9Xr17V+rLYV9HatWtRKBRcvXpV16UUSe4LlF+mffv2qb049fDhwwWO0UWd2rRo0UJVd2H+Dwh1Enyi1Pjxxx9LVTj9+uuveT6L8FUUGhpKQECArst46UaOHMmyZcuoXbu2rksptClTprBs2TKNtx2IwpHgE6XG8uXLWbduXbHP19bWltu3b+Pl5VWkcSEhISxZsqTY6ymtwsLCmDlzpk6WPXr0aG7fvq2TZbdp0wZPT88yFSKdO3fG09OTChUq6LqUMkmCT7zyDAwMMDMz03jtjq48evRI1yWUOsbGxpiZmem6DKEnJPiEhtzzGOfOnWPgwIHY2tpSs2ZNhg0bRnJyslrfnTt34unpiaOjI5aWljg7OzNlyhSePHmi1i8+Pp5hw4ZRv359LC0tqVevHp6enpw5cwbIOV8XGxvL33//rTp34eLiUqh6jx49SufOnbGysqJ+/foahye1neNLSUlh4sSJNGjQAKVSib29Pd27d2ffvn0AdOvWjd27d3P9+nW180C5Hj16xNSpU3FxccHS0pIGDRrwzTffaKx37nnIyMhI2rdvj1Kp5Pvvv2fgwIHUrl2b9PR0jfXp378/devWJSMjI9/1Pnz4MB07dkSpVOLs7My8efPUXlmTqzCf0eDBg1m1ahWA2vrmnitcu3YtHh4e1K1bF0tLS5o0acL3339PVlZWvjUCZGRkEBgYSJMmTbCysqJ27dp07NiRLVu2qPo8e+4s91yltj/dunVTm/+mTZto164d1apVw9bWFk9PT86dO1dgXQUJCwvjnXfeQalU0qRJE4KDg7X2K8y2+frrr6lataraW8lzTZo0CUtLS+7duwfApUuX+N///oeDgwNKpZL69evTv39/bt269cLrJHLIi2hFngYMGIC1tTWTJk3i1KlTBAcHc+PGDX777TdVnzVr1mBkZMSgQYNQKBQcPHiQBQsWcPPmTYKCglT9+vfvz5kzZxg0aBC2trYkJCQQHR3NxYsXqV+/PgEBAYwaNQpzc3NGjhwJwGuvvVZgjVevXsXLy4sPP/yQPn36sHnzZiZMmEC9evVwd3fPc9yIESP4/fff8fPzo169eiQlJXHkyBFOnTpFq1atGDVqFImJidy+fZvvvvtObWx2djYff/wxf/31F15eXjRt2pQDBw4we/ZsYmJiNM5TXrp0iU8++YRPPvmEjz76iBo1atC8eXM2bNjAn3/+SdeuXVV9k5KSCAsLw8fHB2PjvP97njt3jvfff5+KFSsyatQoTExM+Omnn7Rus8J8Rj4+Pty8eZPIyEiWLVumGlu1alUg5zC0vb097du3p3z58oSHhzN16lSSk5OZPHlyPp8QzJgxgzlz5vDxxx/TpEkTUlNTOXnyJEeOHMHDw0PrmHfeeUetDoBr167x7bffqr2/7fvvv2fq1Kl0794dLy8vUlNTCQoKolOnTkRERBT4rr68RERE8OGHH1K7dm2++uorHj9+zNdff616zc7TCrNtvL29mTNnDps2beLTTz9Vjc3KymLTpk106NCBN954g/T0dHr16sXjx4/x8/NDqVQSFxfHnj17uHXrFtbW1s+1PkKdPKRaaAgICGDmzJm0b9+eDRs2qN6Q/O233xIYGMjmzZtVofLw4UON8wyBgYF89913nD59murVq5OUlETNmjX5+uuvGTZsWJ7Lffvtt7G0tGTHjh2FqtPFxYXr16/z+++/06ZNGwCePHmCs7MzLVu25OeffwZywrFhw4YsWrSIfv36ATnvnOvbty+BgYF5zr93795cuHCBU6dOqbWHhobi5eXFqFGjmDhxoqp9/PjxZekhDAAAC45JREFULFmyRK2e3BrXrVunFnBZWVm4uLjw9ttv89NPP6nag4OD+fzzz9m7dy+NGjXKs7aPP/6Y0NBQDh06xJtvvgnkvNTzrbfeIjk5mX/++YeaNWsChfuMAIYPH86qVatITEzUWJ62eQwbNozNmzdz6dKlfF9p1apVK6ytrfn111/z7JP7M6dt2bnL79SpE3fv3mXv3r0olUquX79O48aNGTlypOqtEgC3b9/G1dWVHj16sHDhwjyXmfuGjW3bttGqVSu1aW5ubty4cYMjR45QuXJlAM6fP0/Lli3JzMxUq7Ow26Zjx45kZGSwZ88eVb+IiAg8PDwIDg6mR48eql+8fv755zx/KXiai4sLdevWZdOmTQX2Ff9HDnWKPA0cOFAVeoDqN9Vdu3ap2nL/w2dlZZGUlERCQgItW7YkOzubf/75BwAzMzPKlStHVFQU9+/fL9Ya7ezsVCEDYGpqStOmTbly5Uq+4ypWrMjRo0ef6/BRWFgYBgYGDB06VK39iy++UE1/WvXq1dVCD8DQ0JC+ffsSGhpKUlKSqv3XX3+lXr16+YZeZmYmu3fvpnPnzqrQg5y9s759+2r0L8xnVJDceeR+6SckJPDuu++SmppKbGxsvmMrVqxITEwMFy9eLNSytPn88885f/48P//8s2qva9u2bWRkZNC7d28SEhJUf8qVK0fTpk2JjIx8rmXFxcXxzz//4OXlpQo9AAcHB9UrhJ5W2G3j7e3NsWPH1NrWr1+PQqGgU6dOQM62Ati9e7fqPYOi+EnwiTzZ2dmp/btKlSooFAquX7+uaouJiaFPnz5Ur16dmjVrYmdnpzoHk/uFbmpqypQpU/jrr7+wt7enc+fOzJkzR20+z8vGxkajTaFQFBiw06ZN4+zZszg7O9OmTRu++eYbzp8/X6hlXrt2DaVSqXE/l5WVFZUqVeLatWtq7bl7Xs/y9vbm8ePHqnNdN27cIDo6Gk9Pz3yXf/fuXR4+fIi9vb3GtDp16mi0FeYzKsj+/fvp0qUL1apVo1atWtjZ2aleflrQPMaPH09SUhJNmzalefPmTJgwgWPHjhVquQDz589n48aNzJo1C1dXV1X7v//+C+S8mdzOzk7tz549e7h7926hl/G03M+vsNu3sNumZ8+emJqaqvZ8Hz16xPbt21XtALVq1eLTTz8lODgYOzs7PDw8WLx4MQkJCc+1LkI7CT6Rp6f39nI9ffFEUlIS3bt359y5c0yaNIlffvmF33//XXVxydMn94cOHcrRo0eZPn065ubmBAYG0rx5cyIiIl6oxryu1NR2kcfTevfuzYkTJ5gzZw42Njb8v/buNqTpLY4D+NenZBNqWyyN1AStObFAczLSUnM2NRzaGjlG4lOF9iKJZlGKrL1wFipoaSmJGoO5aZMVGpYK9iLxTQQLtYSEVhEZ+BA+hLb74t79a25rm1dvF3Y+4Avd2fmf/zm68z8Pv+O9e/eQkJDw2+k4V9i7Lo1Gs5t2//79OHToELRaLQBAp9MBACQSiUvXcNY+gHtt5Mj09DRycnIwNzeH6upqdHV1obe3FwqFwqU8jhw5glevXqG5uRkHDx6ERqNBamoq6urqnF57eHgYCoUCeXl5yM/Pt3rNct3u7m709vbafGk0Gqf52+NO/bpTNwwGA5mZmdDpdDCbzejr68PCwoLNg45KpcKLFy9QXl6OtbU1VFZWgsfjYXx8fEP3Q9gim1sIh6ampqxGfV+/fsXc3Bw1ynr+/DlmZmbw+PFjJCYmUumGh4ft5hcWFobS0lKUlpbCZDLh6NGjqK+vR1JSEgD7HzRbKSgoCAUFBSgoKMDs7CzS0tJQU1NDfRA5Kk9oaCiGhoYwOztrNer7/Pkz5ufnERoa6nIZpFIp5HI5TCYTtFotEhMTnf5HajabDTqdjjdv3ti8ZhkFWbjTRo7ut6+vD8vLy9BoNFb35s7pMAwGA1KpFFKpFEtLSzh16hRqampw8eJFhw8v09PTKCwsRExMjN21WMs0b3BwMCIjI10uizOWEbor9etu3UilUuj1eoyOjqKrqwthYWHg8/k26bhcLrhcLi5dugSj0Yjk5GQ0NzejoaHh39wa8Q8y4iMcam1ttXrCvXv3LgAgLS0NwM/R1q9pfvz4gTt37ljls7i4aBO7FhwcDDabbbVJgE6nO9zcsJnW1tZspucYDAb27t1rUx5703hCoRBms9kmbMLyoWRZr3GFWCyGn58fKisrMT4+7lKQvY+PD44dO4YnT57g3bt31M9nZmaoUeOvaQHnbQT8XKta3wb28lhZWUFLS4vTsgKgtulb0Gg0cDgcrKysYHFx0e57FhcXIZPJ4Ofnh87OTrubZ0QiEXx9fVFdXW131LnRqc7AwEBqZPrrlPnk5CQGBwet0rpbN6mpqQgMDERTUxOGhoZsRnvz8/M2YSwcDgc0Gu0/+dvwFGTERzj08eNHSCQSCIVCGI1GdHR0ICkpiVrg5/P5YLFYKCkpwfnz5+Hr6wuDwYBv375Z5TM1NQWRSITs7GxERkbC398fAwMDmJychFKppNLFxMSgvb0dKpUKERERCAgIQEZGxqbf18LCAqKiopCVlYXo6Ghs374do6OjePbsGc6ePWtVHoPBgCtXriAuLg7e3t4Qi8UQCoUQCAS4efMmTCYTYmNjMTY2Bq1Wi8zMTKvNNs4wmUykp6dDr9eDRqNBJBK59L5r165haGgIGRkZKC4uhp+fH9rb2xESEmLVWbvaRpb7Bf4+RUUgEMDX1xfp6elITU3Ftm3bkJubi/z8fHz//h0ajQbe3q49N8fHx+Pw4cOIjY0Fi8WC0WhEZ2cnhEIhtZljPZVKhdevX6OwsJCKrbTYtWsXUlJSEBYWBoVCgevXr0MgECArKwtMJhPv37/HwMAA4uLiUF9f71IZ11MoFBCLxTh+/Djy8vKwtLSE1tZWcLlcGI1GKp27dePj4wOJRELtNl3f8Y2MjEAul0MkEmHfvn0wm814+PAhFhYWyJmcm4h0fIRD9+/fR21tLdU5yWQyq5g2JpMJrVaLiooKVFdXIyAgACKRCIWFhUhISKDSBQcHQyKRYGRkBN3d3fDy8kJ4eDgaGxtx5swZKt3Vq1fx6dMnNDU1YX5+HiEhIVvS8dHpdBQXF2N4eBj9/f1YXV2lwi1KSkqodOfOncPExAS0Wi1aWlpgNpshFovh5eWFBw8eQKVSoaenBzqdDkFBQbh8+TLkcrnb5ZFKpTAYDDhx4oTDjmC9qKgo6PV6VFRU4NatW2Cz2SgqKgKbzbbabepqGwFAdnY2xsbGoNfr0d3dTe36jIiIgFqtxo0bN1BVVYWdO3ciNzcXiYmJyMnJcVrWkpIS9Pf3Y2RkBMvLy9izZw/KyspQVlbm8D2WQO+2tja0tbVZvZaQkICUlBQAwIULFxAREYHGxkbU1dVhdXUVu3fvBp/Pt/rdcldKSgrUajWUSiWUSiVCQkJQWVmJDx8+WHV8G6kbqVSK27dvIz4+3uZ80OjoaAgEAjx9+pQa6XK5XKjVapvAfWLjSBwfYcMSUzU5OWk3YJfYXIODgxCLxdDpdNQ0MrH1LHF8arUafD4fO3bs+O2hAZvl7du34PF4qK2tRVFR0YbymJ2dxdraGpKSksDhcEgcn5vIGh9B/GEdHR0ICgr67UkzxNaRyWQIDw/Hy5cv/5PrdXR0wN/fHydPntxwHhkZGQgPD4fJZNrEknkOMtVJEH9IT08PJiYm8OjRI1RVVf1vDtH2FAcOHEBvby/1PYfD2dLr9ff3Y2pqCq2trZDJZFbB8e5qaGigAtxZLNZmFdFjkI6PIP6QoqIiBAQE4PTp0ygtLf3TxfE4DAbDrY1I/1Z5eTm+fPmC5ORkp+ebOsPj8TapVJ6JrPERBEEQHoWs8REEQRAehXR8BEEQhEchHR9BEAThUUjHRxAEQXgU0vERBEEQHoV0fARBEIRH+QsDxMkzjN8IYgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize results\n",
    "# compare RNN to LSTM results\n",
    "\n",
    "df_res = df_res_22\n",
    "\n",
    "x_label = 'past_history_size'\n",
    "y_label = 'mse'\n",
    "z_label = 'val_mse'\n",
    "\n",
    "for model_type in model_types:\n",
    "    condition_1 = (df_res['model_type']== model_type)\n",
    "    \n",
    "    x = df_res[condition_1][x_label].values\n",
    "    y = df_res[condition_1][y_label].values\n",
    "    \n",
    "    z = df_res[condition_1][z_label].values\n",
    "    \n",
    "    plt.scatter(x, y, alpha=0.6, c=\"red\", linewidth=0.0, label='training')\n",
    "    plt.scatter(x, z, alpha=0.6, c=\"blue\", linewidth=0.0, label='validation')\n",
    "        \n",
    "    plt.xlabel('past history data size [days]')\n",
    "    plt.ylabel('mse')\n",
    "    plt.legend()\n",
    "    plt.title('clean dataset: {} model'.format(model_type))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3_link'></a>\n",
    "# 3. Distorted time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run RNN and LSTM model with noise added ontop of the clean data. Evaluate model performance for a range of variances of the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.1_link'></a>\n",
    "### 3.1 Evaluate model performance under varying noise levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=5*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 10  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "\n",
    "# initialize object\n",
    "try:\n",
    "    del mqd\n",
    "except: pass\n",
    "\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# set target feature \n",
    "mdq._selected_features = ['observations']\n",
    "\n",
    "\n",
    "# generate noisy observations by adding Gaussian noise to clean observations\n",
    "mean = 0.0\n",
    "std = 1.0\n",
    "noise = [np.random.normal(loc=mean, scale=std, size=None) for x in range(len(idx))]        \n",
    "noisy_observations = [noise[i]+observations[i] for i in range(len(noise))]\n",
    "\n",
    "# initialize dataframe to store time series\n",
    "df = pd.DataFrame(data={'observations': noisy_observations})\n",
    "df.index = idx\n",
    "\n",
    "# load dataframe into object\n",
    "mdq.df = df\n",
    "\n",
    "# initialize dataset from dataframe \n",
    "mdq.initialize_dataset()\n",
    "\n",
    "# standardize data\n",
    "mdq.standardize_data()\n",
    "\n",
    "# set number of time points for 1/ future forecasting points and 2/ the past, historical time points\n",
    "future_target_size = int(365/52)\n",
    "\n",
    "# specify model configuration: this is chosen basen on the results from the previous notebook 02_Freddie_Freeloader.ipynb\n",
    "units = 128  # number of units in each neural network layer\n",
    "num_layers = 2  # total number of layers\n",
    "epochs = 50\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: x:(1267, 7, 1), y:(1267, 7, 1)\n",
      "validation set shape: x:(532, 7, 1), y:(532, 7, 1)\n",
      "Epoch 1/50\n",
      "181/181 [==============================] - 1s 4ms/step - loss: 0.7974 - mse: 0.7974 - val_loss: 0.8475 - val_mse: 0.8475\n",
      "Epoch 2/50\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.7735 - mse: 0.7735 - val_loss: 0.8463 - val_mse: 0.8463\n",
      "Epoch 3/50\n",
      " 87/181 [=============>................] - ETA: 0s - loss: 0.7591 - mse: 0.7591"
     ]
    }
   ],
   "source": [
    "# initialize results dictionary\n",
    "res_3 = {'model_type': [], 'past_history_size': [], 'val_mse': []\n",
    "       , 'mse': [], 'total_training_time': []}\n",
    "\n",
    "# model type \n",
    "model_types = ['RNN', 'LSTM']\n",
    "\n",
    "for model_type in model_types:\n",
    "    \n",
    "    for past_history_size in past_history_sizes:\n",
    "        \n",
    "        # generate train and validation data\n",
    "        mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size)\n",
    "\n",
    "        # set number of steps per epoch\n",
    "        num_samples = mdq._num_samples\n",
    "        steps_per_epoch = int(num_samples/future_target_size)\n",
    "        validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "        # compile model\n",
    "        mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "        # fit model\n",
    "        mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "                      ,validation_steps=validation_steps, model_type=model_type)\n",
    "\n",
    "        # get errors\n",
    "        history = mdq._histories[model_type]\n",
    "        val_mse = history.history['val_mse'][-1]\n",
    "        mse = history.history['mse'][-1]\n",
    "\n",
    "        # get total training time\n",
    "        total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "\n",
    "        # append results to results dictionary\n",
    "        res_3['model_type'].append(model_type)\n",
    "        res_3['past_history_size'].append(past_history_size)\n",
    "        res_3['val_mse'].append(val_mse)\n",
    "        res_3['mse'].append(mse)\n",
    "        res_3['total_training_time'].append(total_training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.2_link'></a>\n",
    "### 3.2 Visualize and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary to dataframe\n",
    "df_res_32 = pd.DataFrame(res_3)\n",
    "\n",
    "# store dataframe as csv locally\n",
    "df_res_32.to_csv('../data/04_results_distored.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results\n",
    "# compare RNN to LSTM results\n",
    "\n",
    "df_res = df_res_32\n",
    "\n",
    "x_label = 'past_history_size'\n",
    "y_label = 'mse'\n",
    "z_label = 'val_mse'\n",
    "\n",
    "for model_type in model_types:\n",
    "    condition_1 = (df_res['model_type']== model_type)\n",
    "    \n",
    "    x = df_res[condition_1][x_label].values\n",
    "    y = df_res[condition_1][y_label].values\n",
    "    \n",
    "    z = df_res[condition_1][z_label].values\n",
    "    \n",
    "    plt.scatter(x, y, alpha=0.6, c=\"red\", linewidth=0.0, label='training')\n",
    "    plt.scatter(x, z, alpha=0.6, c=\"blue\", linewidth=0.0, label='validation')\n",
    "        \n",
    "    plt.xlabel('past history data size [days]')\n",
    "    plt.ylabel('mse')\n",
    "    plt.title('noisy dataset: {} model'.format(model_type))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
