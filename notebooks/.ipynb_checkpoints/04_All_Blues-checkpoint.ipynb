{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "#### In this notebook, the trial runs from the preceding notebook ('01_So_What.ipynb') are systematically extended to try to find an optimal configuration for the two models. The model parameters to be fine tuned are: number of epochs, number of layers and the number of units.\n",
    "\n",
    "#### The best performing model configuration will be used in the notebook '03_Blue_in_Green.ipynb' to analyze the impact of adding noise to the clean dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [1. Load modules](#Part1_link)\n",
    "* [2. Setup data](#Part2_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.1  Clean data](#Part2.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.2  Add noise](#Part2.2_link)\n",
    "* [3. Setup models and evaluate for various hyper-parameter choices](#Part3_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.1 Compile and fit LSTM and RNN model](#Part3.1_link)\n",
    "* [4. Visualize results](#Part4_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part1_link'></a>\n",
    "# 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import Kind_of_Blue  # own class with a collection of methods used in this analysis\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2_link'></a>\n",
    "# 2. Setup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.1_link'></a>\n",
    "### 2.1 Noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations in time series: 1820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcfc3423210>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=5*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 10  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "\n",
    "# generate Gaussian noise\n",
    "\n",
    "std = 0.5\n",
    "mean = 0.0\n",
    "observations = [observations[x] + np.random.normal(loc=mean, scale=std, size=None) for x in range(len(idx))]\n",
    "print('number of observations in time series: {}'.format(len(observations)))\n",
    "\n",
    "# initialize dataframe to store time series\n",
    "df = pd.DataFrame(data={'observations': observations})\n",
    "df.index = idx\n",
    "\n",
    "df.plot(alpha=0.5)\n",
    "\n",
    "print('something else')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps are repeated from the previous notebook, '01_So_What.ipynb', and are grouped into one single step here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: x:(909, 365, 1), y:(909, 7, 1)\n",
      "validation set shape: x:(174, 365, 1), y:(174, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "# initialize object\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# load dataframe into object\n",
    "mdq._selected_features = ['observations']\n",
    "mdq.df = df\n",
    "\n",
    "# initialize dataset from dataframe \n",
    "mdq.initialize_dataset()\n",
    "\n",
    "# standardize data\n",
    "mdq.standardize_data()\n",
    "\n",
    "# set number of time points for 1/ future forecasting points and 2/ the past, historical time points\n",
    "future_target_size = int(365/52)\n",
    "past_history_size = int(1*365)\n",
    "\n",
    "# generate train and validation data\n",
    "mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3_link'></a>\n",
    "# 3. Compile and fit models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.1_link'></a>\n",
    "### 3.1 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'RNN'\n",
    "\n",
    "# set number of steps per epoch\n",
    "num_samples = mdq._num_samples\n",
    "steps_per_epoch = int(num_samples/future_target_size)\n",
    "validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "units = 128  # number of units in each neural network layer\n",
    "num_layers = 2  # total number of layers\n",
    "epochs = 30\n",
    "\n",
    "# compile model\n",
    "mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "129/129 [==============================] - 13s 99ms/step - loss: 0.1085 - mse: 0.1085 - val_loss: 0.2357 - val_mse: 0.2357\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 12s 93ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 12s 93ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 11s 83ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 11s 86ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 11s 87ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 12s 97ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 12s 93ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 11s 87ms/step - loss: 0.0708 - mse: 0.0708 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 11s 83ms/step - loss: 0.0422 - mse: 0.0422 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 10s 81ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 10s 81ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 11s 84ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 13s 99ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 11s 86ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 13s 98ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 12s 89ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 11s 89ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 11s 86ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 23/30\n",
      " 19/129 [===>..........................] - ETA: 8s - loss: 0.0123 - mse: 0.0123"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "              ,validation_steps=validation_steps, model_type=model_type)\n",
    "\n",
    "# get errors\n",
    "history = mdq._histories[model_type]\n",
    "val_mse = history.history['val_mse'][-1]\n",
    "mse = history.history['mse'][-1]\n",
    "\n",
    "# get total training time\n",
    "total_training_time = sum(mdq._time_callbacks[model_type].times)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part4_link'></a>\n",
    "# 4. update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
