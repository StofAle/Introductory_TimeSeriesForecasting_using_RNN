{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "#### In this notebook, a continuous time series is generated and a neural network utilized to learn its shape and forecasts its future states.\n",
    "#### More specifically, the time series is given in the form of a sine wave. Two recurrent neural networks from tensorflow's Keras are trained: a simple RNN and an LSTM neural net. Error and performance metrics are evaluated for both and results visualized.\n",
    "\n",
    "#### Both models have the same number of units and are trained on the same number of epochs. Both use relu-activation functions and are optimized using an adam-optimizer.\n",
    "\n",
    "#### The steps outlined in this notebook will be used in the notebook '02_Freddie_Freeloader.ipynb' to analyze the dependence of model-parameter choices on the model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [1. Load modules](#Part1_link)\n",
    "* [2. Setup data](#Part2_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.1 Generate time series: sine wave](#Part2.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.2 Separate training and validation data ](#Part2.2_link)\n",
    "\n",
    "* [3. Feature scaling](#Part3_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.1 Standardize training data](#Part3.1_link)\n",
    "* [4. Preprocess data](#Part4_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[4.1 Cache, batch and shuffle using Tensorflow's data format](#Part4.1_link)\n",
    "* [5. Setup and compile model](#Part5_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[5.1 RNN](#Part5.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[5.2 LSTM](#Part5.2_link)\n",
    "* [6. Fit model](#Part6_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[6.1 RNN](#Part6.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[6.2 LSTM](#Part6.2_link)\n",
    "* [7. Loss and error metrics](#Part7_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[7.1 RNN](#Part7.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[7.2 LSTM](#Part7.2_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part1_link'></a>\n",
    "# 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import Kind_of_Blue  # own class with a collection of methods used in this analysis\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2_link'></a>\n",
    "# 2. Setup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.1_link'></a>\n",
    "### 2.1 Generate time series: sine wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this initial experiment is a simple sine wave. The number of data points in each period is kept fixed thoughout the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations in time series: 1820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-09</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-10</th>\n",
       "      <td>0.034516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-11</th>\n",
       "      <td>0.068991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-12</th>\n",
       "      <td>0.103384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-13</th>\n",
       "      <td>0.137654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            observations\n",
       "2015-07-09      0.000000\n",
       "2015-07-10      0.034516\n",
       "2015-07-11      0.068991\n",
       "2015-07-12      0.103384\n",
       "2015-07-13      0.137654"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=5*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 10  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "print('number of observations in time series: {}'.format(len(observations)))\n",
    "\n",
    "# initialize dataframe to store time series\n",
    "df = pd.DataFrame(data=observations, columns=['observations'])\n",
    "df.index = idx\n",
    "\n",
    "# initialize object\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# load dataframe into object\n",
    "mdq._selected_features = ['observations']\n",
    "mdq.df = df\n",
    "mdq.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.2_link'></a>\n",
    "### 2.2 Separate training and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split ratio =  0.7\n"
     ]
    }
   ],
   "source": [
    "# train-validation split ratio as class attribute set to 70%\n",
    "print('train split ratio = ', mdq.TRAIN_SPLIT_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data set length: 1820\n"
     ]
    }
   ],
   "source": [
    "# initialize dataset from dataframe \n",
    "mdq.initialize_dataset()\n",
    "\n",
    "print('loaded data set length: {}'.format(len(mdq._dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3_link'></a>\n",
    "# 3. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.1_link'></a>\n",
    "### 3.1 Standardize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.0, std: 1.0\n"
     ]
    }
   ],
   "source": [
    "# standardize data\n",
    "mdq.standardize_data()\n",
    "\n",
    "# check that mean equals zero and the standard deviation is one\n",
    "print('mean: {}, std: {}'.format(round(np.mean(mdq._dataset), 2), round(np.std(mdq._dataset), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part4_link'></a>\n",
    "# 4. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part4.1_link'></a>\n",
    "### 4.1 Cache, batch and shuffle using Tensorflow's data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number time points to be forecasted and the number of points the model is trained on are set. The training and validation dataset is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: x:(909, 365, 1), y:(909, 7, 1)\n",
      "validation set shape: x:(174, 365, 1), y:(174, 7, 1)\n",
      "number of training samples: 909\n"
     ]
    }
   ],
   "source": [
    "# set number of time points for 1/ future forecasting points and 2/ the past, historical time points\n",
    "future_target_size = int(365/52)\n",
    "past_history_size = int(1*365)\n",
    "\n",
    "# generate training and validation data\n",
    "mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size)\n",
    "\n",
    "\"\"\"\n",
    "data shapes: (batch size, number of input time steps, number of features)\\\n",
    "\"\"\"\n",
    "\n",
    "print('number of training samples: {}'.format(mdq._num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part5_link'></a>\n",
    "# 5. Setup and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set model specifics for both neural networks\n",
    "units = 128\n",
    "num_layers = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part5.1_link'></a>\n",
    "### 5.1 RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test that model got created in object instance: \n",
      " {'RNN': <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fbb1c56d490>}\n"
     ]
    }
   ],
   "source": [
    "# setup Keras LSTM model and compile\n",
    "\n",
    "model_type = 'RNN'\n",
    "mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "# check that model exists in mdq-object\n",
    "print('test that model got created in object instance: \\n', mdq._models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part5.2_link'></a>\n",
    "### 5.2 LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Keras, the configuration details of the LSTM model is set and compiled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test that model got created in object instance: \n",
      " {'RNN': <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fbb1c56d490>, 'LSTM': <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fbb1ca91390>}\n"
     ]
    }
   ],
   "source": [
    "# setup Keras LSTM model and compile\n",
    "\n",
    "model_type = 'LSTM'\n",
    "mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "# check that model exists in mdq-object\n",
    "print('test that model got created in object instance: \\n', mdq._models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part6_link'></a>\n",
    "# 6. Fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part6.1_link'></a>\n",
    "### 6.1 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the number of epochs and steps per epoch, the model is fit to the training data. The generated 'history' will be used in the following section to assess the quality of the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "129/129 [==============================] - 10s 75ms/step - loss: 0.1085 - mse: 0.1085 - val_loss: 0.2357 - val_mse: 0.2357\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 9s 71ms/step - loss: 0.0947 - mse: 0.0947 - val_loss: 0.0160 - val_mse: 0.0160\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 9s 69ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 9s 68ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 8s 64ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 8s 64ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 8s 63ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 8s 63ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 8s 63ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0296 - val_mse: 0.0296\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 8s 64ms/step - loss: 0.0708 - mse: 0.0708 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 8s 64ms/step - loss: 0.0422 - mse: 0.0422 - val_loss: 0.0299 - val_mse: 0.0299\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 8s 64ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0314 - val_mse: 0.0314\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 9s 68ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 9s 67ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0171 - val_mse: 0.0171\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 10s 74ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 9s 73ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 9s 68ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 9s 66ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 9s 67ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 8s 65ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 8s 65ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 9s 67ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 9s 70ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 9s 73ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 9s 68ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0029 - val_mse: 0.0029\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 9s 68ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 9s 67ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 9s 68ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0033 - val_mse: 0.0033\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 9s 73ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 9s 69ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0028 - val_mse: 0.0028\n"
     ]
    }
   ],
   "source": [
    "# set number of epochs\n",
    "epochs = 30\n",
    "\n",
    "# set number of steps per epoch\n",
    "num_samples = mdq._num_samples\n",
    "steps_per_epoch = int(num_samples/future_target_size)\n",
    "\n",
    "validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "model_type = 'RNN'\n",
    "mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "              ,validation_steps=validation_steps, model_type=model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training time: 264.2737545967102\n"
     ]
    }
   ],
   "source": [
    "total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "print('total training time: {}'.format(total_training_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part6.2_link'></a>\n",
    "### 6.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "129/129 [==============================] - 42s 326ms/step - loss: 0.1901 - mse: 0.1901 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 2/30\n",
      " 57/129 [============>.................] - ETA: 27s - loss: 0.0294 - mse: 0.0294"
     ]
    }
   ],
   "source": [
    "model_type = 'LSTM'\n",
    "mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "              ,validation_steps=validation_steps, model_type=model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "print('total training time: {}'.format(total_training_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part7_link'></a>\n",
    "# 7. loss and error metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part7.1_link'></a>\n",
    "### 7.1 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize training and validation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = 'RNN'\n",
    "mdq.plot_history(model_type=model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize predictions\n",
    "\n",
    "num = 2\n",
    "for x, y in mdq._val_data.take(3):\n",
    "    mdq.multi_step_plot(x[num], y[num], mdq._models[model_type].predict(x)[:1], xlabel=None, title=model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part7.2_link'></a>\n",
    "### 7.2 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize training and validation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_type = 'LSTM'\n",
    "mdq.plot_history(model_type=model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize predictions\n",
    "\n",
    "num = 2\n",
    "for x, y in mdq._val_data.take(3):\n",
    "    mdq.multi_step_plot(x[num], y[num], mdq._models[model_type].predict(x)[:1], xlabel=None, title=model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
