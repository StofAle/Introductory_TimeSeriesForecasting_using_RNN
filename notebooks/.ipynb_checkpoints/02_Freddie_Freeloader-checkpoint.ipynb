{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "#### In this notebook, the trial runs from the preceding notebook ('01_So_What.ipynb') are systematically extended to try to find an optimal configuration for the two models. The model parameters to be fine tuned are: number of epochs, number of layers and the number of units.\n",
    "\n",
    "#### The best performing model configuration will be used in the notebook '03_Blue_in_Green.ipynb' to analyze the impact of adding noise to the clean dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [1. Load modules](#Part1_link)\n",
    "* [2. Setup data](#Part2_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.1  Generate data, separate testing and validation set and standardize testing data](#Part2.1_link)\n",
    "* [3. Setup models and evaluate for various hyper-parameter choices](#Part3_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.1 Compile and fit LSTM and RNN model](#Part3.1_link)\n",
    "* [4. Visualize results](#Part4_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part1_link'></a>\n",
    "# 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import Kind_of_Blue  # own class with a collection of methods used in this analysis\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2_link'></a>\n",
    "# 2. Setup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.1_link'></a>\n",
    "### 2.1 Generate data, separate testing and validation set and standardize testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps are repeated from the previous notebook, '01_So_What.ipynb', and are grouped into one single step here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations in time series: 1820\n",
      "train split ratio =  0.7\n",
      "loaded data set length: 1820\n",
      "mean: 0.0, std: 1.0\n",
      "debug3: check what buffer_size actually does! and why is data shape always (..., ..., 1) <- 1???\n",
      "training set shape: x:(909, 365, 1), y:(909, 7, 1)\n",
      "validation set shape: x:(174, 365, 1), y:(174, 7, 1)\n",
      "number of training samples: 909\n"
     ]
    }
   ],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=5*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 10  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "print('number of observations in time series: {}'.format(len(observations)))\n",
    "\n",
    "# initialize dataframe to store time series\n",
    "df = pd.DataFrame(data=observations, columns=['observations'])\n",
    "df.index = idx\n",
    "\n",
    "# initialize object\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# load dataframe into object\n",
    "mdq._selected_features = ['observations']\n",
    "mdq.df = df\n",
    "\n",
    "# train-validation split ratio as class attribute set to 70%\n",
    "print('train split ratio = ', mdq.TRAIN_SPLIT_RATIO)\n",
    "\n",
    "# initialize dataset from dataframe \n",
    "mdq.initialize_dataset()\n",
    "print('loaded data set length: {}'.format(len(mdq._dataset)))\n",
    "\n",
    "# standardize data\n",
    "mdq.standardize_data()\n",
    "\n",
    "# check that mean equals zero and the standard deviation is one\n",
    "print('mean: {}, std: {}'.format(round(np.mean(mdq._dataset), 2), round(np.std(mdq._dataset), 2)))\n",
    "\n",
    "# set number of time points for 1/ future forecasting points and 2/ the past, historical time points\n",
    "future_target_size = int(365/52)\n",
    "past_history_size = int(1*365)\n",
    "\n",
    "# set batch size\n",
    "batch_size = 32\n",
    "\n",
    "# generate train and validation data\n",
    "mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size\n",
    "                                , batch_size=batch_size)\n",
    "\n",
    "print('number of training samples: {}'.format(mdq._num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3_link'></a>\n",
    "# 3. Setup models and evaluate for various hyper-parameter choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.1_link'></a>\n",
    "### 3.1 Compile and fit LSTM and RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator for configurations to be iterated over\n",
    "\n",
    "def config_generator():\n",
    "    \n",
    "    unit_choices = [2, 8, 16, 64, 128, 256, 512]  # number of units in each neural network layer\n",
    "    layer_choices = [2]  # total number of layers\n",
    "    epoch_choices = [10, 30, 50]  # number of epochs the model is trained on\n",
    "    \n",
    "    for units in unit_choices:\n",
    "        for num_layers in layer_choices:\n",
    "            for epochs in epoch_choices:\n",
    "                yield units, num_layers, epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently running RNN model\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 7s 57ms/step - loss: 0.9911 - mse: 0.9911 - val_loss: 0.9756 - val_mse: 0.9756\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 6s 47ms/step - loss: 0.9062 - mse: 0.9062 - val_loss: 0.8620 - val_mse: 0.8620\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 6s 48ms/step - loss: 0.7902 - mse: 0.7902 - val_loss: 0.7122 - val_mse: 0.7122\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 6s 50ms/step - loss: 0.6992 - mse: 0.6992 - val_loss: 0.5802 - val_mse: 0.5802\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 6s 46ms/step - loss: 0.6052 - mse: 0.6052 - val_loss: 0.4696 - val_mse: 0.4696\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 7s 53ms/step - loss: 0.5205 - mse: 0.5205 - val_loss: 0.3790 - val_mse: 0.3790\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 6s 50ms/step - loss: 0.4746 - mse: 0.4746 - val_loss: 0.3118 - val_mse: 0.3118\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 7s 53ms/step - loss: 0.4553 - mse: 0.4553 - val_loss: 0.2682 - val_mse: 0.2682\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 6s 45ms/step - loss: 0.4332 - mse: 0.4332 - val_loss: 0.2409 - val_mse: 0.2409\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 6s 45ms/step - loss: 0.3863 - mse: 0.3863 - val_loss: 0.2102 - val_mse: 0.2102\n",
      "currently running RNN model\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 7s 55ms/step - loss: 0.9072 - mse: 0.9072 - val_loss: 0.8354 - val_mse: 0.8354\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 6s 49ms/step - loss: 0.7434 - mse: 0.7434 - val_loss: 0.6663 - val_mse: 0.6663\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 6s 48ms/step - loss: 0.6373 - mse: 0.6373 - val_loss: 0.5327 - val_mse: 0.5327\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 6s 43ms/step - loss: 0.5532 - mse: 0.5532 - val_loss: 0.4319 - val_mse: 0.4319\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 6s 49ms/step - loss: 0.4802 - mse: 0.4802 - val_loss: 0.3520 - val_mse: 0.3520\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 5s 41ms/step - loss: 0.4440 - mse: 0.4440 - val_loss: 0.2921 - val_mse: 0.2921\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 6s 50ms/step - loss: 0.3790 - mse: 0.3790 - val_loss: 0.2395 - val_mse: 0.2395\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 6s 44ms/step - loss: 0.3411 - mse: 0.3411 - val_loss: 0.2023 - val_mse: 0.2023\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 6s 47ms/step - loss: 0.3208 - mse: 0.3208 - val_loss: 0.1722 - val_mse: 0.1722\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 5s 42ms/step - loss: 0.2955 - mse: 0.2955 - val_loss: 0.1457 - val_mse: 0.1457\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 6s 46ms/step - loss: 0.2766 - mse: 0.2766 - val_loss: 0.1394 - val_mse: 0.1394\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 6s 46ms/step - loss: 0.2717 - mse: 0.2717 - val_loss: 0.1247 - val_mse: 0.1247\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 6s 43ms/step - loss: 0.2525 - mse: 0.2525 - val_loss: 0.1177 - val_mse: 0.1177\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 6s 43ms/step - loss: 0.2633 - mse: 0.2633 - val_loss: 0.1077 - val_mse: 0.1077\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 6s 50ms/step - loss: 0.2585 - mse: 0.2585 - val_loss: 0.1111 - val_mse: 0.1111\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 9s 66ms/step - loss: 0.2445 - mse: 0.2445 - val_loss: 0.1017 - val_mse: 0.1017\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 8s 65ms/step - loss: 0.2622 - mse: 0.2622 - val_loss: 0.1032 - val_mse: 0.1032\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 6s 47ms/step - loss: 0.2496 - mse: 0.2496 - val_loss: 0.0988 - val_mse: 0.0988\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 6s 46ms/step - loss: 0.2659 - mse: 0.2659 - val_loss: 0.0947 - val_mse: 0.0947\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 6s 47ms/step - loss: 0.2482 - mse: 0.2482 - val_loss: 0.1016 - val_mse: 0.1016\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 7s 54ms/step - loss: 0.2427 - mse: 0.2427 - val_loss: 0.0929 - val_mse: 0.0929\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 6s 50ms/step - loss: 0.2530 - mse: 0.2530 - val_loss: 0.0892 - val_mse: 0.0892\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 7s 53ms/step - loss: 0.2443 - mse: 0.2443 - val_loss: 0.0967 - val_mse: 0.0967\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 6s 49ms/step - loss: 0.2591 - mse: 0.2591 - val_loss: 0.0909 - val_mse: 0.0909\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 6s 50ms/step - loss: 0.2512 - mse: 0.2512 - val_loss: 0.0922 - val_mse: 0.0922\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 7s 54ms/step - loss: 0.2638 - mse: 0.2638 - val_loss: 0.0941 - val_mse: 0.0941\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 7s 51ms/step - loss: 0.2344 - mse: 0.2344 - val_loss: 0.0967 - val_mse: 0.0967\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 6s 50ms/step - loss: 0.2642 - mse: 0.2642 - val_loss: 0.1014 - val_mse: 0.1014\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 6s 46ms/step - loss: 0.2483 - mse: 0.2483 - val_loss: 0.0954 - val_mse: 0.0954\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 6s 46ms/step - loss: 0.2380 - mse: 0.2380 - val_loss: 0.0934 - val_mse: 0.0934\n",
      "currently running RNN model\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 6s 45ms/step - loss: 0.9873 - mse: 0.9873 - val_loss: 0.9649 - val_mse: 0.9649\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 6s 43ms/step - loss: 0.8644 - mse: 0.8644 - val_loss: 0.7836 - val_mse: 0.7836\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 6s 47ms/step - loss: 0.6865 - mse: 0.6865 - val_loss: 0.5671 - val_mse: 0.5671\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 7s 52ms/step - loss: 0.5402 - mse: 0.5402 - val_loss: 0.4067 - val_mse: 0.4067\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 6s 45ms/step - loss: 0.4252 - mse: 0.4252 - val_loss: 0.3092 - val_mse: 0.3092\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 6s 46ms/step - loss: 0.3654 - mse: 0.3654 - val_loss: 0.2433 - val_mse: 0.2433\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 6s 45ms/step - loss: 0.3313 - mse: 0.3313 - val_loss: 0.2016 - val_mse: 0.2016\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 6s 44ms/step - loss: 0.2948 - mse: 0.2948 - val_loss: 0.1694 - val_mse: 0.1694\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 6s 43ms/step - loss: 0.2831 - mse: 0.2831 - val_loss: 0.1491 - val_mse: 0.1491\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 6s 44ms/step - loss: 0.2738 - mse: 0.2738 - val_loss: 0.1299 - val_mse: 0.1299\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 6s 43ms/step - loss: 0.2656 - mse: 0.2656 - val_loss: 0.1161 - val_mse: 0.1161\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 6s 43ms/step - loss: 0.2675 - mse: 0.2675 - val_loss: 0.1084 - val_mse: 0.1084\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 6s 44ms/step - loss: 0.2396 - mse: 0.2396 - val_loss: 0.1050 - val_mse: 0.1050\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 6s 50ms/step - loss: 0.2514 - mse: 0.2514 - val_loss: 0.1036 - val_mse: 0.1036\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 5s 42ms/step - loss: 0.2539 - mse: 0.2539 - val_loss: 0.1002 - val_mse: 0.1002\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 6s 49ms/step - loss: 0.2463 - mse: 0.2463 - val_loss: 0.0950 - val_mse: 0.0950\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 6s 50ms/step - loss: 0.2534 - mse: 0.2534 - val_loss: 0.0963 - val_mse: 0.0963\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 6s 44ms/step - loss: 0.2419 - mse: 0.2419 - val_loss: 0.0914 - val_mse: 0.0914\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 7s 51ms/step - loss: 0.2668 - mse: 0.2668 - val_loss: 0.0869 - val_mse: 0.0869\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 6s 46ms/step - loss: 0.2460 - mse: 0.2460 - val_loss: 0.0917 - val_mse: 0.0917\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 6s 44ms/step - loss: 0.2468 - mse: 0.2468 - val_loss: 0.0861 - val_mse: 0.0861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "129/129 [==============================] - 6s 45ms/step - loss: 0.2425 - mse: 0.2425 - val_loss: 0.0860 - val_mse: 0.0860\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 6s 43ms/step - loss: 0.2473 - mse: 0.2473 - val_loss: 0.0912 - val_mse: 0.0912\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 6s 48ms/step - loss: 0.2442 - mse: 0.2442 - val_loss: 0.0865 - val_mse: 0.0865\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 6s 44ms/step - loss: 0.2587 - mse: 0.2587 - val_loss: 0.0850 - val_mse: 0.0850\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 6s 47ms/step - loss: 0.2451 - mse: 0.2451 - val_loss: 0.0888 - val_mse: 0.0888\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 7s 51ms/step - loss: 0.2290 - mse: 0.2290 - val_loss: 0.0848 - val_mse: 0.0848\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 6s 46ms/step - loss: 0.2483 - mse: 0.2483 - val_loss: 0.0838 - val_mse: 0.0838\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 7s 51ms/step - loss: 0.2431 - mse: 0.2431 - val_loss: 0.0857 - val_mse: 0.0857\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 5s 41ms/step - loss: 0.2446 - mse: 0.2446 - val_loss: 0.0868 - val_mse: 0.0868\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 5s 41ms/step - loss: 0.2471 - mse: 0.2471 - val_loss: 0.0880 - val_mse: 0.0880\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 5s 42ms/step - loss: 0.2369 - mse: 0.2369 - val_loss: 0.0861 - val_mse: 0.0861\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 49s 383ms/step - loss: 0.2428 - mse: 0.2428 - val_loss: 0.0847 - val_mse: 0.0847\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 6s 48ms/step - loss: 0.2462 - mse: 0.2462 - val_loss: 0.0820 - val_mse: 0.0820\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 6s 48ms/step - loss: 0.2490 - mse: 0.2490 - val_loss: 0.0836 - val_mse: 0.0836\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 6s 44ms/step - loss: 0.2481 - mse: 0.2481 - val_loss: 0.0845 - val_mse: 0.0845\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 6s 48ms/step - loss: 0.2492 - mse: 0.2492 - val_loss: 0.0858 - val_mse: 0.0858\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 6s 45ms/step - loss: 0.2290 - mse: 0.2290 - val_loss: 0.0841 - val_mse: 0.0841\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 6s 45ms/step - loss: 0.2419 - mse: 0.2419 - val_loss: 0.0832 - val_mse: 0.0832\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 6s 44ms/step - loss: 0.2367 - mse: 0.2367 - val_loss: 0.0844 - val_mse: 0.0844\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 6s 44ms/step - loss: 0.2434 - mse: 0.2434 - val_loss: 0.0880 - val_mse: 0.0880\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 6s 44ms/step - loss: 0.2527 - mse: 0.2527 - val_loss: 0.0805 - val_mse: 0.0805\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 5s 41ms/step - loss: 0.2466 - mse: 0.2466 - val_loss: 0.0886 - val_mse: 0.0886\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 5s 43ms/step - loss: 0.2454 - mse: 0.2454 - val_loss: 0.0798 - val_mse: 0.0798\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 6s 43ms/step - loss: 0.2496 - mse: 0.2496 - val_loss: 0.0890 - val_mse: 0.0890\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 6s 43ms/step - loss: 0.2588 - mse: 0.2588 - val_loss: 0.0859 - val_mse: 0.0859\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 6s 43ms/step - loss: 0.2550 - mse: 0.2550 - val_loss: 0.0918 - val_mse: 0.0918\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 7s 52ms/step - loss: 0.2399 - mse: 0.2399 - val_loss: 0.0842 - val_mse: 0.0842\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 5s 42ms/step - loss: 0.2614 - mse: 0.2614 - val_loss: 0.0879 - val_mse: 0.0879\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 8s 59ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.0809 - val_mse: 0.0809\n",
      "currently running RNN model\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 8s 62ms/step - loss: 0.6595 - mse: 0.6595 - val_loss: 0.4493 - val_mse: 0.4493\n",
      "Epoch 2/10\n",
      " 71/129 [===============>..............] - ETA: 3s - loss: 0.4423 - mse: 0.4423"
     ]
    }
   ],
   "source": [
    "# iterations over the model parameter configurations are done for both LSTM as well as RNN model\n",
    "# model_types = ['LSTM', 'RNN']\n",
    "model_types = ['RNN']\n",
    "\n",
    "# set number of steps per epoch\n",
    "num_samples = mdq._num_samples\n",
    "steps_per_epoch = int(num_samples/future_target_size)\n",
    "validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "# initialize results dictionary\n",
    "res = {'model_type': [], 'epochs': [], 'num_layers': [], 'units': [], 'val_mse': []\n",
    "       , 'mse': [], 'total_training_time': []}\n",
    "\n",
    "for units, num_layers, epochs in config_generator():\n",
    "    for model_type in model_types:\n",
    "\n",
    "        print('currently running {} model'.format(model_type))\n",
    "\n",
    "        # compile model\n",
    "        mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "        # fit model\n",
    "        mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "                      ,validation_steps=validation_steps, model_type=model_type)\n",
    "        \n",
    "        # get errors\n",
    "        history = mdq._histories[model_type]\n",
    "        val_mse = history.history['val_mse'][-1]\n",
    "        mse = history.history['mse'][-1]\n",
    "        \n",
    "        # get total training time\n",
    "        total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "        \n",
    "        # append results to results dictionary\n",
    "        res['model_type'].append(model_type)\n",
    "        res['epochs'].append(epochs)\n",
    "        res['num_layers'].append(num_layers)\n",
    "        res['units'].append(units)\n",
    "        res['val_mse'].append(val_mse)\n",
    "        res['mse'].append(mse)\n",
    "        res['total_training_time'].append(total_training_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part4_link'></a>\n",
    "# 4. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary to dataframe\n",
    "df_res = pd.DataFrame(res)\n",
    "\n",
    "# store dataframe as csv locally\n",
    "# df_res.to_csv('../data/02_results_run4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results; use bubble plots to indicate magnitude of mean-square error for specific configuration comparing\n",
    "# RNN to LSTM results\n",
    "\n",
    "x_label = 'epochs'\n",
    "y_label = 'units'\n",
    "z_label = 'mse'\n",
    "# condition_label = 'num_layers'\n",
    "# condition_vals = list(set(df_res[condition_label]))\n",
    "\n",
    "# condition_LSTM = (df_res['model_type']=='LSTM')\n",
    "# condition_RNN = (df_res['model_type']=='RNN')\n",
    "\n",
    "for model_type in ['LSTM', 'RNN']:\n",
    "    condition_1 = (df_res['model_type']== model_type)\n",
    "    \n",
    "    x = df_res[condition_1][x_label].values\n",
    "    y = df_res[condition_1][y_label].values\n",
    "    \n",
    "    z = df_res[condition_1][z_label].values\n",
    "    plt.scatter(x, y, s=z*10000, alpha=0.6, c=\"red\", linewidth=0.0)\n",
    "        \n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title('mean-square training error: {} model'.format(model_type))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res[df_res['model_type']=='RNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
