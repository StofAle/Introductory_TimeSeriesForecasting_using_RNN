{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "#### In this notebook, the trial runs from the preceding notebook ('01_So_What.ipynb') are systematically extended to try to find an optimal configuration for the two models varying the number of units and training epochs. \n",
    "\n",
    "#### The best performing model configuration will be used in the notebook '03_Blue_in_Green.ipynb' to analyze the impact of adding noise to the clean dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [1. Load modules](#Part1_link)\n",
    "* [2. Setup data](#Part2_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.1  Generate data, separate testing and validation set and standardize testing data](#Part2.1_link)\n",
    "* [3. Setup models and evaluate for various hyper-parameter choices](#Part3_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.1 Compile and fit LSTM and RNN model](#Part3.1_link)\n",
    "* [4. Visualize and save results](#Part4_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part1_link'></a>\n",
    "# 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import Kind_of_Blue  # own class with a collection of methods used in this analysis\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2_link'></a>\n",
    "# 2. Setup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.1_link'></a>\n",
    "### 2.1 Generate data, separate testing and validation set and standardize testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps are repeated from the previous notebook, '01_So_What.ipynb', and are grouped into one single step here for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations in time series: 1820\n",
      "train split ratio =  0.7\n",
      "loaded data set length: 1820\n",
      "mean: 0.0, std: 1.0\n",
      "training set shape: x:(909, 365, 1), y:(909, 7, 1)\n",
      "validation set shape: x:(174, 365, 1), y:(174, 7, 1)\n",
      "number of training samples: 909\n"
     ]
    }
   ],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=5*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 10  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "print('number of observations in time series: {}'.format(len(observations)))\n",
    "\n",
    "# initialize dataframe to store time series\n",
    "df = pd.DataFrame(data=observations, columns=['observations'])\n",
    "df.index = idx\n",
    "\n",
    "# initialize object\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# load dataframe into object\n",
    "mdq._selected_features = ['observations']\n",
    "mdq.df = df\n",
    "\n",
    "# train-validation split ratio as class attribute set to 70%\n",
    "print('train split ratio = ', mdq.TRAIN_SPLIT_RATIO)\n",
    "\n",
    "# initialize dataset from dataframe \n",
    "mdq.initialize_dataset()\n",
    "print('loaded data set length: {}'.format(len(mdq._dataset)))\n",
    "\n",
    "# standardize data\n",
    "mdq.standardize_data()\n",
    "\n",
    "# check that mean equals zero and the standard deviation is one\n",
    "print('mean: {}, std: {}'.format(round(np.mean(mdq._dataset), 2), round(np.std(mdq._dataset), 2)))\n",
    "\n",
    "# set number of time points for 1/ future forecasting points and 2/ the past, historical time points\n",
    "future_target_size = int(365/52)\n",
    "past_history_size = int(1*365)\n",
    "\n",
    "# generate train and validation data\n",
    "mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size)\n",
    "\n",
    "print('number of training samples: {}'.format(mdq._num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3_link'></a>\n",
    "# 3. Setup models and evaluate for various hyper-parameter choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.1_link'></a>\n",
    "### 3.1 Compile and fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generator for configurations to be iterated over\n",
    "\n",
    "def config_generator():\n",
    "    \n",
    "    unit_choices = [64, 128, 256]  # number of units in each neural network layer\n",
    "    layer_choices = [2]  # total number of layers\n",
    "    epoch_choices = [10, 30, 50]  # number of epochs the model is trained on\n",
    "    \n",
    "    for units in unit_choices:\n",
    "        for num_layers in layer_choices:\n",
    "            for epochs in epoch_choices:\n",
    "                yield units, num_layers, epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 62s 478ms/step - loss: 0.1651 - mse: 0.1651 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 54s 420ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 69s 535ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 62s 484ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 62s 478ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 59s 458ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 60s 465ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 8.0246e-04 - val_mse: 8.0246e-04\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 59s 459ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 8.8133e-04 - val_mse: 8.8133e-04\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 61s 476ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 8.4428e-04 - val_mse: 8.4428e-04\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 72s 561ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 7.8294e-04 - val_mse: 7.8294e-04\n",
      "currently running RNN model\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 15s 117ms/step - loss: 0.1566 - mse: 0.1566 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 13s 102ms/step - loss: 0.0536 - mse: 0.0536 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 13s 99ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 13s 100ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 15s 115ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 9.4879e-04 - val_mse: 9.4879e-04\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 13s 98ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 14s 110ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 15s 117ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 5.5447e-04 - val_mse: 5.5447e-04\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 15s 117ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 4.1929e-04 - val_mse: 4.1929e-04\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 13s 103ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 64s 499ms/step - loss: 0.1571 - mse: 0.1571 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 53s 412ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 58s 448ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 68s 529ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 53s 409ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 9.8571e-04 - val_mse: 9.8571e-04\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 53s 408ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 4.0955e-04 - val_mse: 4.0955e-04\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 53s 410ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 53s 410ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 53s 413ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 59s 457ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 9.5763e-04 - val_mse: 9.5763e-04\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 60s 461ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 53s 413ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 53s 412ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 3.1981e-04 - val_mse: 3.1981e-04\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 55s 423ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 56s 435ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 54s 418ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0039 - val_mse: 0.0039\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 55s 423ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0032 - val_mse: 0.0032\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 61s 473ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 57s 438ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 9.8769e-04 - val_mse: 9.8769e-04\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 65s 502ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 70s 539ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 69s 536ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 9.6383e-04 - val_mse: 9.6383e-04\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 47s 365ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 2.8557e-04 - val_mse: 2.8557e-04\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 40s 312ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 5.6254e-04 - val_mse: 5.6254e-04\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 41s 319ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 41s 319ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 41s 318ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 7.5425e-04 - val_mse: 7.5425e-04\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 56s 431ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 53s 414ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 7.5499e-04 - val_mse: 7.5499e-04\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 59s 459ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "currently running RNN model\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 13s 102ms/step - loss: 0.1399 - mse: 0.1399 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 13s 99ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 12s 94ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 14s 105ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0055 - val_mse: 0.0055\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 12s 94ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 16s 121ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 14s 111ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 14s 107ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0014 - val_mse: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "129/129 [==============================] - 14s 107ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 7.9036e-04 - val_mse: 7.9036e-04\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 15s 119ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 9.3797e-04 - val_mse: 9.3797e-04\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 13s 104ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 5.0932e-04 - val_mse: 5.0932e-04\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 13s 99ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 4.6047e-04 - val_mse: 4.6047e-04\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 12s 89ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 10s 78ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 11s 82ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 4.6928e-04 - val_mse: 4.6928e-04\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 10s 80ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 13s 100ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 8.2017e-04 - val_mse: 8.2017e-04\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 11s 83ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 10s 81ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 11s 83ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 10s 80ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "Epoch 23/30\n",
      "129/129 [==============================] - 11s 85ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 24/30\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 25/30\n",
      "129/129 [==============================] - 14s 109ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 26/30\n",
      "129/129 [==============================] - 16s 127ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 27/30\n",
      "129/129 [==============================] - 11s 89ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 9.7616e-04 - val_mse: 9.7616e-04\n",
      "Epoch 28/30\n",
      "129/129 [==============================] - 11s 83ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 3.9101e-04 - val_mse: 3.9101e-04\n",
      "Epoch 29/30\n",
      "129/129 [==============================] - 11s 87ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 3.4929e-04 - val_mse: 3.4929e-04\n",
      "Epoch 30/30\n",
      "129/129 [==============================] - 11s 84ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 6.5986e-04 - val_mse: 6.5986e-04\n",
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 62s 478ms/step - loss: 0.1834 - mse: 0.1834 - val_loss: 0.0085 - val_mse: 0.0085\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 56s 437ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 55s 425ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 52s 401ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 54s 417ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 73s 562ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 9.9652e-04 - val_mse: 9.9652e-04\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 60s 468ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 6.6874e-04 - val_mse: 6.6874e-04\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 56s 431ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 54s 418ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 9.0869e-04 - val_mse: 9.0869e-04\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 52s 405ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 59s 455ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 5.2045e-04 - val_mse: 5.2045e-04\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 66s 511ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 7.4323e-04 - val_mse: 7.4323e-04\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 58s 448ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 82s 636ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 84s 654ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 84s 650ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 61s 472ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 7.6826e-04 - val_mse: 7.6826e-04\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 60s 467ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 59s 454ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 7.3796e-04 - val_mse: 7.3796e-04\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 60s 465ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 7.9760e-04 - val_mse: 7.9760e-04\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 59s 457ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 6.4129e-04 - val_mse: 6.4129e-04\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 76s 586ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 73s 568ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 8.6231e-04 - val_mse: 8.6231e-04\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 87s 675ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 85s 658ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 8.3773e-04 - val_mse: 8.3773e-04\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 68s 528ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 56s 435ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 4.8405e-04 - val_mse: 4.8405e-04\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 56s 437ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 7.7518e-04 - val_mse: 7.7518e-04\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 62s 483ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 3.7011e-04 - val_mse: 3.7011e-04\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 59s 454ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 55s 424ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 58s 448ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 9.1968e-04 - val_mse: 9.1968e-04\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 70s 544ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 71s 554ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 68s 525ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 6.9114e-04 - val_mse: 6.9114e-04\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 60s 461ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0034 - val_mse: 0.0034\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 64s 497ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 8.2617e-04 - val_mse: 8.2617e-04\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 76s 593ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 5.5147e-04 - val_mse: 5.5147e-04\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 79s 616ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 82s 632ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 4.8417e-04 - val_mse: 4.8417e-04\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 85s 662ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 3.7036e-04 - val_mse: 3.7036e-04\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 91s 707ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 92s 711ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 5.3918e-04 - val_mse: 5.3918e-04\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 89s 692ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 85s 658ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 72s 562ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 71s 550ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 5.7658e-04 - val_mse: 5.7658e-04\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 76s 586ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 6.1677e-04 - val_mse: 6.1677e-04\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 87s 676ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 84s 649ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 4.4160e-04 - val_mse: 4.4160e-04\n",
      "currently running RNN model\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - 17s 133ms/step - loss: 0.1165 - mse: 0.1165 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 12s 97ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 4.8549e-04 - val_mse: 4.8549e-04\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 13s 100ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 11s 89ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 2.8909e-04 - val_mse: 2.8909e-04\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 11s 89ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 5.2517e-04 - val_mse: 5.2517e-04\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 12s 89ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 9.5457e-04 - val_mse: 9.5457e-04\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 11s 88ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 3.8849e-04 - val_mse: 3.8849e-04\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 4.9313e-04 - val_mse: 4.9313e-04\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 6.8624e-04 - val_mse: 6.8624e-04\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 8.6218e-04 - val_mse: 8.6218e-04\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 5.9682e-04 - val_mse: 5.9682e-04\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0015 - val_mse: 0.0015\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.2158 - mse: 0.2158 - val_loss: 0.0352 - val_mse: 0.0352\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 12s 93ms/step - loss: 0.0491 - mse: 0.0491 - val_loss: 0.0315 - val_mse: 0.0315\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 12s 95ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0305 - val_mse: 0.0305\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 12s 93ms/step - loss: 0.0416 - mse: 0.0416 - val_loss: 0.0295 - val_mse: 0.0295\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 12s 93ms/step - loss: 0.0390 - mse: 0.0390 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 12s 94ms/step - loss: 0.0384 - mse: 0.0384 - val_loss: 0.0282 - val_mse: 0.0282\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0269 - val_mse: 0.0269\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 12s 93ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 12s 94ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 13s 99ms/step - loss: 0.0335 - mse: 0.0335 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 14s 105ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 14s 106ms/step - loss: 0.0306 - mse: 0.0306 - val_loss: 0.0213 - val_mse: 0.0213\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 13s 103ms/step - loss: 0.0300 - mse: 0.0300 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 13s 105ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 13s 104ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0177 - val_mse: 0.0177\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 14s 109ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0141 - val_mse: 0.0141\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 12s 96ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 13s 98ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.0086 - val_mse: 0.0086\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 12s 95ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 12s 96ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 12s 92ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0087 - val_mse: 0.0087\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 12s 89ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 109s 843ms/step - loss: 0.1433 - mse: 0.1433 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 112s 866ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 109s 847ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 121s 935ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 130s 1s/step - loss: 0.0110 - mse: 0.0110 - val_loss: 7.1723e-04 - val_mse: 7.1723e-04\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 139s 1s/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 125s 967ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 90s 701ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 5.3374e-04 - val_mse: 5.3374e-04\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 96s 746ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 83s 646ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0028 - val_mse: 0.0028\n",
      "currently running RNN model\n",
      "Epoch 1/10\n",
      "129/129 [==============================] - 12s 95ms/step - loss: 0.0768 - mse: 0.0768 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 12s 91ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 11s 83ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 10s 79ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 6.1405e-04 - val_mse: 6.1405e-04\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 10s 80ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 11s 85ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 7.9200e-04 - val_mse: 7.9200e-04\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 10s 77ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0093 - val_mse: 0.0093\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 10s 78ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 4.6323e-04 - val_mse: 4.6323e-04\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 11s 82ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 8.7716e-04 - val_mse: 8.7716e-04\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 11s 87ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "currently running LSTM model\n",
      "debugLSTM: should an LSTM layer or a Dense layer be added?\n",
      "Epoch 1/30\n",
      "129/129 [==============================] - 88s 679ms/step - loss: 0.0929 - mse: 0.0929 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 2/30\n",
      "129/129 [==============================] - 82s 633ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 3/30\n",
      "129/129 [==============================] - 78s 607ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 4/30\n",
      "129/129 [==============================] - 83s 646ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 8.7636e-04 - val_mse: 8.7636e-04\n",
      "Epoch 5/30\n",
      "129/129 [==============================] - 92s 711ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 9.5816e-04 - val_mse: 9.5816e-04\n",
      "Epoch 6/30\n",
      "129/129 [==============================] - 85s 657ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 8.6065e-04 - val_mse: 8.6065e-04\n",
      "Epoch 7/30\n",
      "129/129 [==============================] - 79s 613ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 8/30\n",
      "129/129 [==============================] - 77s 601ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 2.7935e-04 - val_mse: 2.7935e-04\n",
      "Epoch 9/30\n",
      "129/129 [==============================] - 73s 567ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 10/30\n",
      "129/129 [==============================] - 77s 598ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 11/30\n",
      "129/129 [==============================] - 82s 637ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 12/30\n",
      "129/129 [==============================] - 92s 712ms/step - loss: 0.0075 - mse: 0.0075 - val_loss: 3.6504e-04 - val_mse: 3.6504e-04\n",
      "Epoch 13/30\n",
      "129/129 [==============================] - 80s 619ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 14/30\n",
      "129/129 [==============================] - 77s 598ms/step - loss: 0.0074 - mse: 0.0074 - val_loss: 2.7581e-04 - val_mse: 2.7581e-04\n",
      "Epoch 15/30\n",
      "129/129 [==============================] - 74s 575ms/step - loss: 0.0072 - mse: 0.0072 - val_loss: 7.8996e-04 - val_mse: 7.8996e-04\n",
      "Epoch 16/30\n",
      "129/129 [==============================] - 76s 593ms/step - loss: 0.0073 - mse: 0.0073 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 17/30\n",
      "129/129 [==============================] - 76s 588ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 6.7149e-04 - val_mse: 6.7149e-04\n",
      "Epoch 18/30\n",
      "129/129 [==============================] - 73s 566ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 6.5034e-04 - val_mse: 6.5034e-04\n",
      "Epoch 19/30\n",
      "129/129 [==============================] - 75s 581ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 2.4078e-04 - val_mse: 2.4078e-04\n",
      "Epoch 20/30\n",
      "129/129 [==============================] - 93s 722ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 4.6084e-04 - val_mse: 4.6084e-04\n",
      "Epoch 21/30\n",
      "129/129 [==============================] - 69s 531ms/step - loss: 0.0068 - mse: 0.0068 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 22/30\n",
      "129/129 [==============================] - 75s 578ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 8.1288e-04 - val_mse: 8.1288e-04\n",
      "Epoch 23/30\n",
      " 76/129 [================>.............] - ETA: 27s - loss: 0.0066 - mse: 0.0066"
     ]
    }
   ],
   "source": [
    "# iterations over the model parameter configurations are done for both LSTM as well as RNN model\n",
    "model_types = ['LSTM', 'RNN']\n",
    "\n",
    "# set number of steps per epoch\n",
    "num_samples = mdq._num_samples\n",
    "steps_per_epoch = int(num_samples/future_target_size)\n",
    "validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "# initialize results dictionary\n",
    "res = {'model_type': [], 'epochs': [], 'num_layers': [], 'units': [], 'val_mse': []\n",
    "       , 'mse': [], 'total_training_time': []}\n",
    "\n",
    "for units, num_layers, epochs in config_generator():\n",
    "    for model_type in model_types:\n",
    "\n",
    "        print('currently running {} model'.format(model_type))\n",
    "\n",
    "        # compile model\n",
    "        mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "        # fit model\n",
    "        mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "                      ,validation_steps=validation_steps, model_type=model_type)\n",
    "        \n",
    "        # get errors\n",
    "        history = mdq._histories[model_type]\n",
    "        val_mse = history.history['val_mse'][-1]\n",
    "        mse = history.history['mse'][-1]\n",
    "        \n",
    "        # get total training time\n",
    "        total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "        \n",
    "        # append results to results dictionary\n",
    "        res['model_type'].append(model_type)\n",
    "        res['epochs'].append(epochs)\n",
    "        res['num_layers'].append(num_layers)\n",
    "        res['units'].append(units)\n",
    "        res['val_mse'].append(val_mse)\n",
    "        res['mse'].append(mse)\n",
    "        res['total_training_time'].append(total_training_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part4_link'></a>\n",
    "# 4. Visualize and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transform dictionary to dataframe\n",
    "df_res = pd.DataFrame(res)\n",
    "\n",
    "# store dataframe as csv locally\n",
    "df_res.to_csv('../data/02_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize results; use bubble plots to indicate magnitude of mean-square error for specific configuration comparing\n",
    "# RNN to LSTM results\n",
    "\n",
    "x_label = 'epochs'\n",
    "y_label = 'units'\n",
    "z_label = 'mse'\n",
    "\n",
    "for model_type in model_types:\n",
    "    condition_1 = (df_res['model_type']== model_type)\n",
    "    \n",
    "    x = df_res[condition_1][x_label].values\n",
    "    y = df_res[condition_1][y_label].values\n",
    "    \n",
    "    z = df_res[condition_1][z_label].values\n",
    "    plt.scatter(x, y, s=z*10000, alpha=0.6, c=\"red\", linewidth=0.0)\n",
    "        \n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title('mean-square training error: {} model'.format(model_type))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
