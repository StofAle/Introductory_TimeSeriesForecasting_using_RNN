{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "#### In this notebook, 'clean' time series is generated and a neural network utilized to learn its shape and forecasts its future states.\n",
    "#### More specifically, the time series is given in the form of a sine wave. Two recurrent neural networks from tensorflow's Keras are trained: a simple RNN and an LSTM neural net. Error and performance metrics are evaluated for both and results visualized.\n",
    "\n",
    "#### The steps outlined in this notebook will be used in the notebook '02_Freddie_Freeloader.ipynb' to analyze the dependence of model-parameter choices on the model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [1. Load modules](#Part1_link)\n",
    "* [2. Setup data](#Part2_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.1 Generate time series: sine wave](#Part2.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.2 Separate training and validation data ](#Part2.2_link)\n",
    "\n",
    "* [3. Feature scaling](#Part3_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.1 Standardize training data](#Part3.1_link)\n",
    "* [4. Preprocess data](#Part4_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[4.1 Cache, batch and shuffle using Tensorflow's data format](#Part4.1_link)\n",
    "* [5. Setup and compile model](#Part5_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[5.1 RNN](#Part5.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[5.2 LSTM](#Part5.2_link)\n",
    "* [6. Fit model](#Part6_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[6.1 RNN](#Part6.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[6.2 LSTM](#Part6.2_link)\n",
    "* [7. Loss and error metrics](#Part7_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[7.1 RNN](#Part7.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[7.2 LSTM](#Part7.2_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part1_link'></a>\n",
    "# 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import Kind_of_Blue  # own class with a collection of methods used in this analysis\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2_link'></a>\n",
    "# 2. Setup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.1_link'></a>\n",
    "### 2.1 Generate time series: sine wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this initial experiment is a simple sine wave. The number of data points in each period is kept fixed thoughout the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations in time series: 1820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-09</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-10</th>\n",
       "      <td>0.034516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-11</th>\n",
       "      <td>0.068991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-12</th>\n",
       "      <td>0.103384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-13</th>\n",
       "      <td>0.137654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            observations\n",
       "2015-07-09      0.000000\n",
       "2015-07-10      0.034516\n",
       "2015-07-11      0.068991\n",
       "2015-07-12      0.103384\n",
       "2015-07-13      0.137654"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=5*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 10  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "print('number of observations in time series: {}'.format(len(observations)))\n",
    "\n",
    "# initialize dataframe to store time series\n",
    "df = pd.DataFrame(data=observations, columns=['observations'])\n",
    "df.index = idx\n",
    "\n",
    "# initialize object\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# load dataframe into object\n",
    "mdq._selected_features = ['observations']\n",
    "mdq.df = df\n",
    "mdq.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.2_link'></a>\n",
    "### 2.2 Separate training and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split ratio =  0.7\n"
     ]
    }
   ],
   "source": [
    "# train-validation split ratio as class attribute set to 70%\n",
    "print('train split ratio = ', mdq.TRAIN_SPLIT_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data set length: 1820\n"
     ]
    }
   ],
   "source": [
    "# initialize dataset from dataframe \n",
    "mdq.initialize_dataset()\n",
    "\n",
    "print('loaded data set length: {}'.format(len(mdq._dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3_link'></a>\n",
    "# 3. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.1_link'></a>\n",
    "### 3.1 Standardize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.0, std: 1.0\n"
     ]
    }
   ],
   "source": [
    "# standardize data\n",
    "mdq.standardize_data()\n",
    "\n",
    "# check that mean equals zero and the standard deviation is one\n",
    "print('mean: {}, std: {}'.format(round(np.mean(mdq._dataset), 2), round(np.std(mdq._dataset), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part4_link'></a>\n",
    "# 4. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part4.1_link'></a>\n",
    "### 4.1 Cache, batch and shuffle using Tensorflow's data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number time points to be forecasted and the number of points the model is trained on are set. The training and validation dataset is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: x:(909, 365, 1), y:(909, 7, 1)\n",
      "validation set shape: x:(174, 365, 1), y:(174, 7, 1)\n",
      "number of training samples: 909\n"
     ]
    }
   ],
   "source": [
    "# set number of time points for 1/ future forecasting points and 2/ the past, historical time points\n",
    "future_target_size = int(365/52)\n",
    "past_history_size = int(1*365)\n",
    "\n",
    "# generate training and validation data\n",
    "mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size)\n",
    "\n",
    "\"\"\"\n",
    "data shapes: (batch size, number of input time steps, number of features)\\\n",
    "\"\"\"\n",
    "\n",
    "print('number of training samples: {}'.format(mdq._num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part5_link'></a>\n",
    "# 5. Setup and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model specifics \n",
    "units = 96\n",
    "num_layers = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part5.1_link'></a>\n",
    "### 5.1 RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test that model got created in object instance: \n",
      " {'RNN': <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fbf8c50e650>}\n"
     ]
    }
   ],
   "source": [
    "# setup Keras LSTM model and compile\n",
    "\n",
    "model_type = 'RNN'\n",
    "mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "# check that model exists in mdq-object\n",
    "print('test that model got created in object instance: \\n', mdq._models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part5.2_link'></a>\n",
    "### 5.2 LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Keras, the configuration details of the LSTM model is set and compiled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setup Keras LSTM model and compile\n",
    "\n",
    "# model_type = 'LSTM'\n",
    "# mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "# # check that model exists in mdq-object\n",
    "# print('test that model got created in object instance: \\n', mdq._models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part6_link'></a>\n",
    "# 6. Fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part6.1_link'></a>\n",
    "### 6.1 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the number of epochs and steps per epoch, the model is fit to the training data. The generated 'history' will be used in the following section to assess the quality of the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "129/129 [==============================] - 10s 81ms/step - loss: 0.0941 - mse: 0.0941 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 10s 76ms/step - loss: 0.2681 - mse: 0.2681 - val_loss: 0.0539 - val_mse: 0.0539\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 10s 80ms/step - loss: 0.1026 - mse: 0.1026 - val_loss: 0.0500 - val_mse: 0.0500\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 10s 79ms/step - loss: 0.0785 - mse: 0.0785 - val_loss: 0.0493 - val_mse: 0.0493\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 12s 90ms/step - loss: 0.0809 - mse: 0.0809 - val_loss: 0.0378 - val_mse: 0.0378\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 11s 88ms/step - loss: 0.0705 - mse: 0.0705 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 10s 76ms/step - loss: 0.0637 - mse: 0.0637 - val_loss: 0.0337 - val_mse: 0.0337\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 10s 78ms/step - loss: 0.0692 - mse: 0.0692 - val_loss: 0.0514 - val_mse: 0.0514\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 10s 77ms/step - loss: 0.0686 - mse: 0.0686 - val_loss: 0.0323 - val_mse: 0.0323\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 9s 69ms/step - loss: 0.0607 - mse: 0.0607 - val_loss: 0.0330 - val_mse: 0.0330\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 9s 72ms/step - loss: 0.0666 - mse: 0.0666 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 8s 65ms/step - loss: 0.0629 - mse: 0.0629 - val_loss: 0.0415 - val_mse: 0.0415\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 9s 69ms/step - loss: 0.0629 - mse: 0.0629 - val_loss: 0.0312 - val_mse: 0.0312\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 9s 70ms/step - loss: 0.0531 - mse: 0.0531 - val_loss: 0.0398 - val_mse: 0.0398\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 10s 78ms/step - loss: 0.0560 - mse: 0.0560 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 9s 68ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0643 - val_mse: 0.0643\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 9s 70ms/step - loss: 0.0597 - mse: 0.0597 - val_loss: 0.0552 - val_mse: 0.0552\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 8s 64ms/step - loss: 0.0555 - mse: 0.0555 - val_loss: 0.0304 - val_mse: 0.0304\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 10s 75ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0309 - val_mse: 0.0309\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 10s 81ms/step - loss: 0.0490 - mse: 0.0490 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 11s 86ms/step - loss: 0.0530 - mse: 0.0530 - val_loss: 0.1008 - val_mse: 0.1008\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 13s 100ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0339 - val_mse: 0.0339\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 11s 84ms/step - loss: 0.0464 - mse: 0.0464 - val_loss: 0.0375 - val_mse: 0.0375\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 9s 74ms/step - loss: 0.0496 - mse: 0.0496 - val_loss: 0.0327 - val_mse: 0.0327\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 10s 74ms/step - loss: 0.0357 - mse: 0.0357 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 8s 65ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0195 - val_mse: 0.0195\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 9s 69ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.0168 - val_mse: 0.0168\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 10s 74ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.0216 - val_mse: 0.0216\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 10s 78ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 11s 83ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.0169 - val_mse: 0.0169\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 10s 78ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 14s 108ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 9s 73ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0040 - val_mse: 0.0040\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 9s 73ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 10s 75ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 8s 65ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 8s 64ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 9s 68ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 6.0316e-04 - val_mse: 6.0316e-04\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 10s 77ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 9s 67ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0147 - val_mse: 0.0147\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 9s 70ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 9s 68ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 8s 65ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0041 - val_mse: 0.0041\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 9s 66ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0063 - val_mse: 0.0063\n",
      "Epoch 45/50\n",
      " 78/129 [=================>............] - ETA: 3s - loss: 0.0173 - mse: 0.0173"
     ]
    }
   ],
   "source": [
    "# set number of epochs\n",
    "epochs = 50\n",
    "\n",
    "# set number of steps per epoch\n",
    "num_samples = mdq._num_samples\n",
    "steps_per_epoch = int(num_samples/future_target_size)\n",
    "\n",
    "validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "model_type = 'RNN'\n",
    "mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "              ,validation_steps=validation_steps, model_type=model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "print('total training time: {}'.format(total_training_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part6.2_link'></a>\n",
    "### 6.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = 'LSTM'\n",
    "# mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "#               ,validation_steps=validation_steps, model_type=model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "# print('total training time: {}'.format(total_training_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part7_link'></a>\n",
    "# 7. loss and error metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part7.1_link'></a>\n",
    "### 7.1 RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize training and validation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'RNN'\n",
    "mdq.plot_history(model_type=model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize predictions\n",
    "\n",
    "num = 2\n",
    "for x, y in mdq._val_data.take(3):\n",
    "    mdq.multi_step_plot(x[num], y[num], mdq._models[model_type].predict(x)[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part7.2_link'></a>\n",
    "### 7.2 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize training and validation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = 'LSTM'\n",
    "# mdq.plot_history(model_type=model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize predictions\n",
    "\n",
    "# num = 2\n",
    "# for x, y in mdq._val_data.take(3):\n",
    "#     mdq.multi_step_plot(x[num], y[num], mdq._models[model_type].predict(x)[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
