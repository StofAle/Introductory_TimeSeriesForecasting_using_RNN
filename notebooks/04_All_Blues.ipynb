{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "#### In this notebook, the optimal network configurations obtained from the runs in the preceding notebook ('03_Blue_in_Green.ipynb') are trained on different lengths of historical data set. The behavior of the learning curves as well as the magnitude of the error metric with varying historical information is analyzed and an optimal length for the training data inferred.\n",
    "\n",
    "#### The experiements are run on the clean as well as distored datasets which were both analyzed in the preceding notebook.\n",
    "\n",
    "#### GIven a seven day forecasting horizon for the target, the inferred optimal range of historical information is used as a guideline in the subsequent notebook '05_Flamenco_Sketches.ipynb', where the fine tuned models are test on financial stock data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [1. Load modules](#Part1_link)\n",
    "* [2. Clean time series](#Part2_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.1 Evaluate model performance under varying amounts of historical information](#Part2.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.2 Visualize and save results](#Part2.2_link)\n",
    "* [3. Distorted time series](#Part3_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.1 Evaluate model performance under varying amounts of historical information](#Part3.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.2 Visualize and save results](#Part3.2_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part1_link'></a>\n",
    "# 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import Kind_of_Blue  # own class with a collection of methods used in this analysis\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2_link'></a>\n",
    "# 2. Clean time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model performance for a range of historical training data lengths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=5*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 10  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "\n",
    "# initialize object\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# set target feature \n",
    "mdq._selected_features = ['observations']\n",
    "\n",
    "# initialize dataframe to store time series\n",
    "df = pd.DataFrame(data={'observations': observations})\n",
    "df.index = idx\n",
    "\n",
    "# load dataframe into object\n",
    "mdq.df = df\n",
    "\n",
    "# initialize dataset from dataframe \n",
    "mdq.initialize_dataset()\n",
    "\n",
    "# standardize data\n",
    "mdq.standardize_data()\n",
    "\n",
    "# set number of time points for 1/ future forecasting points and 2/ the past, historical time points\n",
    "future_target_size = int(365/52)\n",
    "\n",
    "# specify model configuration: this is chosen basen on the results from the previous notebook 02_Freddie_Freeloader.ipynb\n",
    "units = 128  # number of units in each neural network layer\n",
    "num_layers = 2  # total number of layers\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.1_link'></a>\n",
    "### 2.1 Evaluate model performance under varying amounts of historical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: x:(1267, 7, 1), y:(1267, 7, 1)\n",
      "validation set shape: x:(532, 7, 1), y:(532, 7, 1)\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 1s 6ms/step - loss: 0.0625 - mse: 0.0625 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 1s 4ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0030 - val_mse: 0.0030\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0026 - val_mse: 0.0026\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0021 - val_mse: 0.0021\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 1s 3ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "training set shape: x:(1204, 70, 1), y:(1204, 7, 1)\n",
      "validation set shape: x:(469, 70, 1), y:(469, 7, 1)\n",
      "Epoch 1/10\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 0.0568 - mse: 0.0568 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.0011 - val_mse: 0.0011\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0018 - val_mse: 0.0018\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 9.8489e-04 - val_mse: 9.8489e-04\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 3s 16ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 6.4051e-04 - val_mse: 6.4051e-04\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0035 - val_mse: 0.0035\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0014 - val_mse: 0.0014\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 5.4967e-04 - val_mse: 5.4967e-04\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 3s 20ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "training set shape: x:(1134, 140, 1), y:(1134, 7, 1)\n",
      "validation set shape: x:(399, 140, 1), y:(399, 7, 1)\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 6s 39ms/step - loss: 0.0645 - mse: 0.0645 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 6s 38ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.0099 - val_mse: 0.0099\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0024 - val_mse: 0.0024\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0036 - val_mse: 0.0036\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 5s 32ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 5s 32ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 9.0513e-04 - val_mse: 9.0513e-04\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 5s 32ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 5s 32ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0025 - val_mse: 0.0025\n",
      "training set shape: x:(910, 364, 1), y:(910, 7, 1)\n",
      "validation set shape: x:(175, 364, 1), y:(175, 7, 1)\n",
      "Epoch 1/10\n",
      "130/130 [==============================] - 11s 82ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.0293 - val_mse: 0.0293\n",
      "Epoch 2/10\n",
      "130/130 [==============================] - 11s 84ms/step - loss: 0.0340 - mse: 0.0340 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 3/10\n",
      "130/130 [==============================] - 10s 80ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0042 - val_mse: 0.0042\n",
      "Epoch 4/10\n",
      "130/130 [==============================] - 10s 80ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0064 - val_mse: 0.0064\n",
      "Epoch 5/10\n",
      "130/130 [==============================] - 11s 85ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0010 - val_mse: 0.0010\n",
      "Epoch 6/10\n",
      "130/130 [==============================] - 11s 83ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 7/10\n",
      "130/130 [==============================] - 11s 82ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0013 - val_mse: 0.0013\n",
      "Epoch 8/10\n",
      "130/130 [==============================] - 12s 91ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0058 - val_mse: 0.0058\n",
      "Epoch 9/10\n",
      "130/130 [==============================] - 12s 90ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 3.7214e-04 - val_mse: 3.7214e-04\n",
      "Epoch 10/10\n",
      "130/130 [==============================] - 12s 93ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 8.7179e-04 - val_mse: 8.7179e-04\n",
      "training set shape: x:(1267, 7, 1), y:(1267, 7, 1)\n",
      "validation set shape: x:(532, 7, 1), y:(532, 7, 1)\n",
      "Epoch 1/10\n",
      "181/181 [==============================] - 3s 19ms/step - loss: 0.1497 - mse: 0.1497 - val_loss: 0.0649 - val_mse: 0.0649\n",
      "Epoch 2/10\n",
      "181/181 [==============================] - 2s 13ms/step - loss: 0.0666 - mse: 0.0666 - val_loss: 0.0357 - val_mse: 0.0357\n",
      "Epoch 3/10\n",
      "181/181 [==============================] - 2s 12ms/step - loss: 0.0378 - mse: 0.0378 - val_loss: 0.0102 - val_mse: 0.0102\n",
      "Epoch 4/10\n",
      "181/181 [==============================] - 2s 12ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 5/10\n",
      "181/181 [==============================] - 2s 12ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0078 - val_mse: 0.0078\n",
      "Epoch 6/10\n",
      "181/181 [==============================] - 2s 12ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0017 - val_mse: 0.0017\n",
      "Epoch 7/10\n",
      "181/181 [==============================] - 2s 12ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0038 - val_mse: 0.0038\n",
      "Epoch 8/10\n",
      "181/181 [==============================] - 2s 12ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 9/10\n",
      "181/181 [==============================] - 2s 12ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.0022 - val_mse: 0.0022\n",
      "Epoch 10/10\n",
      "181/181 [==============================] - 2s 13ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "training set shape: x:(1204, 70, 1), y:(1204, 7, 1)\n",
      "validation set shape: x:(469, 70, 1), y:(469, 7, 1)\n",
      "Epoch 1/10\n",
      "172/172 [==============================] - 19s 109ms/step - loss: 0.0928 - mse: 0.0928 - val_loss: 0.0037 - val_mse: 0.0037\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.0019 - val_mse: 0.0019\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 21s 124ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0016 - val_mse: 0.0016\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 16s 96ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 15s 89ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0031 - val_mse: 0.0031\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 15s 89ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 7.4696e-04 - val_mse: 7.4696e-04\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 15s 88ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0027 - val_mse: 0.0027\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 15s 89ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0023 - val_mse: 0.0023\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 16s 90ms/step - loss: 0.0106 - mse: 0.0106 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 16s 92ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0020 - val_mse: 0.0020\n",
      "training set shape: x:(1134, 140, 1), y:(1134, 7, 1)\n",
      "validation set shape: x:(399, 140, 1), y:(399, 7, 1)\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 29s 177ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 29s 176ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 29s 176ms/step - loss: nan - mse: nan - val_loss: nan - val_mse: nan\n",
      "Epoch 4/10\n",
      " 26/162 [===>..........................] - ETA: 21s - loss: nan - mse: nan"
     ]
    }
   ],
   "source": [
    "# choose a few past history sizes as a multiple of the future target size (seven data points)\n",
    "past_history_sizes = [1 * future_target_size, 10 * future_target_size\n",
    "                      , 20 * future_target_size, 52 * future_target_size]\n",
    "\n",
    "# initialize results dictionary\n",
    "res_2 = {'model_type': [], 'past_history_size': [], 'val_mse': []\n",
    "       , 'mse': [], 'total_training_time': []}\n",
    "\n",
    "# model type \n",
    "model_types = ['RNN', 'LSTM']\n",
    "\n",
    "for model_type in model_types:\n",
    "    \n",
    "    for past_history_size in past_history_sizes:\n",
    "        \n",
    "        # generate train and validation data\n",
    "        mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size)\n",
    "\n",
    "        # set number of steps per epoch\n",
    "        num_samples = mdq._num_samples\n",
    "        steps_per_epoch = int(num_samples/future_target_size)\n",
    "        validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "        # compile model\n",
    "        mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "        # fit model\n",
    "        mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "                      ,validation_steps=validation_steps, model_type=model_type)\n",
    "\n",
    "        # get errors\n",
    "        history = mdq._histories[model_type]\n",
    "        val_mse = history.history['val_mse'][-1]\n",
    "        mse = history.history['mse'][-1]\n",
    "\n",
    "        # get total training time\n",
    "        total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "\n",
    "        # append results to results dictionary\n",
    "        res_2['model_type'].append(model_type)\n",
    "        res_2['past_history_size'].append(past_history_size)\n",
    "        res_2['val_mse'].append(val_mse)\n",
    "        res_2['mse'].append(mse)\n",
    "        res_2['total_training_time'].append(total_training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.2_link'></a>\n",
    "### 2.2 Visualize and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary to dataframe\n",
    "df_res_22 = pd.DataFrame(res_2)\n",
    "\n",
    "# store dataframe as csv locally\n",
    "df_res_22.to_csv('../data/04_results_cleanData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results\n",
    "# compare RNN to LSTM results\n",
    "\n",
    "df_res = df_res_22\n",
    "\n",
    "x_label = 'past_history_size'\n",
    "y_label = 'mse'\n",
    "z_label = 'val_mse'\n",
    "\n",
    "for model_type in model_types:\n",
    "    condition_1 = (df_res['model_type']== model_type)\n",
    "    \n",
    "    x = df_res[condition_1][x_label].values\n",
    "    y = df_res[condition_1][y_label].values\n",
    "    \n",
    "    z = df_res[condition_1][z_label].values\n",
    "    \n",
    "    plt.scatter(x, y, alpha=0.6, c=\"red\", linewidth=0.0, label='training')\n",
    "    plt.scatter(x, z, alpha=0.6, c=\"blue\", linewidth=0.0, label='validation')\n",
    "        \n",
    "    plt.xlabel('past history data size [days]')\n",
    "    plt.ylabel('mse')\n",
    "    plt.legend()\n",
    "    plt.title('clean dataset: {} model'.format(model_type))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3_link'></a>\n",
    "# 3. Distorted time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run RNN and LSTM model with noise added ontop of the clean data. Evaluate model performance for a range of variances of the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.1_link'></a>\n",
    "### 3.1 Evaluate model performance under varying noise levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=5*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 10  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "\n",
    "# initialize object\n",
    "try:\n",
    "    del mqd\n",
    "except: pass\n",
    "\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# set target feature \n",
    "mdq._selected_features = ['observations']\n",
    "\n",
    "\n",
    "# generate noisy observations by adding Gaussian noise to clean observations\n",
    "mean = 0.0\n",
    "std = 1.0\n",
    "noise = [np.random.normal(loc=mean, scale=std, size=None) for x in range(len(idx))]        \n",
    "noisy_observations = [noise[i]+observations[i] for i in range(len(noise))]\n",
    "\n",
    "# initialize dataframe to store time series\n",
    "df = pd.DataFrame(data={'observations': noisy_observations})\n",
    "df.index = idx\n",
    "\n",
    "# load dataframe into object\n",
    "mdq.df = df\n",
    "\n",
    "# initialize dataset from dataframe \n",
    "mdq.initialize_dataset()\n",
    "\n",
    "# standardize data\n",
    "mdq.standardize_data()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialize results dictionary\n",
    "res_3 = {'model_type': [], 'past_history_size': [], 'val_mse': []\n",
    "       , 'mse': [], 'total_training_time': []}\n",
    "\n",
    "# model type \n",
    "model_types = ['RNN', 'LSTM']\n",
    "\n",
    "for model_type in model_types:\n",
    "    \n",
    "    for past_history_size in past_history_sizes:\n",
    "        \n",
    "        # generate train and validation data\n",
    "        mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size)\n",
    "\n",
    "        # set number of steps per epoch\n",
    "        num_samples = mdq._num_samples\n",
    "        steps_per_epoch = int(num_samples/future_target_size)\n",
    "        validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "        # compile model\n",
    "        mdq.compile_model(units=units, num_layers=num_layers, model_type=model_type)\n",
    "\n",
    "        # fit model\n",
    "        mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "                      ,validation_steps=validation_steps, model_type=model_type)\n",
    "\n",
    "        # get errors\n",
    "        history = mdq._histories[model_type]\n",
    "        val_mse = history.history['val_mse'][-1]\n",
    "        mse = history.history['mse'][-1]\n",
    "\n",
    "        # get total training time\n",
    "        total_training_time = sum(mdq._time_callbacks[model_type].times)\n",
    "\n",
    "        # append results to results dictionary\n",
    "        res_3['model_type'].append(model_type)\n",
    "        res_3['past_history_size'].append(past_history_size)\n",
    "        res_3['val_mse'].append(val_mse)\n",
    "        res_3['mse'].append(mse)\n",
    "        res_3['total_training_time'].append(total_training_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.2_link'></a>\n",
    "### 3.2 Visualize and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform dictionary to dataframe\n",
    "df_res_32 = pd.DataFrame(res_3)\n",
    "\n",
    "# store dataframe as csv locally\n",
    "df_res_32.to_csv('../data/04_results_distored.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results\n",
    "# compare RNN to LSTM results\n",
    "\n",
    "df_res = df_res_32\n",
    "\n",
    "x_label = 'past_history_size'\n",
    "y_label = 'mse'\n",
    "z_label = 'val_mse'\n",
    "\n",
    "for model_type in model_types:\n",
    "    condition_1 = (df_res['model_type']== model_type)\n",
    "    \n",
    "    x = df_res[condition_1][x_label].values\n",
    "    y = df_res[condition_1][y_label].values\n",
    "    \n",
    "    z = df_res[condition_1][z_label].values\n",
    "    \n",
    "    plt.scatter(x, y, alpha=0.6, c=\"red\", linewidth=0.0, label='training')\n",
    "    plt.scatter(x, z, alpha=0.6, c=\"blue\", linewidth=0.0, label='validation')\n",
    "        \n",
    "    plt.xlabel('past history data size [days]')\n",
    "    plt.ylabel('mse')\n",
    "    plt.title('noisy dataset: {} model'.format(model_type))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
