{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "\n",
    "#### ...\n",
    "\n",
    "#### In particular, the following questions will be analyzed:\n",
    "#### - How does...?\n",
    "\n",
    "\n",
    "\n",
    "## ToDo:\n",
    "#### choose continuous function as target first. then add noise to it and magnify it. \n",
    "#### also test: add noise ontop of sine or as another feature next to it - should give same answer?\n",
    "#### also check: keras.layers.RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [1. update](#Part1_link)\n",
    "* [2. update](#Part2_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.1 update](#Part2.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[2.2 update](#Part2.2_link)\n",
    "\n",
    "* [3. update](#Part3_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[3.1 update](#Part3.1_link)\n",
    "* [4. update](#Part4_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[4.1 update](#Part4.1_link)\n",
    "* [5. update](#Part5_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[5.1 update](#Part5.1_link)\n",
    "* [6. update](#Part6_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[6.1 update](#Part6.1_link)\n",
    "* [7. update](#Part7_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[7.1 update](#Part7.1_link)\n",
    "<br >&nbsp;&nbsp;&nbsp;[7.2 update](#Part7.2_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part1_link'></a>\n",
    "# 1. Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Kind_of_Blue  # own class with a collection of methods used in this analysis\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2_link'></a>\n",
    "# 2. Setup data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.1_link'></a>\n",
    "### 2.1 Generate time series: sine wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this initial experiment is a simple sine wave. The number of data points in each period is kept fixed thoughout the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of observations in time series: 3640\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-07-15</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-16</th>\n",
       "      <td>0.034516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-17</th>\n",
       "      <td>0.068991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-18</th>\n",
       "      <td>0.103384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-19</th>\n",
       "      <td>0.137654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            observations\n",
       "2010-07-15      0.000000\n",
       "2010-07-16      0.034516\n",
       "2010-07-17      0.068991\n",
       "2010-07-18      0.103384\n",
       "2010-07-19      0.137654"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set a range of dates on which the observations are made\n",
    "idx = pd.date_range(end='7/1/2020', periods=10*364, freq='d')\n",
    "\n",
    "# take a sine function as the observations\n",
    "num_periods = 20  # number of sine periods\n",
    "observations = [np.sin(2*np.pi*num_periods*x/len(idx)) for x in range(len(idx))]\n",
    "print('number of observations in time series: {}'.format(len(observations)))\n",
    "\n",
    "# initialize dataframe to store time series\n",
    "df = pd.DataFrame(data=observations, columns=['observations'])\n",
    "df.index = idx\n",
    "\n",
    "# initialize object\n",
    "mdq = Kind_of_Blue.Kind_of_Blue()\n",
    "\n",
    "# load dataframe into object\n",
    "mdq._selected_features = ['observations']\n",
    "mdq.df = df\n",
    "mdq.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part2.2_link'></a>\n",
    "### 2.2 Separate training and validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train split ratio =  0.7\n"
     ]
    }
   ],
   "source": [
    "# train-validation split ratio as class attribute set to 70%\n",
    "print('train split ratio = ', mdq.TRAIN_SPLIT_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data set length: 3640\n"
     ]
    }
   ],
   "source": [
    "# initialize dataset from dataframe \n",
    "mdq.initialize_dataset()\n",
    "print('loaded data set length: {}'.format(len(mdq._dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3_link'></a>\n",
    "# 3. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part3.1_link'></a>\n",
    "### 3.1 Standardize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.0, std: 1.0\n"
     ]
    }
   ],
   "source": [
    "# standardize data\n",
    "mdq.standardize_data()\n",
    "\n",
    "# check that mean equals zero and the standard deviation is one\n",
    "print('mean: {}, std: {}'.format(round(np.mean(mdq._dataset), 2), round(np.std(mdq._dataset), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part4_link'></a>\n",
    "# 4. Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part4.1_link'></a>\n",
    "### 4.1 Cache, batch and shuffle using Tensorflow's data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number time points to be forecasted and the number of points the model is trained on are set. The training and validation dataset is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape: x:(1818, 730, 1), y:(1818, 7, 1)\n",
      "validation set shape: x:(355, 730, 1), y:(355, 7, 1)\n",
      "number of training samples: 1818\n"
     ]
    }
   ],
   "source": [
    "# set number of time points for 1/ future forecasting points and 2/ the past, historical time points\n",
    "future_target_size = int(365/52)\n",
    "past_history_size = int(2*365)\n",
    "\n",
    "# set batch size\n",
    "batch_size = 32\n",
    "mdq.generate_train_and_val_data(future_target_size=future_target_size, past_history_size=past_history_size\n",
    "                                , batch_size=batch_size)\n",
    "\n",
    "print('number of training samples: {}'.format(mdq._num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part5_link'></a>\n",
    "# 5. Setup and compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part5.1_link'></a>\n",
    "### 5.1 LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Keras, the configuration details of the LSTM model is set and compiled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToDo2: change a few things in the LSTM setup before running tests\n",
      "test that model got created in object instance: \n",
      " <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fb2c240dc10>\n"
     ]
    }
   ],
   "source": [
    "# setup Keras LSTM model and compile\n",
    "units = 32\n",
    "num_layers = 3\n",
    "mdq.compile_LSTM_model(units=units, num_layers=num_layers)\n",
    "\n",
    "# check that model exists in mdq-object\n",
    "print('test that model got created in object instance: \\n', mdq._model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part6_link'></a>\n",
    "# 6. Fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part6.1_link'></a>\n",
    "### 6.1 LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the number of epochs and steps per epoch, the model is fit to the training data. The generated 'history' will be used in the following section to assess the quality of the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "56/56 [==============================] - 45s 796ms/step - loss: 0.5335 - mse: 0.5335 - val_loss: 0.0890 - val_mse: 0.0890\n",
      "Epoch 2/5\n",
      "56/56 [==============================] - 41s 734ms/step - loss: 0.1091 - mse: 0.1091 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 3/5\n",
      "56/56 [==============================] - 40s 713ms/step - loss: 0.0762 - mse: 0.0762 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 4/5\n",
      "12/56 [=====>........................] - ETA: 28s - loss: 0.0656 - mse: 0.0656"
     ]
    }
   ],
   "source": [
    "# set number of epochs\n",
    "epochs = 5\n",
    "\n",
    "# set number of \n",
    "num_samples = mdq._num_samples\n",
    "steps_per_epoch = int(num_samples/batch_size)\n",
    "\n",
    "validation_steps = int(steps_per_epoch/2)\n",
    "\n",
    "mdq.fit_model(epochs=epochs, steps_per_epoch=steps_per_epoch\n",
    "              ,validation_steps=validation_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part7_link'></a>\n",
    "# 7. loss and error metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part7.1_link'></a>\n",
    "### 7.1 Visualize training and validation history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Part7.2_link'></a>\n",
    "### 7.2 Assess error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_target_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdq.plot_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize predictions\n",
    "\n",
    "num = 2\n",
    "for x, y in mdq._val_data.take(3):\n",
    "    mdq.multi_step_plot(x[num], y[num], mdq._model.predict(x)[:1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
